#!/usr/bin/perl

use strict;

use Digest::SHA;
use File::Basename;
use File::Spec;
use File::Path;
use File::Copy; 
use Time::HiRes qw( CLOCK_REALTIME gettimeofday tv_interval);
use Getopt::Long;
use POSIX; # needed for time formating

# Database Layer

use BerkeleyDB;
use BerkeleyDB::Hash;
use BerkeleyDB::Btree;

# Gives us tied access to databases

use MLDBM qw( BerkeleyDB::Hash Storable );

# Major globals

my $DESCRIPTOR_FILENAME = "00descriptor.gfs";
my $GENERAL_DEBUG = 1;
my $USUAL_IGNORE = 1;
local $main::SCRIPT_START = time();
local $main::SCRIPT_START_GTOD = [gettimeofday];
local $main::GUARD_TIME_SECONDS = undef; 

# Run statistics - globals

local $main::run_files_fullread = 0;
local $main::run_bytes_fullread = 0;
local $main::run_time_fullread = 0;
local $main::run_files_stat = 0;
local $main::run_descriptors_read = 0;
local $main::run_descriptors_write = 0;
local $main::readdir_invokes = 0;
local $main::readdir_entries = 0;

# Get path to our WD

my $HOME = $ENV{HOME};
my $WDIR = "$HOME/.gfs";
my $DBDIR = "$WDIR/db";
my $EDIR = "$ENV{HOME}/.gfsrun/EXEC-$$";

$main::localFileSystemFSE = undef;

# Option management

my $OPT_ALL = 0;
my $OPT_STATS = 0;
my $OPT_GUARDTIME = undef;

&GetOptions( 'all' => \$OPT_ALL,
			 'G|guard=s' => \$OPT_GUARDTIME,
			 'stats' => \$OPT_STATS );


if( defined $OPT_GUARDTIME )
{
	$main::GUARD_TIME_SECONDS = $OPT_GUARDTIME;

	print "Guard time set to: $main::GUARD_TIME_SECONDS\n";
}


sub expressRelativeTime
{
	my $seconds = shift;

	if( $seconds > 24*60*60)
	{
		$seconds /= 24*60*60;
		my $r = sprintf( "%0.4s days", $seconds );
		return $r;
	}

	if( $seconds > 2*60*60)
	{
		$seconds /= 60*60;
		my $r = sprintf( "%0.4s hours", $seconds );
		return $r;
	}

	if( $seconds > 120)
	{
		$seconds /= 60;
		my $r = sprintf( "%0.4s secs", $seconds );
		return $r;
	}


	return "$seconds" . "s";

}


# Key function prototypes
sub debug($);

# Helper function that creates a nested path with lots of error checking

sub mkdirs
{
    my $dir = shift;
    my $dirx = dirname $dir;

    # print "MKDIRS:[$dirx]\n";

    eval{ mkpath($dirx,1) };
    $@ and die "Couldn't create dir path: $@";
    die "Did not find new path" if not -d $dirx;

   return 1;
}

# Helper function - if user requests it, ignores shit things like .git and .DS_Store
# Returns true if the file is good to go, or false if it is usually ignored
# This is not to be used for avoiding actual logic or recursion errors
# (such as scanning our own descriptors).
# User should be free to turn this feature off and the program must work as intended. 

sub fileIsUsuallyIgnored
{
	my $cfn = shift;

	return 0 if( not $USUAL_IGNORE );

	return 1 if $cfn =~ /\.DS_Store$/;
	return 1 if $cfn =~ /\Thumbs.db$/;
	return 1 if $cfn =~ /\.pcip_info$/;

	return 0;
}

# Verifies readability of various directories needed for program invocation

sub verifyWorkingDirectories
{
	if( not -e $WDIR )
	{
	    mkdir $WDIR or die "Error creating [$WDIR]: $!";
	}

	if( not -e $DBDIR )
	{
	    mkdir $DBDIR or die "Error creating [$DBDIR]: $!";
	}

	if( not -e $EDIR )
	{
	    mkdirs($EDIR . "/") or die "Error creating [$EDIR]: $!";
	}

	die "Cannot create $WDIR" unless -w $WDIR;
	die "Cannot create $DBDIR" unless -w $DBDIR;
}

# Sets up our data

sub setupDatabases
{
	my $bdb_env = new BerkeleyDB::Env 
	    -Verbose => 1,
	    -Home => $DBDIR,
	    -Flags => DB_CREATE|DB_INIT_MPOOL|DB_INIT_CDB,
	    -ErrFile => "$DBDIR/Errors-$$",
	    -ErrPrefix => "GFS";
}


sub debug ($)
{
	return if not $GENERAL_DEBUG;
	my $a = shift @_;
	chomp $a;
	print "DEBUG_LINE: " . $a . "\n";
}


sub init
{
	verifyWorkingDirectories();
	setupDatabases();
	$main::localFileSystemFSE = new FilesystemExplorer();

}



# Incorporated code from String::Escape via per artistic license
# Reason: Need to tweak what counts as an escaped character

# =head1 AUTHOR
# Matthew Simon Cavalletto, C<< <simonm at cavalletto.org> >>
# Initial versions developed at Evolution Online Systems with Eleanor J. Evans and Jeremy G. Bishop.
# =head1 LICENSE
# Copyright 2010, 2002 Matthew Simon Cavalletto.
# Portions copyright 1996, 1997, 1998, 2001 Evolution Online Systems, Inc.
# You may use, modify, and distribute this software under the same terms as Perl.
# See http://dev.perl.org/licenses/ for more information.
# =cut


use vars qw( %Backslashed %Interpolated );

# Earlier definitions are preferred to later ones, thus we output \n not \x0d
_define_backslash_escapes(
	( map { $_ => $_ } ( '\\', '"', '$', '@' ) ),
	( 'r' => "\r", 'n' => "\n", 't' => "\t" ),
	( map { 'x' . unpack('H2', chr($_)) => chr($_) } (0..255) ),
	( map { sprintf('%03o', $_) => chr($_) } (0..255) ),
);

sub _define_backslash_escapes {
	%Interpolated = @_;
	%Backslashed  = reverse @_;
}

# $special_characters_escaped = backslash( $source_string );
sub backslash ($) {
	local $_ = ( defined $_[0] ? $_[0] : '' );
	# Preserve only printable ASCII characters other than \, ", $, and @
	s/([^\x20\x21\x24\x25-\x39\x41-\x5b\x5d-\x7e])/\\$Backslashed{$1}/gs;
	return $_;
}

# $original_string = unbackslash( $special_characters_escaped );
sub unbackslash ($) {
	local $_ = ( defined $_[0] ? $_[0] : '' );
	s/ (\A|\G|[^\\]) [\\] ( [0]\d\d | [x][\da-fA-F]{2} | . ) / $1 . ( $Interpolated{lc($2) }) /gsxe;
	return $_;
}


sub gfs_escape($)
{
	my $v = shift;

	$v =~ s/:/\\c/gs;
	$v =~ s/\n/\\n/gs;
	return $v;

}

sub gfs_unescape($)
{

	my $v = shift;
	$v =~ s/\\c/:/gs;
	$v =~ s/\\n/\n/gs;

	return $v;
}

# test cases:
# snapshot directories both a/* and a/ and a

# insight: we could have an entry for a directory.. the last full time it was scanned
# then if the read date of the file is earlier than the scan date of the directory
# then we know the file may be stale and can delete it



# how do we stick virtual things into the hash?
# for instance, where or how do we store the idea that a .tar file has certain contents
# or that an rsync directory (jgilbert@auspice.net:a/b/c) contains a file?
# almost like a normal path a/b/c is basically an implicit "local:a/b/c"..
# the local handler knows to write .gfs_info files
# whereas the remote one knows not to
# each FS type offeres a get, move, copy, retrieve full checksum, stat, etc function
# so now we can handle S3, Rsync, etc

# how does that tie in with tags?
# how do I say anything under /Volume/Foo should be addressed as FOODRIVE:
# clearly this only matters during AFN conversion
# disktag:FOODRIVE|/one/two/three
#
# if that is the AFN recorded, then the system will think that is there
# we just need to write a record like /Volume/Foo -> FOODRIVE
# and also write a /Volume/Foo/GFS_ID.txt file
# then a dereference just requires that we verify that the /Volume/Foo/GFS_ID can still be reached
# maybe there is a tool like "bless" which does this for you
# so the rel->AFN conversion would either need to rely on this mapping
# or traverse back up to make sure that all ../GFS_ID.txt files were registered

# is a snapshot treated as a file collection as a target? if it is, we have to emphasize 
# that it is a ghost. e.g. you can enumerate, but the fact that snapshot:4444/sdf contains
# this file version could never be used as a proxy.
# so when you "get all AFNs for hash", you'd have to pass to a FShandler for the snapshot

# GFS is an overlay snapshoting and directory reconstruction tool. Its not really meant 
# for version control, but managing someone's life which may be scattered 
# across many different asset types and locations.
# GFS is entirely built around command line tools. It doesn't watch the filesystem
# for changes.
# key features
# 1) highly accelerated content-aware rsync - a file is never retransmitted unless needed
# 2) worried you still wantt o eb sure you have a backup of a wedding photos? 
#     this has tools that let you flag and manage bit-rot and verify your stuff is where
#     you think it is
# 3) work with large file trees both on a desktop and laptop? GFS can tell you instantly
#     which chnages you've made on your laptop that are not yet on your desktop and push them
#     to the desktop efficiently
# 4) in the field and want to be sure files you are working on are protected?
#     GFS can make sure any file is either in your dropbox, on your machine at home
# 5) trying to free up space on your laptop? do you have a copy of that big 10 GB ISO file
#     at home? find out quickly if you can ditch it. 



# Database layer use cases
# 1) quickly give me ghost information for a path
#      AFN -> GhostSerialized as absolute
# 2) quickly give me the AFNs associated with a hash or size
#      hash -> AFN 0..n   (needed for LSDup)
#	   size -> AFN 0..n   (also possibly needed for LSDup)

# so when something is stored in location X or found in location X, 
# what permanent record is created?
# maybe we create spontaneous snapshot records that can be loaded back in?
#
#    gfs rsync /source jgilbert@asdf:foobar/
# 
# All files written to foobar drops a file in .gfs/receipts/rsync-$$-date.snapshot
# With the note: "This snapshot record was written by GFS on date XXXX"

sub main()
{
	# print "Welcome to Ghost.\n";

	init();

	# TODO: Some kind of sanity checking on arguments
	# Are all the files listed MECE?
	# Just a warning is fine here but the user ought to be prompted
	# just to be sure

	my $tk = TruthKeeper::get();

	my $verb = shift @ARGV;

	# print " Verb = [$verb]\n";

	handleVerb( $verb );

	# reconstruct-test A B C
	#   makes sure that everything in A and B be reconstructed in target C
	#   as long as there is at least one valid duplicate, we move on
	# 			first, best approach is to look for hashed AFN
	#			       ask FSE if it "owns" that file
	#				   then call "hasIdenticalContent()"
	#               if that doens't work, check the cache of sizes
	#					call hasIdenticalContent
	#                  as soon as one returns "hasIdenticalContent", we return
	#               finally, force the full cache of sizes

	# copy-delta A B C
	#    Anything in A and B that is not in C is going to get copied over 
	#	 into a "delta" directory

	# rsync A B C
	#	 C is reconfigured to look exactly like A and B. Files that no longer
	#    belong can be identified and removed as an option.
	#	 this works by MOVING files around inside of C. depending on how
	#    slashes are used, we either merge or replace (rsync ffo/ behavior)
	#    $fse->move( a, b );
	#			the move tool has to move the ghosts too
	# 			and that may invalidate certain descriptor files
	
	# what is the means by whcih deleted files are recongized?
	# in cases of a full scan, someone has to be smart enough
	# to know we are doing a scan that is "full" enough to count,
	# and to mark ghosts for deletion

	# right now, there is no stat verification when writing a snapshot
	#  snapshot -verify-stat (can find it, size and lastmod match) --verify-hash
	# and when those things are in place, anthing that hasn't been checked in the last 24 hours
	# are rejected, unless you say --hit-disk which means basically ignore all of the 
	# tools and recheck everything
	

	$tk->flush();

	if( $OPT_STATS )
	{
		handleStats();

	}
}


sub handleStats
{

	print "----- DONE -----\n";

	print "Full reads count: $main::run_files_fullread\n";
	print "Full reads size : $main::run_bytes_fullread\n";
	print "Full read time  : $main::run_time_fullread\n";

	print "Stat reads      : $main::run_files_stat\n";

	print "Local .gfs reads: $main::run_descriptors_read\n";
	print "Local .gfs writs: $main::run_descriptors_write\n";
	print "Readdir invokes : $main::readdir_invokes\n";
	print "Readdir entries : $main::readdir_entries\n";

	print "Total Script Time: " . tv_interval( $main::SCRIPT_START_GTOD ) . "\n";
	
}

sub handleVerb
{
	my $verb = shift;


	if( $verb eq "dbtest" )
	{
		my $fse = new FilesystemExplorer();
		$fse->setRoots( @ARGV );

		while( defined( my $file = $fse->next() ) )
		{
			print "DBTest - Scanning: [$file]\n";
		}
		return;
	}	

	if( $verb eq "lsdup")
	{
		doverb_lsdup();
		return;
	}

	if( $verb eq "help")
	{
		doverb_help();
		return;
	}

	# LS tells us what we can find out about the current directory tree
	# nothing is force read. there is a dirscan and that is it.

	if( $verb eq "ls" )
	{
		doverb_ls();
		return;
	}

	# Writes a permanent file of this entire tree

	if( $verb eq "write-snapshot")
	{
		doverb_writeSnapshot();
		return;
	}

	#### THINGS BELOW THIS LINE NOT TESTED

	# Takes the listed things and writes a single descriptor file

	if( $verb eq "write-descriptor")
	{
		doverb_writeDescriptor();
		return;
	}

	# Basically a test verb used to prove that serialization and deserialization are identical

	if( $verb eq "copyDescriptor" )
	{
		my $src = shift @ARGV;
		my $d = shift @ARGV;

		my $store = GhostStore->new();
		$store->slurpDescriptor( $src);
		$store->writeAsDescriptor( $d );
		return;
	}

	if( $verb eq "info" )
	{
		doverb_info();
		return;		
	}

	die "Verb $verb not recognized - try $0 help for ideas";

	return;
}


# GFS relies on all paths being canonicalized so that
# text matching occurs properly.
# Otherwise ./foo and foo will not text match and it will appear
# like they are different files. Any routines that brings in a "net new"
# path to the system should convert it to a cpath.

sub assert_cpath($)
{
	my $lfn = shift;
	my $clfn = File::Spec->canonpath( $lfn );
	die "$lfn ne $clfn" if $lfn ne $clfn; 
}

sub canonize($)
{
	my $lfn = shift;
	my $clfn = File::Spec->canonpath( $lfn );

	# print "Canonicalize: $lfn ---> $clfn\n";	

	return $clfn;
}


sub doverb_help
{
	print <<HERE;

gfs - a universal tool for file handling with checksums

Moves, snapshots and searches for duplicates with a minimum of disk activity.

Unless otherwise instructed, GFS avoids disk access
whenever possible. If meta-data about the size, modification date,
or checksum is already available, it is used for the operation regardless of its age
(although you might get a warning if its too old.) You can force
information to be more up to date by setting a guard time with -G.
This is the number of seconds old that metadata is valid. Setting it to 0 means
that basically no metadata caching is done.

Future feature: Checksums are not typically forced by the -G switch
unless there is some reason to doubt them (such as a changed size or modification
date. If you really want everything recalculated, set the --force-checksum.)


gfs ls file1 [... file-n]

	Prints out each file and the data known about it. Does
	not force any new calculations or checksums unless
	a guard argument is in place. 

gfs write-snapshot file1 [... filen]

    Writes a file describing the current state of the listed files.
    Checksums if not present are forced, otherwise, no unnecessary
    disk activity is created.

gfs lsdup [source1 .. source-n] target [--all]

    For every file in target tree, reports which is duplicated
    in the target or source trees.

    --all forces a report for every file, not just duplicates


HERE



}

##########
# Writes a snapshot file to disk for the listed paths
# 

sub doverb_writeSnapshot()
{
	my $tk = TruthKeeper::get();
	my $targetGS = $tk->makeGhostsFromCommandLine( @ARGV );

	my $i = $targetGS->getDescendingIterator();

	my $store = GhostStore->new();


	while( my $g = $i->next() )
	{
		print "Write Snapshot - Got Ghost: $g\n";

		if( not $g->canHaveChildren() )
		{
			$g->forceCharacterization();
		}
		

		$g->printDebug();
		$store->addGhost( $g );

	}

	$store->writeSnapshotToDisk( "snapshot-$$.out");
}

# for each item listed, shows what we know about it -- no recursion, no forced characterization

sub doverb_ls()
{
	my $tk = TruthKeeper::get();
	foreach my $lfn (@ARGV)
	{
		next unless -f $lfn;
		$lfn = canonize($lfn);
		my $g = $tk->obtainGhostForLFN($lfn);

		my $fullHash = $g->fullHash() || '<not calculated>';
		my $lastFullHash = $g->lastFullHash();

		my $lfh = defined $lastFullHash ? strftime( "%c", localtime( $lastFullHash) ) : '<not calculated>';

		my $d = expressRelativeTime( $main::SCRIPT_START - $lastFullHash );

		$lfh .= "($d)";

		print "$fullHash\t$lfh\t$lfn\n";
	}

}

###########
# Lsdup: A B C - for every file in C, say which are copied in A and or B and C (and where)
# Ghost-tools tries to be minimal about hitting the disk, but at a minimum,
# a duplicate requires that at some point GFS has to have a full SHA-1 match of the file.
# 
# Tells you where the duplicates are, and when they were last checked or verified
#
# foreach c (where size != 0)
# c->findDuplicates( $g );
# b->findDuplicates( $g );
# a->findDuplicates( $g );
# findDuplicates psucdocode
#    get ghost G for FN
#    find candidates - $fse->listAllFilesWithSize( $size )
#        lafby size, first time its called iterates over all FSE, hashing up sizes
#		 next, for each we do the test "$g->hasIdenticalContent($g)"
#		 	HIC first rules out size, then mod-date, then finally fullhash



sub doverb_lsdup()
{
	my $tk = TruthKeeper::get();

	my $target = pop @ARGV;

	my $targetFSE = new FilesystemExplorer();
	$targetFSE->setRoots( $target );
	my $targetIterator = $targetFSE->getIterator();

	my $sourceFSE = new FilesystemExplorer();
	$sourceFSE->setRoots( @ARGV );

	my $dup_count = 0;
	my $dup_size = 0;
	my $dup_size_interior = 0;
	my $dup_count_interior = 0;
	my $total_files = 0;

	my @report; 

	my $asWeGoPrint = 1;

	while( my $file = $targetIterator->next()  )
	{
		next unless -f $file;
		next if fileIsUsuallyIgnored( $file );

		$total_files++;

		# print "LSDUP - Iterated to lfn:[$file] - gathering data\n";

		my $g = $tk->obtainGhostForLFN($file);

		my @tdups = $targetFSE->findOtherDuplicates( $g );
		my @sdups = $sourceFSE->findOtherDuplicates( $g );

		#print "Verb LSDUP - Finding duplicates for: [$file]\n";
		#$g->printDebug();

		my $dupCount = @tdups + @sdups;

		if( $dupCount > 0 )
		{
			$dup_count_interior++;
		}

		if( $asWeGoPrint )
		{
			printf "[%3d]_________%s\n", $dupCount, $file;
		}

		if( @tdups > 0 )
		{	
			#print "    Duplicate in local tree: ($target)\n";

			foreach my $d (@tdups)
			{
				my $dfn = $d->lfn();

				print "      Target: $dfn\n" if $asWeGoPrint;
				$dup_count++;
				$dup_size += $d->getSize();
				$dup_size_interior += $d->getSize();
				# $d->printDebug();
			}
		}

		
		if( @sdups > 0 )
		{
			$dup_size_interior += $g->getSize();
			#print "    Duplicate in source trees (@ARGV):\n";
			foreach my $d (@sdups)
			{
				my $dfn = $d->lfn();

				print "      Source: $dfn\n" if $asWeGoPrint;
				$dup_count++;
				$dup_size += $d->getSize();
				# $d->printDebug();
			}
		}

		push @report, [$g, \@tdups, \@sdups];
	}

	print "Duplicate report: size X (target dups / source dups ) filename\n";

	foreach my $line (reverse sort { $a->[0]->getSize() <=>  $b->[0]->getSize() } @report )
	{
		my ($g, $tdups, $sdups ) = @$line;
		my $file = $g->lfn();
		my $size = $g->size();
		my $i = 0 + @$tdups;
		my $e = 0 + @$sdups;


		if( $i > 0 or $e > 0 or $OPT_ALL )
		{	
			print "$size X ($i/$e) $file \n";
		}
	}




	print "LSDup finished\n";
	print "I found $dup_count_interior files that were duplicated in target ($target),\n";
	print "when searching among the target plus source files: @ARGV\n";
	print "occupying $dup_size unnecessary space across the whole filesystem over $dup_count fules.\n";
	print "Within the target itself, this represents $dup_size_interior bytes.\n";
	print "There were $total_files in the target directory\n";



}

# Write the in place descriptors in each directory named

sub doverb_writeDescriptor()
{
	die "dead";
	my $store = GhostStore->new();

	my $fse = new FilesystemExplorer();
	$fse->setRoots( @ARGV );

	# sort of a lazy way to do it -- forces
	# a checksum computation, which should
	# populate the in place descriptors

	# a better way would be to enter each directory
	# and call some specific "build for x" function

	while( defined( my $file = $fse->next() ) )
	{
		print "Verb WD - Scanning: [$file]\n";

		if( -f $file )
		{
			$fse->forceGhostCharacterization( $file );
			my $fullHash = $fse->getFullHash( $file );
			print "Verb WD: fullhash = $fullHash\n";
		}
		else
		{
			print "Verb WD - Not a regular file: [$file]\n";
		}

	
	}
}

sub doverb_info()
{

	##################### BAD IMPLEMENTATION ------- KILL!!!
die();

	my $store = GhostStore->new();
	$store->slurpDescriptor( $DESCRIPTOR_FILENAME  );

	foreach my $lfn (@ARGV)
	{
		print( "Info request for: $lfn\n");
		my $g = Ghost->make( $lfn );
		my $h = $g->getFullHashForceHitDisk();
		print("    $h\n");

		$store->addGhost( $g );
	}	

	$store->writeAsDescriptor( $DESCRIPTOR_FILENAME );
}

sub getFullHashForceHitDisk($)
{
	my $lfn = shift;

	print "FULLHASH: $lfn\n";

	# TODO: examine use of stat
	$main::run_bytes_fullread += -s $lfn;

	my $START_GTOD = [gettimeofday];

	my $sha = Digest::SHA->new(1);
	$sha->addfile( $lfn );
	my $hexdigest = $sha->hexdigest();

	$main::run_files_fullread++;

	$main::run_time_fullread += tv_interval( $START_GTOD );

	return( "SHA1/FULL/$hexdigest");
}


# A hard ignore is a filename that we must pretend never existed
# it will not factor into any directory checksums

sub isHardIgnore
{
	my $fn = shift;

	my $b = basename $fn;	

	return 1 if $b =~ /$DESCRIPTOR_FILENAME$/;


	return 0;
}


##########
# The FSE class handles low level access and coherency for a particular
# domain of listed files. This could be a real file system or a snapshot
# or even a remote filesystem or S3 type thing.
# 
# I think this is the right definition for the class: 
#
# It provides the ability to iterate over the filesystem in an organized way.
# Everything that hits a primary resource should go here
# FSE is mainly called by the ghost API
# 
# Verbs i know it has to support
#
# - iteration
# - findDuplicates();
# - forceFullCharacterization();

package FilesystemExplorer;

use File::Basename;
use base qw(Class::Accessor);
FilesystemExplorer->mk_accessors( qw(topLevelLFNs sizeToFNs) );

my $fseDebug = 1;

# Return new FSE
# CORE - any FSE must implement

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();

	$self->sizeToFNs( undef );

	return $self;
}

# Return LFNs of immediate children
# CORE - any FSE must implement

sub getImmediateChildren
{
	my $self = shift;
	my $parent = shift;

	my $dir = $parent->lfn();

	print "FSE:ScanDIR into dir:[$dir]\n" if $fseDebug;

	#$dir =~ s/\/+$//;

	opendir DIR, $dir or die "cannot descend into [$dir] #!";

	$main::readdir_invokes++;

	# drop . and .., sort directory
	my @files = map {  main::canonize( File::Spec->catfile( $dir, $_ ) ) } 
		grep { !/^\.{1,2}$/ } 
		grep { !main::isHardIgnore( $_ ) } 
		sort { $a cmp $b } 
		readdir DIR;


	$main::readdir_entries += @files;

	print( "FSE:ScanDIR Returned: ", (join ':', @files ), "\n" ) if $fseDebug;

	close DIR;

	return @files;
}



sub loadSizeCache
{
	die "TODO No longer supported here - to remove";
	my $self = shift;

	my $h = {};
	my $tk = $self->tk();

	my $iterator = $self->getIterator();

	print "FSE-Generating size cache\n";

	while( my $file = $iterator->next() )
	{
		next unless -f $file;

		my $size = $tk->obtainGhostForLFN($file)->getSize();

		next if $size <= 0;

		print "FSE - Size Cache $file -> $size\n" if $fseDebug;

		push @{$h->{$size}}, $file;
	}


	$self->sizeToFNs($h);

}

sub findFilesWithSize
{
		die "TODO No longer supported here - to remove";

	my $self = shift;
	my $s = shift;

	return undef if( $s <= 0 );

	if( not defined $self->sizeToFNs() )
	{
		$self->loadSizeCache();
	}

	my $lu = $self->sizeToFNs()->{$s};

	return +() if not defined $lu;

	return ( @{$lu} );
}


# Returns files other than the one listed that are duplicates

sub findOtherDuplicates
{
		die "TODO No longer supported here - to remove";

	my $self = shift;
	my $g = shift;

	return grep { not $g->isSameFilename($_) } $self->findDuplicates($g);
}

# Returns a list of actual duplicates of the file
# may not actually hit the disk depending on what criteria
# of verification or recency you provide

sub findDuplicates
{
		die "TODO No longer supported here - to remove";

	my $self = shift;
	my $target = shift;

	# First, check our size cache for a match
	my $size = $target->getSize();

	return () if $size < 1; 

	my @otherFN = $self->findFilesWithSize( $size );

	return if @otherFN < 1;

	# print " -- Checking size duplicates size:[$size]\n";

	my @matches;

	foreach my $c ( @otherFN )
	{
		my $gc = $self->getGhost( $c );

		next if $gc->isSameFilename( $target );

		if( $fseDebug )
		{
			my $cFN = $gc->lfn();
			my $tFN = $target->lfn();

			print "     -- Checking size duplicates size:[$size]\n";
			print "     ---> cfn:[$cFN]\n";
			print "  vs ---> tfn:[$tFN]\n";
		}

		if( $target->isDuplicateOf( $gc ) )
		{
			push @matches, $gc;
		}
	}

	return @matches;
}

sub getGhost()
{
	die "TODO No longer supported here - to remove";



	my $self = shift;
	my $lfn = shift;

	# Todo - refactor - why wouldn't you always get ghosts from truthkeeper?
	# is there a reason to have this pass through?
	# or is the sematic here that a ghoststore may have unincorporated state?

	my $tk = TruthKeeper::get();

	# print "Checking getGhost (unusual case?) [$lfn]\n";

	my $g = $tk->obtainGhostForLFN( $lfn );

	return $g;

}

sub tk
{
		die "TODO No longer supported here - to remove";

	my $self = shift;
	return TruthKeeper::get();

}

# Forces all data about the ghost to be calculated present
# from a scan (e.g. hash, size, etc). Does not necessarily
# mean anything is read from disk unless some recovation rule
# is available

sub forceGhostCharacterization
{
	die "TODO No longer supported here - to remove";


	my $self = shift;
	my $lfn = shift;

	print "Force: [$lfn]\n";

	$self->tk->obtainGhostForLFN( $lfn )->forceCharacterization();
}

# Todo: Relocate this.

sub getFullHash()
{
		die "TODO No longer supported here - to remove";

	my $self = shift;
	my $lfn = shift;

	$self->tk->obtainGhostForLFN( $lfn )->getFullHash();

}

sub setRoots()
{
		die "TODO No longer supported here - to remove";

	my $self = shift;

	$self->topLevelLFNs( [@_] );

	foreach my $f ( @_ )
	{
		if( not -r $f )
		{		
			die "File [$f] is not a readable file or directory";
		}
	}
}

sub getIterator()
{
		die "TODO No longer supported here - to remove";

	my $self = shift;

	my $r = FilesystemIterator->new();
	$r->queue( [ @{$self->topLevelLFNs()} ] );

	return $r;
}


package TruthKeeper;

use Data::Dumper;
use File::Basename;
use base qw(Class::Accessor);

my $global_tk;

my %ghostForLFN_private;
my %ghostStoreForDescriptorLFN;

my $tkdebug = 1;

sub makeGhostsFromCommandLine
{
	my $self = shift;
	my @stuff = @_;

	my $gs = GhostStore->new();

	foreach my $lfn (@stuff )
	{
		print "Adding lfn:[$lfn] from command line to store\n";
		my $g = $self->obtainGhostForLFN($lfn);
		$gs->addGhost( $g );
	}

	return $gs;
}


sub ghostForLFN
{
	my $self = shift;
	return \%ghostForLFN_private;
}

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();
	# $self->ghostForLFN( +{} );
	return $self;
}

sub printInternallyTracked
{
	my $self = shift;
	my $ghostForLFN = $self->ghostForLFN();
	foreach my $g (values %$ghostForLFN )
	{
		print "   TKGhostDebug: ";
		print $g->printDebug();
		print "  ";
		print $g->dirty() ? "YES" : "NO";
		print "\n";

	}
	return;
}

sub flush
{
	my $self = shift;

#	print Dumper( $self );

	print "TK: Beginning flush ---\n";

	# $self->printInternallyTracked();

	print "TK: Ghost Cache Writes ---\n";

	$self->flushGhostDescriptorCache();

	print "TK: Verify ---\n";

	$self->verifyNoDirtyGhostsRemain();
}

sub get
{
	my $class = shift;

	return $global_tk if defined $global_tk;

	$global_tk = new TruthKeeper();

	return $global_tk;
}

sub verifyNoDirtyGhostsRemain
{
	my $self = shift;
	my $ghostForLFN = $self->ghostForLFN();

	my $error = 0;

	foreach my $g (values %$ghostForLFN )
	{
		if( 0 )
		{
			print "   Verifying TK Ghost: ";
			print $g->printDebug();
			print "  ";
			print $g->dirty() ? "YES" : "NO";
			print "\n";
		}	
		$error++ if $g->dirty();
	}

	die "Dirty ghosts remain unflushed!! assert" if $error > 0;
}

sub flushGhostDescriptorCache
{
	my $self = shift;

	foreach my $gslfn ( keys %ghostStoreForDescriptorLFN )
	{
		## my $gs = getGhostStoreForDescriptorFileCoveringFN( $k );

		$self->flushDescriptorToDisk( $gslfn );
	}
}

sub flushDescriptorToDisk
{
	my $self = shift;
	my $lfn = shift; # LFN of the ghoststore

	print "TK: Flushing ghoststore [$lfn] to disk\n" if $tkdebug;

	if( not exists $ghostStoreForDescriptorLFN{$lfn} )
	{
		die "Internal assert - $lfn not found" if $tkdebug;
	}

	my $gs = $ghostStoreForDescriptorLFN{$lfn};

	$gs->purifyAllGhostsToTK();

	if( $gs->countDirty() > 0 )
	{
		$gs->writeAsDescriptor( $lfn );
	}
	else
	{
		print "TK:   - Not needed, no dirty records\n" if $tkdebug;
	}

	map { $_->dirty(0) } $gs->getAllGhosts();

	delete $ghostStoreForDescriptorLFN{$lfn};

	return undef; 
}



sub getGhostDescriptorFileForLFN($)
{
	my $self = shift;
	my $filename = shift;

	# print "GDF: $filename\n";

	my( $fn, $dir ) = fileparse( $filename );

 	my $dfn = File::Spec->catfile($dir, $DESCRIPTOR_FILENAME);

 	# print "GDF [$dfn] for $filename\n";

	return $dfn;
}


sub getGhostStoreForDescriptorFileCoveringFN
{
	my $self = shift;
	my $lfn = shift;

	my $gsfn = $self->getGhostDescriptorFileForLFN( $lfn );

	if( exists $ghostStoreForDescriptorLFN{$gsfn} )
	{
		return( $ghostStoreForDescriptorLFN{$gsfn} );
	}
	else
	{

		# must revisit TODO - the point of this cache is that it shouldn't get too big
		# die "Overflow!" if ((keys %ghostStoreForDescriptorLFN) > 100);

		my $gs = GhostStore->new();

		if( -e $gsfn )
		{
			$gs->slurpDescriptor( $gsfn );
			$self->incorporateGhostStore( $gs );

			# TODO
			# to properly handle identification of deleted files,
			# the ghosts should be added as children to whatever the
			# parent is
		}

		$ghostStoreForDescriptorLFN{$gsfn} = $gs;

		return $gs;
	}
}




sub forceGhostCharacterization
{
	die "TODO - dead code - do not rely on GS to hold this anymore";


	my $self = shift;
	my $lfn = shift;

	# TODO: see notes for getFullHash

	# TODO error check that this path actual existing in the FSE!

	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN($lfn);
	print "TK - Searching for a fullhash for [$lfn]\n" if $tkdebug;
	my $g = $gs->findOrMakeGhostByLFN($lfn);
	my $h = $g->forceCharacterization();

	return $h;
}

# Caller wants the full hash
# Best place to get it is a descriptor file
# next best place to get it is to hit the disk

# TODO: This may need to be reimplemented - better way to handle
# could be to use a FSE specific ghost store and let some other
# mechanism actually trigger writing the in place files

sub getFullHash()
{
		die "TODO - dead code - do not rely on GS to hold this anymore";

	my $self = shift;
	my $lfn = shift;

	# TODO error check that this path actual existing in the FSE!

	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN($lfn);
	print "FSE - Searching for a fullhash for [$lfn]\n";
	my $g = $gs->findOrMakeGhostByLFN($lfn);
	my $h = $g->getFullHash();

	return $h;
}


sub incorporateGhostStore
{
	my $self = shift;
	my $gs = shift;

  # print Dumper( $self );

	my @g = $gs->getAllGhosts();
	foreach my $g (@g)
	{
		$self->incorporateGhostData( $g );
	}

  # print Dumper( $self );
}


sub incorporateGhostData
{
	my $self = shift;
	my $g = shift;

	my $icDebug = 0;

	my $ghostForLFN = $self->ghostForLFN();


	print "Incorporating ghost data $g (self=$self, glfn=$ghostForLFN)\n" if $icDebug;

	if( exists $ghostForLFN->{$g->lfn()} )
	{
		# merge case
		# take the best of both
		# prefer checksum from the newer one
		# use that for the date of the hash

		my $base = $ghostForLFN->{$g->lfn()};

		if( $base->lastFullHash() < $g->lastFullHash() )
		{
			$base->lastFullHash( $g->lastFullHash() );
			$base->fullHash( $g->fullHash() );
			$base->dirty(1);
			print "  Incorporate - Merger case - existing ghost updated\n" if $icDebug;
		}
		else
		{
			print "  Incorporate -  Merger case - existing ghost was fine\n"  if $icDebug;
		}

		$g->isTKversion(0);

		return $base; 
	}
	else
	{
		print "  Incorporate -  Merger case - new wins" if $icDebug;

		$ghostForLFN->{$g->lfn()} = $g;
		$g->isTKversion(1);
		return $g;
	}
}

# Normal logic to get a ghost -- first check if we have it already

sub obtainGhostForLFN
{
	my $self = shift;
	my $lfn = shift;

	die "LFN is zero length" if ((length $lfn) < 1);

	die "LFN is not a clean string!" if ref $lfn;

	print "TK:Obtain: obtain f:[$lfn] - requested\n" if $tkdebug;

	my $ghostForLFN = $self->ghostForLFN();

	main::assert_cpath( $lfn );

	if( exists $ghostForLFN->{$lfn} )
	{
		print "TK:Obtain: obtain f:[$lfn] - found in cache\n" if $tkdebug;
		return $ghostForLFN->{$lfn};		
	}

	# Next look for in global cache (if present)

	# TODO when time comes, implement global cache

	# Next look in local descriptor

	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN($lfn);
	my $g = $gs->findGhostForLFN($lfn);
	print "TK:Obtain: obtain f:[$lfn] pulled g:[$g] from ghost descriptor\n" if $tkdebug;
	return $g if( defined $g );

	# Wow, we've totally stuck out here - make a new thing

	print( "TK:Obtain: Making new ghost for f:[$lfn]\n")  if $tkdebug;
	my $g = Ghost->make_private( $lfn );
	$self->incorporateGhostData( $g );
	$g->dirty(1);
	$g->isTKversion(1);
	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN( $lfn );
	$gs->addGhost( $g );

	print "TK:Obtain: Made: $g\n" if $tkdebug;

	return $g;
}





##########
#
# FilesystemIterator -- A helper for iterating over nested directories
# Note: Does not use File::Find!
#
####

package GhostIterator;

use File::Basename;
use base qw(Class::Accessor);
GhostIterator->mk_accessors( qw(queue recurse parentGhoststore) );

my $GI_DEBUG = 1; 

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();
	$self->recurse(0);
	return $self;
}

# Gets the next item in the iterator
#
# Behind the scenes, will call nextRaw and handle things in the queue
# that are unexpected

sub next
{
	my $self = shift;
	my $n = $self->nextRaw();

	if( ref $n )
	{
		print "GI: THUNK received --> $$n\n" if $GI_DEBUG;
		return $self->next();
	}

	# Check for the end-of-queue case
	if( not defined $n )
	{
		print "GI iterator: Undef case - iterator over\n" if $GI_DEBUG;
		return undef;
	}

	print "Next: Got [$n]\n";

	my $tk = TruthKeeper::get();
	my $g = $tk->obtainGhostForLFN( $n );

	return $g;
}

# Internal helper function called when a directory needs to be expanded

sub scanDir
{
	my $self = shift;
	my $g = shift;
 	my $q = $self->queue();	

	# call getChildren
	# getChildren may have these buggers cached
	# caching should be weak
	# if not call up to TK and try to get from GCIP
	# if not FSM->getImmediateChildren;

	my @lfns = $g->getFSE()->getImmediateChildren( $g );

	$g->learnChildrenByLFN( @lfns );

	my @children = $g->getChildren();

 	unshift @$q, \$g;  # add the thunk that will tell us the directory is over
 	unshift @$q, @lfns; # add the files themselves



}

sub nextRaw
{
	my $self = shift;

	my $q = $self->queue();
	my $c = shift @$q;

	if( not defined $c )
	{
		return undef; 
	}

	if( ref $c )
	{
		return $c; 
	}

	# Todo - clean up passing of ghosts back up to parent
	# issue here is that the parentGhostStore only has the top
	# level parents.
	# my $gs = $self->parentGhoststore();
	# my $g = $gs->findGhostForLFN( $c );

	# TODO: two obtains are called, first to check for being a directory
	# second, by next. This could be refined by making the queue
	# able to store both ghosts and LFNs.

	my $tk = TruthKeeper::get();
	my $g = $tk->obtainGhostForLFN( $c);

	print "GI: Checking [$c]->[$g] for children\n" if $GI_DEBUG;

	# if the next thing is a directory, scan into the directory
	if( $g->canHaveChildren() )
	{
		print "GI: Scan directory case\n" if $GI_DEBUG;
		$self->scanDir( $g );
	}

	return $c;
}






##########
#
# GhostStore - utility functions for dealing with arbitrary collections
# of ghosts
#
####

package GhostStore;

use File::Basename;
use base qw(Class::Accessor);
GhostStore->mk_accessors( qw(lfnToGhost clean) );

my $gsDebug = 0;

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();
	$self->lfnToGhost( +{} );
	$self->clean(1);

	return $self;
}

sub getDescendingIterator
{
	my $self = shift;

	my $r = GhostIterator->new();
	$r->queue( [ keys %{$self->lfnToGhost()} ] );
	$r->recurse(1);
	$r->parentGhoststore( $self );
	return $r;
}

sub countDirty
{
	my $self = shift;

	my $i = 0;

	map {$i++ if $_->dirty() > 0 } $self->getAllGhosts();

	return $i;
}

sub findGhostForLFN
{
	my $self= shift;
	my $lfn = shift;

	my $lfnToGhost = $self->lfnToGhost();

	if(exists $lfnToGhost->{$lfn} )
	{
		print "   Found inside ghoststore\n" if $gsDebug;
 		return $lfnToGhost->{$lfn};
 	}

 	return undef;
}

sub purifyAllGhostsToTK
{
	my $self = shift;
	my $tk = TruthKeeper::get();
	my $lfnToGhost = $self->lfnToGhost();

	foreach my $g (values %$lfnToGhost)
	{
		if( $g->isTKversion() == 0 )
		{
			print "GhostStore: ***** PURIFY $g->lfn()\n" if $gsDebug;
			my $n = $tk->obtainGhostForLFN( $g->lfn );
			$lfnToGhost->{$n->lfn()} = $n;
		}
	}
}

sub getAllGhosts
{
	my $self = shift;
	my $lfnToGhost = $self->lfnToGhost();
	return values %$lfnToGhost;
}

sub addGhost($)
{
	my $self= shift;
	my $g = shift;

	my $lfn = $g->lfn();
	my $lfnToGhost = $self->lfnToGhost();

	print "GhostStore: Adding ghost $g (lfn=$lfn) (ltg=$lfnToGhost self=$self) ghoststore\n" if $gsDebug;

	if( exists $lfnToGhost->{$g->lfn()} )
	{
		die "GhostStore: Boundary case - adding ghost where one already existed" if $gsDebug;
	}

	$lfnToGhost->{$lfn} = $g; 

	return;
}

sub slurpDescriptor($)
{
	my $self = shift;
	my $fn = shift;

	print "GhostStore: Slurping descriptor [$fn]" if $gsDebug;

	my( $parsedFn, $dir ) = fileparse( $fn );

	my $treebase = $dir; 

	my %seen;

	open( FILE, "<$fn") or die "Cannot open $fn to read descriptor";

	while( <FILE> )
	{
		chomp;
		print "GhostStore: Slurping: [$_]\n" if $gsDebug;
		my $g = Ghost->newFromSerialized( $_, treeRoot => $treebase );
		$g->isTKversion(0);
		$self->addGhost( $g );

		die "Ghost descriptor contains duplicates - some logic problem - see [$fn]!" if( $seen{$g->lfn()}++ > 0 );
	}

	close( FILE );

	# At this point, our ghosts are not linked to the TK, they are just versions of possible truth

	$main::run_descriptors_read++;
}


sub writeAsDescriptor($)
{
	my $self = shift;
	my $fn = shift;

	my $lfnToGhost = $self->lfnToGhost();

	open( FILE, ">$fn") or die "Cannot open $fn to write descriptor";

	foreach my $g ( values %$lfnToGhost )
	{
		print FILE $g->serialize( pathMode => "basename");
		print FILE "\n";

		if( $gsDebug )
		{
			my $lfn = $g->lfn();
			print "    WAD: Write ($lfn):";
			print $g->serialize( pathMode => "basename");
			print "\n"
		}
	}

	close( FILE );

	print "    WAD: Wrote descriptor -> $fn\n" if $gsDebug;

	$main::run_descriptors_write++;
}


sub writeSnapshotToDisk
{
	my $self = shift;
	my $fn = shift;

	$self->writeSerializedToDisk( $fn, pathMode => 'localized' );
}

#  TODO combine codebase with descriptors

sub writeSerializedToDisk($)
{
	my $self = shift;
	my $fn = shift;
	my %options = shift;

	my $lfnToGhost = $self->lfnToGhost();

	open( FILE, ">$fn") or die "Cannot open $fn to write snapshot or descriptor";

	foreach my $g ( values %$lfnToGhost )
	{
		print FILE $g->serialize( %options );
		print FILE "\n";
	}

	close( FILE );

	print "Wrote snapshots -> $fn\n";
}


##########
#
# Ghost - an imprint of a file that may or may not exist at a particular place
#
# The ghost is a carrier of information about a file, and intended to be lightweight
# More than one ghost can exist for a given file, and they can be different
# to obtain an "authoritiative" ghost, the TruthKeeper is used to resolve them
# for instance a snapshot could have one version of a ghost, a descriptor a different
# and the one from the file system could yet again be different.


package Ghost;

use File::Basename;
use base qw(Class::Accessor);

# GHOST_NEW_FIELD: Place 4/4 where you add new fields to ghosts

Ghost->mk_accessors( qw(lfn lastFullHash size mode fullHash dirty isTKversion lastDirScan lastStat mtime children) );

my $serializeDebug = 0;

sub newFromSerialized($)
{
	my $class = shift;
	my $str = shift;
	my %options = @_;

	my $self = Ghost->new();

	my @a = split ':', $str;

	@a = map {main::gfs_unescape($_)} @a;

	my $serialLFN = shift @a;

	if( defined $options{'treeRoot'} )
	{
		my $root = $options{'treeRoot'};

		$serialLFN = File::Spec->catfile( $root , $serialLFN );
		$serialLFN = main::canonize( $serialLFN );
	}

	# GHOST_NEW_FIELD: Place 1/4 where you add new fields to ghosts

	$self->lfn( $serialLFN );
	$self->lastFullHash( shift @a );
	$self->size( shift @a );
	$self->mode( shift @a );
	$self->fullHash( shift @a );
	$self->lastDirScan( shift @a );
	$self->lastStat( shift @a );

	$self->dirty( 0 );
	$self->mtime( shift @a );
	$self->isTKversion( 0 );

	if( $serializeDebug )
	{
		print "Just deserialized: ";
		print $self->printDebug();
		print "\n";
	}	

	return $self;

}

# getFSE - returns whatever FSE object is best for this thing

sub getFSE
{
	return $main::localFileSystemFSE;
}

sub getChildren()
{
	my $self = shift;

	if( not defined $self->children() )
	{
		die "Corner case - someone didn't teach me my children";

	}


	if( not ref $self->children() )
	{
		die "Corner case - someone didn't teach me my children";

	}


	# TODO - should this be weak?
	# if so, how to handle orphans?
	return @{$self->children()};
}

# Caller is giving us a complete list of our children from primary source
# Mark the deleted ones and perform other flags

sub learnChildrenByLFN()
{
	my $self = shift;
	my @lfns = @_;

	my $tk = TruthKeeper::get();

	# Ideally, we call getChildren and do some sort of "merge"

	my @existingGhosts = ();

	@{$self->children()} if( defined $self->children() );

	my %seenLFN;
	my @newKids;

	map { $seenLFN{ $_->getLFN() } = 0 } @existingGhosts;

	foreach my $lfn ( @lfns )
	{
		print "G: Learning child: lfn:[$lfn]\n";
		if( exists $seenLFN{$lfn} )
		{
			print "G:   Child already registered\n";
		}

		$seenLFN{$lfn}++;

		my $g = $tk->obtainGhostForLFN( $lfn );
	
		# inform ghost that it has been seen in a directory scan
		# this also undeletes it
		$g->learnDirscan();
		push @newKids, $g;
	}

	foreach my $lfn ( keys %seenLFN )
	{
		if( $seenLFN{$lfn} < 1 )
		{
			print "G:   Child has disapeared\n";
			my $g = $self->tk()->obtainGhostForLFN( $lfn );
			$g->learnDeleted();
		}
	}

	$self->children( \@newKids );
}

# canHaveChildren() - True if we can descend with a call to "getChildren"

sub canHaveChildren
{
	my $self = shift;

	# print "Fetching type\n";

	my $type = $self->getType();

	# print "Type is: $type\n";

	# base case: no knowledge or hash

	if( $type eq 'd' )
	{
		return 1;
	}

	return 0;
}

sub printDebug
{
	my $self = shift;

	# GHOST_NEW_FIELD: Place 2/4 where you add new fields to ghosts

	my $lfn = $self->lfn();
	my $lastFullHash = $self->lastFullHash();
	my $size = $self->size();
	my $mode = $self->mode();
	my $fullHash = $self->fullHash();
	my $lastDirScan = $self->lastDirScan();
	my $lastStat = $self->lastStat();
	my $mtime = $self->mtime();

	# not technically a field but we should include this
	my $type = $self->getType();


	print "ghostDump: lfn:[$lfn] type:[$type] mode:[$mode] lFH:[$lastFullHash] full:[$fullHash] lds:[$lastDirScan] lstat:[$lastStat] size:[$size] mtime:[$mtime]\n";
}


use Cwd qw(abs_path);

sub isSameFilename
{
	my $self = shift;
	my $other = shift;

	my $fn1 = $self->lfn();
	my $fn2 = $other->lfn();


	# After some testing, it appears that abs_path (also see realpath(3)) 
	# is the very best way to test for complete filename equivilence
	# The testing read-out is below and turned off for now

	if( 0 )
	{
		print "Checking if two files are the same filename:\n";
		print "   me: [$fn1]\n";
		print "   tg: [$fn2]\n";
	  
	  	my $cwd1 = abs_path( $fn1 );
	  	my $cwd2 = abs_path( $fn2 );

	 	print "Using Cwd Abs_path:\n"; 
	  	print "   me: [$cwd1]\n";
		print "   tg: [$cwd2]\n";

	  	my $abs1 = File::Spec->rel2abs( $fn1 );
	  	my $abs2 = File::Spec->rel2abs( $fn2 );

	 	print "Using rel2abs:\n"; 
	  	print "   me: [$abs1]\n";
		print "   tg: [$abs2]\n";
	}

	die "Incomplete info self-size" if not defined $self->lfn();
	die "Incomplete info other-size" if not defined $other->lfn();

	# TODO: revisit if perl libraries give a better way to do this

	return 1 if $self->abspath() eq $other->abspath();
	return 0;
}

# Returns a fully cleaned up absolute path name for this file
# Initial testing has shown this handles foo/../../ properly, etc
# probably requires a ton of stats in cases where there are ..
# but doesn't appear to be too onerous for usual path names

sub abspath
{
	my $self = shift;
	return abs_path( $self->lfn() );

}

sub isDuplicateOf
{
	my $self = shift;
	my $other = shift;

#	die "Incomplete info self-size" if not defined $self->size();
#	die "Incomplete info other-size" if not defined $other->size();

	return 0 if( $self->getSize() ne $other->getSize() );

#    die "Incomplete info self full hash" if not defined $self->fullHash();
#	die "Incomplete info other full hash " if not defined $other->fullHash();


	return 0 if( $self->getFullHash() ne $other->getFullHash() );

	return 1; 
}

sub serialize()
{
	my $self = shift;
	my %options = @_;

	my $lfn = $self->lfn();

	#print "Serialize $self\n";

	if( $options{'pathMode'} eq 'basename' )
	{
			my( $fn, $dir ) = fileparse( $lfn );
			# print "    Serialization has truncated $lfn -> $fn (pathMode)\n";
			$lfn = $fn;

	}

	# GHOST_NEW_FIELD: Place 3/4 where you add new fields to ghosts

	my @s = ( $lfn, 
			  $self->lastFullHash(),
			  $self->size(),
			  $self->mode(),
			  $self->fullHash(),
			  $self->lastDirScan(),
			  $self->lastStat(),
			  $self->mtime()
			  );


	@s = map {main::gfs_escape($_)} @s;

	my $s = join ':', @s;

	return $s;
}

# as of refactor, only TK is really allowed to called this

sub make_private($)
{
	my $class = shift;
	my $lfn = shift;

	my $self = $class->new();

	main::assert_cpath( $lfn );

	# print "Ghost: Making ghost for lfn=[$lfn]\n";

	$self->lfn( $lfn );

	return $self;
}

sub make
{
	die "Assert - old code, warning!!";

}

# Forces the key fields to be loaded if they aren't already known
# Does not recheck them against the disk unless the standard

# TODO: implement size and fasthash

sub forceCharacterization
{
	my $self = shift;

	$self->getFullHash();
	$self->getSize();
	# $self->getFastHash();	
}

sub hasAcceptableFullhash
{
	my $self = shift;

#	print "Checking if I like my hash\n";

	return 0 if( not defined $self->fullHash() );
	
	if( defined $main::GUARD_TIME_SECONDS )
	{
		my $age = $main::SCRIPT_START - $self->lastFullHash();

		if( $age > $main::GUARD_TIME_SECONDS )
		{
			print "Forcing hash recalculation (", main::expressRelativeTime( $age ), ")\n";
			return 0; 
		}
	}

	return 1;
}

# returns an acceptable fullHash for the ghost
# Normally, the latest cached data is trusted, but
# this function can be set to take a out of data criteria in future TODO

sub getFullHash
{
	my $self = shift;

	if( $self->hasAcceptableFullhash() )
	{
		return $self->fullHash();
	}
	else
	{
		return $self->getFullHashForceHitDisk();
	}
}


sub hasAcceptableStat
{
	my $self = shift;

	return 0 if( not defined $self->size() );
	return 0 if( not defined $self->mtime() );

	if( defined $main::GUARD_TIME_SECONDS )
	{
		my $age = $main::SCRIPT_START - $self->lastStat();

		if( $age > $main::GUARD_TIME_SECONDS )
		{
			print "Forcing recalculation (", main::expressRelativeTime( $age ), ")\n";
			return 0; 
		}
	}


	return 1;
}




sub getMode
{
	my $self = shift;

	if( $self->hasAcceptableStat() )
	{
		return $self->mode();
	}
	else
	{
		$self->getStatForceHitDisk();
		return $self->mode();
	}	
}

sub getSize
{
	my $self = shift;

	if( $self->hasAcceptableStat() )
	{
		return $self->size();
	}
	else
	{
		$self->getStatForceHitDisk();
		return $self->size();
	}	
}

sub getMTime
{
	my $self = shift;

	if( $self->hasAcceptableStat() )
	{
		return $self->mtime();
	}
	else
	{
		$self->getStatForceHitDisk();
		return $self->mtime();
	}	
}

# Dirscan means that we have seen the ghost in a directory scan
# TODO also update a "firstSeen" field.
# If deleted, this should undelete by delegating to learnPresent

sub learnDirscan
{
	my $self = shift;

	$self->lastDirScan( time() );

	# TODO: Do we want a dirscan to always force an update to the ghost?
	# With this next line commented out, a new directory scan will not by itself
	# force an update
	# $self->dirty(1);

	$self->learnPresent();
}

# Should undelete the file

sub learnPresent
{
	# TODO: implement field
}

# Deleted means that we did not see the ghost
# on a recent scan. Mark as deleted and set deleteDate.

sub learnDeleted
{
	my $self = shift;

	$self->lastDirScan( time() );

	# TODO: Do we want a dirscan to always force an update to the ghost?
	$self->dirty(1);
}

sub getFullHashForceHitDisk
{
	my $self = shift;
	my $lfn = $self->lfn();

	die "Full hash not implemented for directories" if( $self->canHaveChildren() );

	$self->lastFullHash( time() );

 	my $fullhash = main::getFullHashForceHitDisk( $lfn );

	$self->fullHash( $fullhash );
	$self->dirty(1);

	return $fullhash;
}

use Fcntl ':mode';

sub extractTypeFromMode
{
	my $self = shift;
	my $mode = shift;

	return 'f' if S_ISREG($mode);
	return 'd' if S_ISDIR($mode);
}

sub getType
{
	my $self = shift;
	my $mode = $self->getMode();
	return $self->extractTypeFromMode( $mode );
}

sub getStatForceHitDisk
{
	my $self = shift;
	my $lfn = $self->lfn();

	print "STAT: $lfn\n";

	$main::run_files_stat++;

	my @statfields = stat($lfn);

	die "Ghost [$lfn] failed stat - probably doesn't exist" if( @statfields == 0 );

	my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size, $atime,$mtime,$ctime,$blksize,$blocks) = @statfields;
		 



	$self->size($size);
	$self->mtime($mtime);
	$self->mode($mode);

	$self->lastStat( time() );

	$self->dirty(1);

	return undef;
}


###

main::main();
exit();



