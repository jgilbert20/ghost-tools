#!/usr/bin/perl

use strict;

use Digest::SHA;
use File::Basename;
use File::Spec;

use File::Path;
use File::Copy; 

# Database Layer

use BerkeleyDB;
use BerkeleyDB::Hash;
use BerkeleyDB::Btree;

# Gives us tied access to databases

use MLDBM qw( BerkeleyDB::Hash Storable );

# Major globals

my $DESCRIPTOR_FILENAME = "00descriptor.gfs";
my $GENERAL_DEBUG = 1;


# Run statistics - globals

local $main::run_files_fullread = 0;
local $main::run_files_stat = 0;
local $main::run_descriptors_read = 0;
local $main::run_descriptors_write = 0;

# Get path to our WD

my $HOME = $ENV{HOME};
my $WDIR = "$HOME/.gfs";
my $DBDIR = "$WDIR/db";
my $EDIR = "$ENV{HOME}/.gfsrun/EXEC-$$";

# Key function prototypes
sub debug($);

# Helper function that creates a nested path with lots of error checking

sub mkdirs
{
    my $dir = shift;
    my $dirx = dirname $dir;

    print "MKDIRS:[$dirx]\n";

    eval{ mkpath($dirx,1) };
    $@ and die "Couldn't create dir path: $@";
    die "Did not find new path" if not -d $dirx;

   return 1;
}

# Verifies readability of various directories needed for program invocation

sub verifyWorkingDirectories
{
	if( not -e $WDIR )
	{
	    mkdir $WDIR or die "Error creating [$WDIR]: $!";
	}

	if( not -e $DBDIR )
	{
	    mkdir $DBDIR or die "Error creating [$DBDIR]: $!";
	}

	if( not -e $EDIR )
	{
	    mkdirs($EDIR . "/") or die "Error creating [$EDIR]: $!";
	}

	die "Cannot create $WDIR" unless -w $WDIR;
	die "Cannot create $DBDIR" unless -w $DBDIR;
}

# Sets up our data

sub setupDatabases
{
	my $bdb_env = new BerkeleyDB::Env 
	    -Verbose => 1,
	    -Home => $DBDIR,
	    -Flags => DB_CREATE|DB_INIT_MPOOL|DB_INIT_CDB,
	    -ErrFile => "$DBDIR/Errors-$$",
	    -ErrPrefix => "GFS";
}


sub debug ($)
{
	return if not $GENERAL_DEBUG;
	my $a = shift @_;
	chomp $a;
	print "DEBUG_LINE: " . $a . "\n";
}


sub init
{
	verifyWorkingDirectories();
	setupDatabases();
}



# test cases:
# snapshot directories both a/* and a/ and a

# insight: we could have an entry for a directory.. the last full time it was scanned
# then if the read date of the file is earlier than the scan date of the directory
# then we know the file may be stale and can delete it



# how do we stick virtual things into the hash?
# for instance, where or how do we store the idea that a .tar file has certain contents
# or that an rsync directory (jgilbert@auspice.net:a/b/c) contains a file?
# almost like a normal path a/b/c is basically an implicit "local:a/b/c"..
# the local handler knows to write .gfs_info files
# whereas the remote one knows not to
# each FS type offeres a get, move, copy, retrieve full checksum, stat, etc function
# so now we can handle S3, Rsync, etc

# how does that tie in with tags?
# how do I say anything under /Volume/Foo should be addressed as FOODRIVE:
# clearly this only matters during AFN conversion
# disktag:FOODRIVE|/one/two/three
#
# if that is the AFN recorded, then the system will think that is there
# we just need to write a record like /Volume/Foo -> FOODRIVE
# and also write a /Volume/Foo/GFS_ID.txt file
# then a dereference just requires that we verify that the /Volume/Foo/GFS_ID can still be reached
# maybe there is a tool like "bless" which does this for you
# so the rel->AFN conversion would either need to rely on this mapping
# or traverse back up to make sure that all ../GFS_ID.txt files were registered

# is a snapshot treated as a file collection as a target? if it is, we have to emphasize 
# that it is a ghost. e.g. you can enumerate, but the fact that snapshot:4444/sdf contains
# this file version could never be used as a proxy.
# so when you "get all AFNs for hash", you'd have to pass to a FShandler for the snapshot

# GFS is an overlay snapshoting and directory reconstruction tool. Its not really meant 
# for version control, but managing someone's life which may be scattered 
# across many different asset types and locations.
# GFS is entirely built around command line tools. It doesn't watch the filesystem
# for changes.
# key features
# 1) highly accelerated content-aware rsync - a file is never retransmitted unless needed
# 2) worried you still wantt o eb sure you have a backup of a wedding photos? 
#     this has tools that let you flag and manage bit-rot and verify your stuff is where
#     you think it is
# 3) work with large file trees both on a desktop and laptop? GFS can tell you instantly
#     which chnages you've made on your laptop that are not yet on your desktop and push them
#     to the desktop efficiently
# 4) in the field and want to be sure files you are working on are protected?
#     GFS can make sure any file is either in your dropbox, on your machine at home
# 5) trying to free up space on your laptop? do you have a copy of that big 10 GB ISO file
#     at home? find out quickly if you can ditch it. 



# Database layer use cases
# 1) quickly give me ghost information for a path
#      AFN -> GhostSerialized as absolute
# 2) quickly give me the AFNs associated with a hash or size
#      hash -> AFN 0..n   (needed for LSDup)
#	   size -> AFN 0..n   (also possibly needed for LSDup)

# so when something is stored in location X or found in location X, 
# what permanent record is created?
# maybe we create spontaneous snapshot records that can be loaded back in?
#
#    gfs rsync /source jgilbert@asdf:foobar/
# 
# All files written to foobar drops a file in .gfs/receipts/rsync-$$-date.snapshot
# With the note: "This snapshot record was written by GFS on date XXXX"

sub main()
{
	print "Welcome to Ghost.\n";

	init();

	my $tk = TruthKeeper::get();

	my $verb = shift @ARGV;

	print " Verb = [$verb]\n";

	if( $verb eq "info" )
	{
		doverb_info();
	}


	# reconstruct-test A B C
	#   makes sure that everything in A and B be reconstructed in target C
	#   as long as there is at least one valid duplicate, we move on
	# 			first, best approach is to look for hashed AFN
	#			       ask FSE if it "owns" that file
	#				   then call "hasIdenticalContent()"
	#               if that doens't work, check the cache of sizes
	#					call hasIdenticalContent
	#                  as soon as one returns "hasIdenticalContent", we return
	#               finally, force the full cache of sizes

	# copy-delta A B C
	#    Anything in A and B that is not in C is going to get copied over 
	#	 into a "delta" directory

	# rsync A B C
	#	 C is reconfigured to look exactly like A and B. Files that no longer
	#    belong can be identified and removed as an option.
	#	 this works by MOVING files around inside of C. depending on how
	#    slashes are used, we either merge or replace (rsync ffo/ behavior)
	#    $fse->move( a, b );
	#			the move tool has to move the ghosts too
	# 			and that may invalidate certain descriptor files
	
	# what is the means by whcih deleted files are recongized?
	# in cases of a full scan, someone has to be smart enough
	# to know we are doing a scan that is "full" enough to count,
	# and to mark ghosts for deletion

	# right now, there is no stat verification when writing a snapshot
	#  snapshot -verify-stat (can find it, size and lastmod match) --verify-hash
	# and when those things are in place, anthing that hasn't been checked in the last 24 hours
	# are rejected, unless you say --hit-disk which means basically ignore all of the 
	# tools and recheck everything
	
	if( $verb eq "dbtest" )
	{

		my $fse = new FilesystemExplorer();
		$fse->setRoots( @ARGV );

		while( defined( my $file = $fse->next() ) )
		{
			print "DBTest - Scanning: [$file]\n";
		}	

	}	


	if( $verb eq "lsdup")
	{
		doverb_lsdup();
	}




	# LS tells us what we can find out about the current directory tree
	# nothing is force read. there is a dirscan and that is it.

	if( $verb eq "ls" )
	{
		doverb_ls();
	}

	# Writes a permanent file of this entire tree

	if( $verb eq "write-snapshot")
	{
		doverb_writeSnapshot();
	}

	# Takes the listed things and writes a single descriptor file

	if( $verb eq "write-descriptor")
	{
		doverb_writeDescriptor();
	}

	# Basically a test verb used to prove that serialization and deserialization are identical

	if( $verb eq "copyDescriptor" )
	{
		my $src = shift @ARGV;
		my $d = shift @ARGV;

		my $store = GhostStore->new();
		$store->slurpDescriptor( $src);
		$store->writeAsDescriptor( $d );
	}

	$tk->flush();

	print "----- DONE -----\n";

	print "Full reads: $main::run_files_fullread\n";
	print "Full reads: $main::run_files_stat\n";
	print "Desc reads: $main::run_descriptors_read\n";
	print "Desc wrtes: $main::run_descriptors_write\n";

	
}


sub doverb_writeSnapshot()
{
	my $store = GhostStore->new();

	my $fse = new FilesystemExplorer();
	$fse->setRoots( @ARGV );

	while( defined( my $file = $fse->next() ) )
	{
		print "SnapshotGen - Scanning: [$file]\n";

		if( -f $file )
		{
			$fse->forceGhostCharacterization( $file );
			my $g = $fse->getGhost( $file );
			$store->addGhost( $g );
		}
		else
		{
			print "SnapshotGen - Skipping non-file [$file]\n";
		}
	}	

	$store->writeSnapshotToDisk( "snapshot-$$.out");
}

# GFS relies on all paths being canonicalized so that
# text matching occurs properly.
# Otherwise ./foo and foo will not text match and it will appear
# like they are different files. Any routines that brings in a "net new"
# path to the system should convert it to a cpath.

sub assert_cpath($)
{
	my $lfn = shift;
	my $clfn = File::Spec->canonpath( $lfn );
	die "$lfn ne $clfn" if $lfn ne $clfn; 
}

sub canonize($)
{
	my $lfn = shift;
	my $clfn = File::Spec->canonpath( $lfn );

	# print "Canonicalize: $lfn ---> $clfn\n";	

	return $clfn;
}


# for each item listed, shows what we know about it -- no recursion, no forced characterization

sub doverb_ls()
{
	my $tk = TruthKeeper::get();
	foreach my $lfn (@ARGV)
	{
		$lfn = canonize($lfn);
		my $g = $tk->obtainGhostForLFN($lfn);

		my $fullHash = $g->fullHash();
		my $lastFullHash = $g->lastFullHash();

		print "Filename:[$lfn] fullH:[$fullHash] lastH:[$lastFullHash]\n";
	}

}


	# Lsdup: A B C - for every file in C, say which are copied in A and or B and C (and where)
	# foreach c (where size != 0)
	# c->findDuplicate( $g );
	# b->findDuplicate( $g );
	# a->findDuplicate( $g );
	# findDuplicate psucdocode
	#    get ghost G for FN
	#    find candidates - $fse->listAllFilesWithSize( $size )
	#        lafby size, first time its called iterates over all FSE, hashing up sizes
	#		 next, for each we do the test "$g->hasIdenticalContent($g)"
	#		 	HIC first rules out size, then mod-date, then finally fullhash



sub doverb_lsdup()
{
	my $tk = TruthKeeper::get();

	my $target = pop @ARGV;


	my $targetFSE = new FilesystemExplorer();
	$targetFSE->setRoots( $target );

	my $sourceFSE = new FilesystemExplorer();
	$sourceFSE->setRoots( @ARGV );

	while( defined( my $file = $targetFSE->next() ) )
	{
		print "Verb LSDUP - Finding duplicates for: [$file]\n";

	


	}

}

# Write the in place descriptors in each directory named

sub doverb_writeDescriptor()
{
	my $store = GhostStore->new();

	my $fse = new FilesystemExplorer();
	$fse->setRoots( @ARGV );

	# sort of a lazy way to do it -- forces
	# a checksum computation, which should
	# populate the in place descriptors

	# a better way would be to enter each directory
	# and call some specific "build for x" function

	while( defined( my $file = $fse->next() ) )
	{
		print "Verb WD - Scanning: [$file]\n";

		if( -f $file )
		{
			$fse->forceGhostCharacterization( $file );
			my $fullHash = $fse->getFullHash( $file );
			print "Verb WD: fullhash = $fullHash\n";
		}
		else
		{
			print "Verb WD - Not a regular file: [$file]\n";
		}

	
	}
}

sub doverb_info()
{
	my $store = GhostStore->new();
	$store->slurpDescriptor( $DESCRIPTOR_FILENAME  );

	foreach my $lfn (@ARGV)
	{
		print( "Info request for: $lfn\n");
		my $g = Ghost->make( $lfn );
		my $h = $g->getFullHashForceHitDisk();
		print("    $h\n");

		$store->addGhost( $g );
	}	

	$store->writeAsDescriptor( $DESCRIPTOR_FILENAME );
}

sub getFullHashForceHitDisk($)
{
	## TODO - implement without full slurp

	my $lfn = shift;

	print "FULLHASH: $lfn\n";

	my $sha = Digest::SHA->new(1);
	$sha->addfile( $lfn );
	my $hexdigest = $sha->hexdigest();

	$main::run_files_fullread++;

	return( "SHA1/FULL/$hexdigest");
}

package FilesystemExplorer;

use File::Basename;
use base qw(Class::Accessor);
FilesystemExplorer->mk_accessors( qw(topLevelLFNs queue) );

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();

	return $self;
}

sub getGhost()
{
	my $self = shift;
	my $lfn = shift;

	# TODO the primary ghost should probably not be the descriptors ghost, right?
	# Probably have to refactor this somehow

	my $tk = TruthKeeper::get();

	my $g = $tk->obtainGhostForLFN( $lfn );

	return $g;

}

sub tk
{
	my $self = shift;
	return TruthKeeper::get();

}

# Forces all data about the ghost to be calculated present
# from a scan (e.g. hash, size, etc). Does not necessarily
# mean anything is read from disk unless some recovation rule
# is available

sub forceGhostCharacterization
{
	my $self = shift;
	my $lfn = shift;

	$self->tk->obtainGhostForLFN( $lfn )->forceCharacterization();
}

sub getFullHash()
{
	my $self = shift;
	my $lfn = shift;

	$self->tk->obtainGhostForLFN( $lfn )->getFullHash();

}

sub setRoots()
{
	my $self = shift;

	$self->topLevelLFNs( [@_] );
	$self->queue( [@_] );

	foreach my $f ( @_ )
	{
		if( not -r $f )
		{		
			die "File [$f] is not a readable file or directory"
		}
	}
}


sub scanDir
{
	my $self = shift;
	my $dir = shift;

	my $q = $self->queue();	

	print "FSE:ScanDIR into $dir\n";

	#$dir =~ s/\/+$//;

	opendir DIR, $dir;

	# drop . and .., sort directory
	my @files = map {  main::canonize( File::Spec->catfile( $dir, $_ ) ) } grep { !/^\.{1,2}$/ } sort { $a cmp $b } readdir DIR;

	print( "FSE:ScanDIR Returned: ", (join ':', @files ), "\n" );

	close DIR;

	unshift @$q, \$dir;
	unshift @$q, @files;
	
}


# returns the next directory

sub next
{
	my $self = shift;

	my $n = $self->nextRaw();

	if( ref $n )
	{
		print "THUNK received --> $$n\n";

		# TODO case: 
		# in this case, we have just exited a directory -- may want
		# to purge any contents of descriptors that weren't found

		return $self->next();
	}

	# Check for the end-of-queue case

	if( not defined $n )
	{
		return undef;
	}

	# Now make sure that this isn't something we need to ignore

	
	my( $fn, $dir ) = fileparse( $n );
 	
	# print " FSE::getNext() checking [$n] -> [$fn]\n";

	if( $fn eq $DESCRIPTOR_FILENAME )
	{
		print " FSE/next -> skipping descriptor [$fn]\n";
		return $self->next();
	}
	return $n;
}


sub nextRaw
{
	my $self = shift;

	my $q = $self->queue();
	my $c = shift @$q;

	if( not defined $c )
	{
		return undef; 
	}

	#  print "Got[$c]\n";

	# if the next thing is a directory, scan into the directory
	if( -d $c )
	{
		$self->scanDir( $c );
	}

	return $c;
}

package TruthKeeper;

use Data::Dumper;
use File::Basename;
use base qw(Class::Accessor);

# TruthKeeper->mk_accessors( qw(ghostForLFN) );

my $global_tk;

my %ghostForLFN_private;


sub ghostForLFN
{
	my $self = shift;
	return \%ghostForLFN_private;
}

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();
	# $self->ghostForLFN( +{} );
	return $self;
}

sub printInternallyTracked
{
	my $self = shift;
	my $ghostForLFN = $self->ghostForLFN();
	foreach my $g (values %$ghostForLFN )
	{
		print "   TKGhostDebug: ";
		print $g->printDebug();
		print "  ";
		print $g->dirty() ? "YES" : "NO";
		print "\n";

	}
	return;
}

sub flush
{
	my $self = shift;

#	print Dumper( $self );

	print "TK: Beginning flush ---\n";

	# $self->printInternallyTracked();

	print "TK: Ghost Cache Writes ---\n";

	$self->flushGhostDescriptorCache();

	print "TK: Verify ---\n";

	$self->verifyNoDirtyGhostsRemain();
}

sub get
{
	my $class = shift;

	return $global_tk if defined $global_tk;

	$global_tk = new TruthKeeper();

	return $global_tk;
}

sub verifyNoDirtyGhostsRemain
{
	my $self = shift;
	my $ghostForLFN = $self->ghostForLFN();

	my $error = 0;

	foreach my $g (values %$ghostForLFN )
	{
		if( 0 )
		{
			print "   Verifying TK Ghost: ";
			print $g->printDebug();
			print "  ";
			print $g->dirty() ? "YES" : "NO";
			print "\n";
		}	
		$error++ if $g->dirty();
	}

	die "Dirty ghosts remain unflushed!! assert" if $error > 0;
}



my %ghostStoreForDescriptorLFN;
my $tkdebug = 0;

sub flushGhostDescriptorCache
{
	my $self = shift;

	foreach my $gslfn ( keys %ghostStoreForDescriptorLFN )
	{
		
		## my $gs = getGhostStoreForDescriptorFileCoveringFN( $k );

		$self->flushDescriptorToDisk( $gslfn );
	}
}

sub flushDescriptorToDisk
{
	my $self = shift;
	my $lfn = shift; # LFN of the ghoststore

	print "TK: Flushing ghoststore [$lfn] to disk\n" if $tkdebug;

	if( not exists $ghostStoreForDescriptorLFN{$lfn} )
	{
		die "Internal assert - $lfn not found" if $tkdebug;
	}

	my $gs = $ghostStoreForDescriptorLFN{$lfn};

	$gs->purifyAllGhostsToTK();

	if( $gs->countDirty() > 0 )
	{
		$gs->writeAsDescriptor( $lfn );
	}
	else
	{
		print "TK:   - Not needed, no dirty records\n" if $tkdebug;
	}

	map { $_->dirty(0) } $gs->getAllGhosts();

	delete $ghostStoreForDescriptorLFN{$lfn};

	return undef; 
}



sub getGhostDescriptorFileForLFN($)
{
	my $self = shift;
	my $filename = shift;

	my( $fn, $dir ) = fileparse( $filename );

 	my $dfn = File::Spec->catfile($dir, $DESCRIPTOR_FILENAME);

 	# print "GDF [$dfn] for $filename\n";

	return $dfn;
}


sub getGhostStoreForDescriptorFileCoveringFN
{
	my $self = shift;
	my $lfn = shift;

	my $gsfn = $self->getGhostDescriptorFileForLFN( $lfn );

	if( exists $ghostStoreForDescriptorLFN{$gsfn} )
	{
		return( $ghostStoreForDescriptorLFN{$gsfn} );
	}
	else
	{
		die "Overflow!" if ((keys %ghostStoreForDescriptorLFN) > 100);

		my $gs = GhostStore->new();

		if( -e $gsfn )
		{
			$gs->slurpDescriptor( $gsfn );
			$self->incorporateGhostStore( $gs );
		}

		$ghostStoreForDescriptorLFN{$gsfn} = $gs;

		return $gs;
	}
}


# Forces all data about the ghost to be calculated present
# from a scan (e.g. hash, size, etc). Does not necessarily
# mean anything is read from disk unless some recovation rule
# is available

sub forceGhostCharacterization
{
	my $self = shift;
	my $lfn = shift;

	# TODO: see notes for getFullHash

	# TODO error check that this path actual existing in the FSE!

	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN($lfn);
	print "TK - Searching for a fullhash for [$lfn]\n" if $tkdebug;
	my $g = $gs->findOrMakeGhostByLFN($lfn);
	my $h = $g->forceCharacterization();

	return $h;
}

# Caller wants the full hash
# Best place to get it is a descriptor file
# next best place to get it is to hit the disk

# TODO: This may need to be reimplemented - better way to handle
# could be to use a FSE specific ghost store and let some other
# mechanism actually trigger writing the in place files

sub getFullHash()
{
	my $self = shift;
	my $lfn = shift;

	# TODO error check that this path actual existing in the FSE!

	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN($lfn);
	print "FSE - Searching for a fullhash for [$lfn]\n";
	my $g = $gs->findOrMakeGhostByLFN($lfn);
	my $h = $g->getFullHash();

	return $h;
}


sub incorporateGhostStore
{
	my $self = shift;
	my $gs = shift;



  # print Dumper( $self );

	my @g = $gs->getAllGhosts();
	foreach my $g (@g)
	{
		$self->incorporateGhostData( $g );
	}

  # print Dumper( $self );
}


sub incorporateGhostData
{
	my $self = shift;
	my $g = shift;

	my $icDebug = 0;

	my $ghostForLFN = $self->ghostForLFN();


	print "Incorporating ghost data $g (self=$self, glfn=$ghostForLFN)\n" if $icDebug;

	if( exists $ghostForLFN->{$g->lfn()} )
	{
		# merge case
		# take the best of both
		# prefer checksum from the newer one
		# use that for the date of the hash

		my $base = $ghostForLFN->{$g->lfn()};

		if( $base->lastFullHash() < $g->lastFullHash() )
		{
			$base->lastFullHash( $g->lastFullHash() );
			$base->fullHash( $g->fullHash() );
			$base->dirty(1);
			print "  Incorporate - Merger case - existing ghost updated\n" if $icDebug;
		}
		else
		{
			print "  Incorporate -  Merger case - existing ghost was fine\n"  if $icDebug;
		}

		$g->isTKversion(0);

		return $base; 
	}
	else
	{
		print "  Incorporate -  Merger case - new wins" if $icDebug;

		$ghostForLFN->{$g->lfn()} = $g;
		$g->isTKversion(1);
		return $g;
	}
}

# Normal logic to get a ghost -- first check if we have it already

sub obtainGhostForLFN
{
	my $self = shift;
	my $lfn = shift;
	my $ghostForLFN = $self->ghostForLFN();

	main::assert_cpath( $lfn );

	if( exists $ghostForLFN->{$lfn} )
	{
		return $ghostForLFN->{$lfn};		
	}

	# Next look for in global cache (if present)

	# TODO when time comes, implement global cache

	# Next look in local descriptor

	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN($lfn);
	my $g = $gs->findGhostForLFN($lfn);
	print "TK:Obtain: obtain [$lfn] pulled [$g] from ghost descriptor\n" if $tkdebug;
	return $g if( defined $g );

	# Wow, we've totally stuck out here - make a new thing

	print( "TK:Obtain: Making new ghost for $lfn\n")  if $tkdebug;
	my $g = Ghost->make( $lfn );
	$self->incorporateGhostData( $g );
	$g->dirty(1);
	$g->isTKversion(1);
	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN( $lfn );
	$gs->addGhost( $g );

	print "TK:Obtain: Made: $g\n" if $tkdebug;

	return $g;
}



package GhostStore;

use File::Basename;
use base qw(Class::Accessor);
GhostStore->mk_accessors( qw(lfnToGhost clean) );

my $gsDebug = 0;

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();
	$self->lfnToGhost( +{} );
	$self->clean(1);

	return $self;
}

sub countDirty
{
	my $self = shift;

	my $i = 0;

	map {$i++ if $_->dirty() > 0 } $self->getAllGhosts();

	return $i;
}

# sub findOrMakeGhostByLFN
# {
# 	my $self = shift;
# 	my $lfn = shift;

# 	my $lfnToGhost = $self->lfnToGhost();


# 	print "Looking for ghost [$lfn]\n";

# 	if( exists $lfnToGhost->{$lfn} )
# 	{
# 		print "   Found inside ghoststore\n";
# 		return  $lfnToGhost->{$lfn};
# 	}
# 	else
# 	{

# 		print( "   Making new ghost for $lfn\n");
# 		my $g = Ghost->make( $lfn );

# 		$self->addGhost( $g );
# 		return $g;
# 	}
# }

sub findGhostForLFN
{
	my $self= shift;
	my $lfn = shift;

	my $lfnToGhost = $self->lfnToGhost();

	if(exists $lfnToGhost->{$lfn} )
	{
		print "   Found inside ghoststore\n" if $gsDebug;
 		return $lfnToGhost->{$lfn};
 	}

 	return undef;
}

sub purifyAllGhostsToTK
{
	my $self = shift;
	my $tk = TruthKeeper::get();
	my $lfnToGhost = $self->lfnToGhost();

	foreach my $g (values %$lfnToGhost)
	{
		if( $g->isTKversion() == 0 )
		{
			print "GhostStore: ***** PURIFY $g->lfn()\n" if $gsDebug;
			my $n = $tk->obtainGhostForLFN( $g->lfn );
			$lfnToGhost->{$n->lfn()} = $n;

		}

	}


}

sub getAllGhosts
{
	my $self = shift;
	my $lfnToGhost = $self->lfnToGhost();
	return values %$lfnToGhost;
}

sub addGhost($)
{
	my $self= shift;
	my $g = shift;

	my $lfn = $g->lfn();
	my $lfnToGhost = $self->lfnToGhost();

	print "GhostStore: Adding ghost $g (lfn=$lfn) (ltg=$lfnToGhost self=$self) ghoststore\n" if $gsDebug;

	# Do the incorporation here
	# the major caching form is by localname which is assumed to be unique
	# there should only be one ghost per LFN

	if( exists $lfnToGhost->{$g->lfn()} )
	{
		die "GhostStore: Boundary case - adding ghost where one already existed" if $gsDebug;
	}

	$lfnToGhost->{$lfn} = $g; 

	return;
}

sub slurpDescriptor($)
{
	my $self = shift;
	my $fn = shift;

	print "GhostStore: Slurping descriptor [$fn]" if $gsDebug;

	my( $parsedFn, $dir ) = fileparse( $fn );

	my $treebase = $dir; 

	my %seen;

	open( FILE, "<$fn") or die "Cannot open $fn to read descriptor";

	while( <FILE> )
	{
		chomp;
		print "GhostStore: Slurping: [$_]\n" if $gsDebug;
		my $g = Ghost->newFromSerialized( $_, treeRoot => $treebase );
		$g->isTKversion(0);
		$self->addGhost( $g );

		die "Ghost descriptor contains duplicates - some logic problem!" if( $seen{$g->lfn()}++ > 0 );
	}

	close( FILE );

	# At this point, our ghosts are not linked to the TK, they are just versions of possible truth

	$main::run_descriptors_read++;
}


sub writeAsDescriptor($)
{
	my $self = shift;
	my $fn = shift;

	my $lfnToGhost = $self->lfnToGhost();

	open( FILE, ">$fn") or die "Cannot open $fn to write descriptor";

	foreach my $g ( values %$lfnToGhost )
	{
		print FILE $g->serialize( pathMode => "basename");
		print FILE "\n";

		if( $gsDebug )
		{
			my $lfn = $g->lfn();
			print "    WAD: Write ($lfn):";
			print $g->serialize( pathMode => "basename");
			print "\n"
		}
	}

	close( FILE );

	print "    WAD: Wrote descriptor -> $fn\n" if $gsDebug;

	$main::run_descriptors_write++;
}


sub writeSnapshotToDisk
{
	my $self = shift;
	my $fn = shift;

	$self->writeSerializedToDisk( $fn, pathMode => 'localized' );
}

#  TODO combine codebase with descriptors

sub writeSerializedToDisk($)
{
	my $self = shift;
	my $fn = shift;
	my %options = shift;

	my $lfnToGhost = $self->lfnToGhost();

	open( FILE, ">$fn") or die "Cannot open $fn to write snapshot or descriptor";

	foreach my $g ( values %$lfnToGhost )
	{
		print FILE $g->serialize( %options );
		print FILE "\n";
	}

	close( FILE );

	print "Wrote snapshots -> $fn\n";
}



package Ghost;

use File::Basename;
use base qw(Class::Accessor);
Ghost->mk_accessors( qw(lfn lastFullHash size fullHash dirty isTKversion lastDirScan lastStat mtime) );

my $serializeDebug = 0;

sub newFromSerialized($)
{
	my $class = shift;
	my $str = shift;
	my %options = @_;

	my $self = Ghost->new();

	# TODO: Add proper escapes (String::Escape has nice examples)

	my @a = split ':', $str;

	my $serialLFN = shift @a;

	if( defined $options{'treeRoot'} )
	{
		my $root = $options{'treeRoot'};

		$serialLFN = File::Spec->catfile( $root , $serialLFN );
		$serialLFN = main::canonize( $serialLFN );
	}

	$self->lfn( $serialLFN );
	$self->lastFullHash( shift @a );
	$self->size( shift @a );
	$self->fullHash( shift @a );
	$self->lastDirScan( shift @a );
	$self->lastStat( shift @a );
	$self->mtime( shift @a );

	$self->dirty( 0 );
	$self->isTKversion( 0 );

	if( $serializeDebug )
	{
		print "Just deserialized: ";
		print $self->printDebug();
		print "\n";
	}	

	return $self;

}

sub printDebug
{
	my $self = shift;

	my $lfn = $self->lfn();
	my $lastFullHash = $self->lastFullHash();
		my $size = $self->size();

	my $fullHash = $self->fullHash();
	my $lastDirScan = $self->lastDirScan();
	my $lastStat = $self->lastStat();
	my $mtime = $self->mtime();


	print "GhostDebug: lfn:[$lfn] lFH:[$lastFullHash] full:[$fullHash] lds:[$lastDirScan] lstat:[$lastStat] size:[$size] mtime:[$mtime]\n";

}

sub serialize()
{
	my $self = shift;
	my %options = @_;

	my $lfn = $self->lfn();

	#print "Serialize $self\n";

	if( $options{'pathMode'} eq 'basename' )
	{
			my( $fn, $dir ) = fileparse( $lfn );
			# print "    Serialization has truncated $lfn -> $fn (pathMode)\n";
			$lfn = $fn;

	}

	# TODO: Add proper escapes (String::Escape has nice examples)

	my @s = ( $lfn, 
			  $self->lastFullHash(),
			  $self->size(),
			  $self->fullHash(),
			  $self->lastDirScan(),
			  $self->lastStat(),
			  $self->mtime()
			  );

	my $s = join ':', @s;

	return $s;
}

sub make($)
{
	my $class = shift;
	my $lfn = shift;

	my $self = $class->new();

	main::assert_cpath( $lfn );

	print "Ghost: Making ghost for lfn=[$lfn]\n";

	$self->lfn( $lfn );

	return $self;
}

# Forces the key fields to be loaded if they aren't already known
# Does not recheck them against the disk unless the standard

# TODO: implement size and fasthash

sub forceCharacterization
{
	my $self = shift;

	$self->getFullHash();
	$self->getSize();
	# $self->getFastHash();	
}

# returns an acceptable fullHash for the ghost
# Normally, the latest cached data is trusted, but
# this function can be set to take a out of data criteria in future TODO

sub getFullHash
{
	my $self = shift;

	if( defined $self->fullHash() )
	{
		return $self->fullHash();
	}
	else
	{
		return $self->getFullHashForceHitDisk();
	}
}

sub getSize
{
	my $self = shift;

	if( defined $self->size() )
	{
		return $self->size();
	}
	else
	{
		$self->getStatForceHitDisk();
		return $self->size();
	}	
}

sub getMTime
{
	my $self = shift;

	if( defined $self->mtime() )
	{
		return $self->mtime();
	}
	else
	{
		$self->getStatForceHitDisk();
		return $self->mtime();
	}	
}

sub informDirscan
{
	my $self = shift;

	$self->lastDirScan( time() );

	# TODO: Do we want a dirscan to always force an update to the ghost?
	# $self->dirty(1);
}

sub getFullHashForceHitDisk
{
	my $self = shift;
	my $lfn = $self->lfn();

	$self->lastFullHash( time() );

 	my $fullhash = main::getFullHashForceHitDisk( $lfn );

	$self->fullHash( $fullhash );

	$self->dirty(1);

	return $fullhash;
}

sub getStatForceHitDisk
{
	my $self = shift;
	my $lfn = $self->lfn();

	print "STAT: $lfn\n";

	$main::run_files_stat++;

	my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size, $atime,$mtime,$ctime,$blksize,$blocks)
		 = stat($lfn);

	$self->size($size);
	$self->mtime($mtime);
	$self->lastStat( time() );

	$self->dirty(1);

	return undef;
}


###

main::main();
exit();



