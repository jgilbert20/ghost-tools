#!/usr/bin/perl

use strict;
use warnings;
use diagnostics;
#use diagnostics -verbose;

use Digest::SHA;
use File::Basename;
use File::Spec;
use File::Path;
use File::Copy; 
use Time::HiRes qw( CLOCK_REALTIME gettimeofday tv_interval);
use Getopt::Long;
use POSIX; # needed for time formating
use Cwd qw(abs_path); # best way to get absolute paths

# Database Layer

use BerkeleyDB;
use BerkeleyDB::Hash;
use BerkeleyDB::Btree;

# Gives us tied access to databases

use MLDBM qw( BerkeleyDB::Hash Storable );

# Key function prototypes

sub debug($);

# Major globals

my $DESCRIPTOR_FILENAME = ".gfs_ip";
my $SERIALIZATION_VERSION_NUMBER = 5;
my $GENERAL_DEBUG = 1;
my $USUAL_IGNORE = 1;
local $main::SCRIPT_START = time();
local $main::SCRIPT_START_GTOD = [gettimeofday];
local $main::GUARD_TIME_SECONDS = undef; 

# Run statistics - globals

local $main::run_files_fullread = 0;
local $main::run_bytes_fullread = 0;
local $main::run_time_fullread = 0;
local $main::run_files_stat = 0;
local $main::run_descriptors_read = 0;
local $main::run_descriptors_write = 0;
local $main::readdir_invokes = 0;
local $main::readdir_entries = 0;

# Get path to our WD

my $HOME = $ENV{HOME};
my $WDIR = "$HOME/.gfs";
my $DBDIR = "$WDIR/db";
my $EDIR = "$ENV{HOME}/.gfsrun/EXEC-$$";

$main::localFileSystemFSE = undef;

# Option management

my $OPT_ALL = 0;
my $OPT_STATS = 0;
my $OPT_GUARDTIME = undef;

&GetOptions( 'all' => \$OPT_ALL,
			 'G|guard=s' => \$OPT_GUARDTIME,
			 'stats' => \$OPT_STATS );


if( defined $OPT_GUARDTIME )
{
	$main::GUARD_TIME_SECONDS = $OPT_GUARDTIME;
	debug "Guard time set to: $main::GUARD_TIME_SECONDS\n";
}

# Utility function to present relative time in a human readable way

sub expressRelativeTime
{
	my $seconds = shift;

	if( $seconds > 24*60*60)
	{
		$seconds /= 24*60*60;
		my $r = sprintf( "%0.4s days", $seconds );
		return $r;
	}

	if( $seconds > 2*60*60)
	{
		$seconds /= 60*60;
		my $r = sprintf( "%0.4s hours", $seconds );
		return $r;
	}

	if( $seconds > 120)
	{
		$seconds /= 60;
		my $r = sprintf( "%0.4s secs", $seconds );
		return $r;
	}

	return "$seconds" . "s";
}



# Helper function that creates a nested path with lots of error checking

sub mkdirs
{
    my $dir = shift;
    my $dirx = dirname $dir;

    # debug "MKDIRS:[$dirx]\n";
    eval{ mkpath($dirx,1) };
    $@ and die "Couldn't create dir path: $@";
    die "Did not find new path" if not -d $dirx;

   return 1;
}

# Helper function - if user requests it, ignores shit things like .git and .DS_Store
# Returns true if the file is good to go, or false if it is usually ignored
# This is not to be used for avoiding actual logic or recursion errors
# (such as scanning our own descriptors).
# User should be free to turn this feature off and the program must work as intended. 

sub fileIsUsuallyIgnored
{
	my $cfn = shift;

	return 0 if( not $USUAL_IGNORE );

	return 1 if $cfn =~ /\.DS_Store$/;
	return 1 if $cfn =~ /Thumbs.db$/;
	return 1 if $cfn =~ /\.pcip_info$/;

	return 0;
}

# Verifies readability of various directories needed for program invocation

sub verifyWorkingDirectories
{
	if( not -e $WDIR )
	{
	    mkdir $WDIR or die "Error creating [$WDIR]: $!";
	}

	if( not -e $DBDIR )
	{
	    mkdir $DBDIR or die "Error creating [$DBDIR]: $!";
	}

	if( not -e $EDIR )
	{
	    mkdirs($EDIR . "/") or die "Error creating [$EDIR]: $!";
	}

	die "Cannot create $WDIR" unless -w $WDIR;
	die "Cannot create $DBDIR" unless -w $DBDIR;
}

# Sets up our data

sub setupDatabases
{
	my $bdb_env = new BerkeleyDB::Env 
	    -Verbose => 1,
	    -Home => $DBDIR,
	    -Flags => DB_CREATE|DB_INIT_MPOOL|DB_INIT_CDB,
	    -ErrFile => "$DBDIR/Errors-$$",
	    -ErrPrefix => "GFS";
}


sub debug ($)
{
	return if not $GENERAL_DEBUG;
	my $a = shift @_;
	chomp $a;
	print STDERR "D:" . $a . "\n";
}


sub init
{
	verifyWorkingDirectories();
	setupDatabases();
	$main::localFileSystemFSE = new FilesystemExplorer::FS();
}



# Incorporated code from String::Escape via per artistic license
# Reason: Need to tweak what counts as an escaped character

# =head1 AUTHOR
# Matthew Simon Cavalletto, C<< <simonm at cavalletto.org> >>
# Initial versions developed at Evolution Online Systems with Eleanor J. Evans and Jeremy G. Bishop.
# =head1 LICENSE
# Copyright 2010, 2002 Matthew Simon Cavalletto.
# Portions copyright 1996, 1997, 1998, 2001 Evolution Online Systems, Inc.
# You may use, modify, and distribute this software under the same terms as Perl.
# See http://dev.perl.org/licenses/ for more information.
# =cut


use vars qw( %Backslashed %Interpolated );

# Earlier definitions are preferred to later ones, thus we output \n not \x0d
_define_backslash_escapes(
	( map { $_ => $_ } ( '\\', '"', '$', '@' ) ),
	( 'r' => "\r", 'n' => "\n", 't' => "\t" ),
	( map { 'x' . unpack('H2', chr($_)) => chr($_) } (0..255) ),
	( map { sprintf('%03o', $_) => chr($_) } (0..255) ),
);

sub _define_backslash_escapes {
	%Interpolated = @_;
	%Backslashed  = reverse @_;
}

# $special_characters_escaped = backslash( $source_string );
sub backslash ($) {
	local $_ = ( defined $_[0] ? $_[0] : '' );
	# Preserve only printable ASCII characters other than \, ", $, and @
	s/([^\x20\x21\x24\x25-\x39\x41-\x5b\x5d-\x7e])/\\$Backslashed{$1}/gs;
	return $_;
}

# $original_string = unbackslash( $special_characters_escaped );
sub unbackslash ($) {
	local $_ = ( defined $_[0] ? $_[0] : '' );
	s/ (\A|\G|[^\\]) [\\] ( [0]\d\d | [x][\da-fA-F]{2} | . ) / $1 . ( $Interpolated{lc($2) }) /gsxe;
	return $_;
}


sub gfs_escape($)
{
	my $v = shift;

	return undef if not defined $v;

	$v =~ s/:/\\c/gs;
	$v =~ s/\@/\\a/gs;
	$v =~ s/#/\\p/gs;
	$v =~ s/\n/\\n/gs;
	return $v;

}

sub gfs_unescape($)
{

	my $v = shift;
	$v =~ s/\\c/:/gs;
	$v =~ s/\\a/\@/gs;
	$v =~ s/\\p/#/gs;
	$v =~ s/\\n/\n/gs;

	return $v;
}

# test cases:
# snapshot directories both a/* and a/ and a

# insight: we could have an entry for a directory.. the last full time it was scanned
# then if the read date of the file is earlier than the scan date of the directory
# then we know the file may be stale and can delete it



# how do we stick virtual things into the hash?
# for instance, where or how do we store the idea that a .tar file has certain contents
# or that an rsync directory (jgilbert@auspice.net:a/b/c) contains a file?
# almost like a normal path a/b/c is basically an implicit "local:a/b/c"..
# the local handler knows to write .gfs_info files
# whereas the remote one knows not to
# each FS type offeres a get, move, copy, retrieve full checksum, stat, etc function
# so now we can handle S3, Rsync, etc

# how does that tie in with tags?
# how do I say anything under /Volume/Foo should be addressed as FOODRIVE:
# clearly this only matters during AFN conversion
# disktag:FOODRIVE|/one/two/three
#
# if that is the AFN recorded, then the system will think that is there
# we just need to write a record like /Volume/Foo -> FOODRIVE
# and also write a /Volume/Foo/GFS_ID.txt file
# then a dereference just requires that we verify that the /Volume/Foo/GFS_ID can still be reached
# maybe there is a tool like "bless" which does this for you
# so the rel->AFN conversion would either need to rely on this mapping
# or traverse back up to make sure that all ../GFS_ID.txt files were registered

# is a snapshot treated as a file collection as a target? if it is, we have to emphasize 
# that it is a ghost. e.g. you can enumerate, but the fact that snapshot:4444/sdf contains
# this file version could never be used as a proxy.
# so when you "get all AFNs for hash", you'd have to pass to a FShandler for the snapshot

# GFS is an overlay snapshoting and directory reconstruction tool. Its not really meant 
# for version control, but managing someone's life which may be scattered 
# across many different asset types and locations.
# GFS is entirely built around command line tools. It doesn't watch the filesystem
# for changes.
# key features
# 1) highly accelerated content-aware rsync - a file is never retransmitted unless needed
# 2) worried you still wantt o eb sure you have a backup of a wedding photos? 
#     this has tools that let you flag and manage bit-rot and verify your stuff is where
#     you think it is
# 3) work with large file trees both on a desktop and laptop? GFS can tell you instantly
#     which chnages you've made on your laptop that are not yet on your desktop and push them
#     to the desktop efficiently
# 4) in the field and want to be sure files you are working on are protected?
#     GFS can make sure any file is either in your dropbox, on your machine at home
# 5) trying to free up space on your laptop? do you have a copy of that big 10 GB ISO file
#     at home? find out quickly if you can ditch it. 



# Database layer use cases
# 1) quickly give me ghost information for a path
#      AFN -> GhostSerialized as absolute
# 2) quickly give me the AFNs associated with a hash or size
#      hash -> AFN 0..n   (needed for LSDup)
#	   size -> AFN 0..n   (also possibly needed for LSDup)

# so when something is stored in location X or found in location X, 
# what permanent record is created?
# maybe we create spontaneous snapshot records that can be loaded back in?
#
#    gfs rsync /source jgilbert@asdf:foobar/
# 
# All files written to foobar drops a file in .gfs/receipts/rsync-$$-date.snapshot
# With the note: "This snapshot record was written by GFS on date XXXX"

sub main()
{
	# print "Welcome to Ghost.\n";

	init();

	# TODO: Some kind of sanity checking on arguments
	# Are all the files listed MECE?
	# Just a warning is fine here but the user ought to be prompted
	# just to be sure

	my $tk = TruthKeeper::get();

	my $verb = shift @ARGV;

	# print " Verb = [$verb]\n";

	handleVerb( $verb );

	# reconstruct-test A B C
	#   makes sure that everything in A and B be reconstructed in target C
	#   as long as there is at least one valid duplicate, we move on
	# 			first, best approach is to look for hashed AFN
	#			       ask FSE if it "owns" that file
	#				   then call "hasIdenticalContent()"
	#               if that doens't work, check the cache of sizes
	#					call hasIdenticalContent
	#                  as soon as one returns "hasIdenticalContent", we return
	#               finally, force the full cache of sizes

	# copy-delta A B C
	#    Anything in A and B that is not in C is going to get copied over 
	#	 into a "delta" directory

	# rsync A B C
	#	 C is reconfigured to look exactly like A and B. Files that no longer
	#    belong can be identified and removed as an option.
	#	 this works by MOVING files around inside of C. depending on how
	#    slashes are used, we either merge or replace (rsync ffo/ behavior)
	#    $fse->move( a, b );
	#			the move tool has to move the ghosts too
	# 			and that may invalidate certain descriptor files
	
	# what is the means by whcih deleted files are recongized?
	# in cases of a full scan, someone has to be smart enough
	# to know we are doing a scan that is "full" enough to count,
	# and to mark ghosts for deletion

	# right now, there is no stat verification when writing a snapshot
	#  snapshot -verify-stat (can find it, size and lastmod match) --verify-hash
	# and when those things are in place, anthing that hasn't been checked in the last 24 hours
	# are rejected, unless you say --hit-disk which means basically ignore all of the 
	# tools and recheck everything
	

	$tk->flush();

	if( $OPT_STATS )
	{
		handleStats();

	}
}


sub handleStats
{
	print "----- DONE -----\n";

	print "Full reads count: $main::run_files_fullread\n";
	print "Full reads size : $main::run_bytes_fullread\n";
	print "Full read time  : $main::run_time_fullread\n";

	print "Stat reads      : $main::run_files_stat\n";

	print "Local .gfs reads: $main::run_descriptors_read\n";
	print "Local .gfs writs: $main::run_descriptors_write\n";
	print "Readdir invokes : $main::readdir_invokes\n";
	print "Readdir entries : $main::readdir_entries\n";

	print "Total Script Time: " . tv_interval( $main::SCRIPT_START_GTOD ) . "\n";	
}

sub handleVerb
{
	my $verb = shift;




	if( $verb eq "lsdup")
	{
		doverb_lsdup();
		return;
	}

	if( $verb eq "help")
	{
		doverb_help();
		return;
	}

	# LS tells us what we can find out about the current directory tree
	# nothing is force read. there is a dirscan and that is it.

	if( $verb eq "ls" )
	{
		doverb_ls();
		return;
	}

	if( $verb eq "checksum" )
	{
		doverb_checksum();
		return;
	}
	# Writes a permanent file of this entire tree

	if( $verb eq "snapshot")
	{
		doverb_writeSnapshot();
		return;
	}


	die "Verb $verb not recognized - try $0 help for ideas";

	return;
}




sub doverb_help
{
	print <<HERE;

gfs - a universal tool for file handling with checksums

Moves, snapshots and searches for duplicates with a minimum of disk activity.

Unless otherwise instructed, GFS avoids disk access whenever possible. If
meta-data about the size, modification date, or checksum is already available,
it is used for the operation regardless of its age (although you might get a
warning if its too old.) You can force information to be more up to date by
setting a guard time with -G. This is the number of seconds old that metadata
is valid. Setting it to 0 means that basically no metadata caching is done,
the most conservative (and slowest) approach.

Future feature: Checksums are not typically forced by the -G switch unless
there is some reason to doubt them (such as a changed size or modification
date. If you really want everything recalculated, set the --force-checksum.)

gfs ls file1 [... file-n]

	Prints out each file and the data known about it. Does not force any new
	calculations or checksums unless a guard argument is in place.

gfs snapshot file1 [... filen]

    Writes a file describing the current state of the listed files. Checksums
    / stats if not present are forced, otherwise, no unnecessary disk activity
    is created.

gfs lsdup [source1 .. source-n] target [--all]

    For every file in target tree, reports which is duplicated
    in the target or source trees.

    --all forces a report for every file, not just duplicates (not yet
      implemented)

HERE

}

# doverb_writeSnapshot - handle the write-snapshot command
#
# for each item listed, shows what we know about it -- no recursion, no forced 
# characterization

sub doverb_writeSnapshot()
{
	my $tk = TruthKeeper::get();
	my ($targetGS, $targetStash) = $tk->makeGhostsFromCommandLine( @ARGV );

	my $i = $targetGS->getDescendingIterator();

	my $store = GhostStore->new();

	while( my $g = $i->next() )
	{
		debug "Write Snapshot - Got Ghost: $g\n";

		if( not $g->canHaveChildren() )
		{
			$g->forceCharacterization();
		}
		

		$g->printDebug();
		$store->addGhost( $g );

	}

	$store->writeSnapshotToDisk( "snapshot-$$.out");
}

# doverb_ls - handle the LS command
#
# for each item listed, shows what we know about it -- no recursion, no forced 
# characterization

sub doverb_ls()
{
	my $tk = TruthKeeper::get();

	my ($targetGS, $targetStash) = $tk->makeGhostsFromCommandLine( @ARGV );

	foreach my $tuple (@$targetStash)
	{
		my( $userFN, $fqlfn, $g ) = @$tuple;


		my $fullHash = $g->fullHash() || '<not calculated>';
		my $lastFullHash = $g->lastFullHash();

		my $lfh_string = defined $lastFullHash ? strftime( "%c", localtime( $lastFullHash) ) : '<not calculated>';

		my $d = expressRelativeTime( $main::SCRIPT_START - $lastFullHash );

		$lfh_string .= "($d)";

		print "$fullHash\t$lfh_string\t$userFN\n";
	}
}


# doverb_checksum - checksum the files we are given
#
#

sub doverb_checksum()
{
	my $tk = TruthKeeper::get();
	my ($targetGS, $targetStash) = $tk->makeGhostsFromCommandLine( @ARGV );
	my $i = $targetGS->getDescendingIterator();

	while( my $g = $i->next() )
	{
		my $lfn = shift; 



		my $fullHash = $g->getFullHash();
		$g->printDebug();

		print +(join "\t", $fullHash, $g->lfn()), "\n";


	}


}



###########
# Lsdup: A B C - for every file in C, say which are copied in A and or B and C (and where)
# Ghost-tools tries to be minimal about hitting the disk, but at a minimum,
# a duplicate requires that at some point GFS has to have a full SHA-1 match of the file.
# 
# Tells you where the duplicates are, and when they were last checked or verified
#
# foreach c (where size != 0)
# c->findDuplicates( $g );
# b->findDuplicates( $g );
# a->findDuplicates( $g );
# findDuplicates psucdocode
#    get ghost G for FN
#    find candidates - $fse->listAllFilesWithSize( $size )
#        lafby size, first time its called iterates over all FSE, hashing up sizes
#		 next, for each we do the test "$g->hasIdenticalContent($g)"
#		 	HIC first rules out size, then mod-date, then finally fullhash

sub doverb_lsdup()
{
	my $target = pop @ARGV;
	my @source = @ARGV;

	my $tk = TruthKeeper::get();
	my ($targetGS, $targetStash) = $tk->makeGhostsFromCommandLine( $target );
	my ($sourceGS, $sourceStash) = $tk->makeGhostsFromCommandLine( @source );
	my $i = $targetGS->getDescendingIterator();

	my $dup_count = 0;
	my $dup_size = 0;
	my $dup_size_interior = 0;
	my $dup_count_interior = 0;
	my $total_files = 0;
	my @report; 
	my $asWeGoPrint = 1;

	while( my $g = $i->next() )
	{
		my $lfn = $g->lfn();

		next unless $g->isFile();
		next if fileIsUsuallyIgnored( $lfn );

		$total_files++;

	#	print "LS Dup -handling LFN:[$lfn]\n";

		my @tdups = $targetGS->findOtherDuplicates( $g );
		my @sdups = $sourceGS->findOtherDuplicates( $g );

		my $dupCount = @tdups + @sdups;

		if( $dupCount > 0 )
		{
			$dup_count_interior++;
		}

		if( $asWeGoPrint )
		{
			printf "[%3d]_________%s\n", $dupCount, $lfn;
		}

		if( @tdups > 0 )
		{	
			#print "    Duplicate in local tree: ($target)\n";

			foreach my $d (@tdups)
			{
				my $dfn = $d->lfn();
 
				print "      Target: $dfn\n" if $asWeGoPrint;
				$dup_count++;
				$dup_size += $d->getSize();
				$dup_size_interior += $d->getSize();
				# $d->printDebug();
			}
		}

		if( @sdups > 0 )
		{
			$dup_size_interior += $g->getSize();
			#print "    Duplicate in source trees (@ARGV):\n";
			foreach my $d (@sdups)
			{
				my $dfn = $d->lfn();

				print "      Source: $dfn\n" if $asWeGoPrint;
				$dup_count++;
				$dup_size += $d->getSize();
				# $d->printDebug();
			}
		}

		push @report, [$g, \@tdups, \@sdups];
	}

	print "Duplicate report: size X (target dups / source dups ) filename\n";

	foreach my $line (reverse sort { $a->[0]->getSize() <=>  $b->[0]->getSize() } @report )
	{
		my ($g, $tdups, $sdups ) = @$line;
		my $file = $g->lfn();
		my $size = $g->size();
		my $i = 0 + @$tdups;
		my $e = 0 + @$sdups;

		if( $i > 0 or $e > 0 or $OPT_ALL )
		{	
			print "$size X ($i/$e) $file \n";
		}
	}

	print "LSDup finished\n";
	print "I found $dup_count_interior files that were duplicated in target ($target),\n";
	print "when searching among the target plus source files: @ARGV\n";
	print "occupying $dup_size unnecessary space across the whole filesystem over $dup_count files.\n";
	print "Within the target itself, this represents $dup_size_interior bytes.\n";
	print "There were $total_files in the target directory\n";
}

# Write the in place descriptors in each directory named

sub doverb_writeDescriptor()
{
	die "dead";
	my $store = GhostStore->new();

	my $fse = new FilesystemExplorer::FS();
	$fse->setRoots( @ARGV );

	# sort of a lazy way to do it -- forces
	# a checksum computation, which should
	# populate the in place descriptors

	# a better way would be to enter each directory
	# and call some specific "build for x" function

	while( defined( my $file = $fse->next() ) )
	{
		print "Verb WD - Scanning: [$file]\n";

		if( -f $file )
		{
			$fse->forceGhostCharacterization( $file );
			my $fullHash = $fse->getFullHash( $file );
			print "Verb WD: fullhash = $fullHash\n";
		}
		else
		{
			print "Verb WD - Not a regular file: [$file]\n";
		}

	
	}
}




# A hard ignore is a filename that we must pretend never existed
# it will not factor into any directory checksums
# or be saved to any ghost stores

sub isHardIgnore
{
	my $fn = shift;

	die "Assert: $fn should be a path" if not main::assert_regularpath( $fn );

	my $b = basename $fn;	

	return 1 if $b =~ /$DESCRIPTOR_FILENAME$/;

	return 0;
}


# Sanity check that a path is indeed canonicalized 
#
# GFS relies on all paths being canonicalized so that text matching occurs
# properly. Otherwise ./foo and foo will not text match and it will appear
# like they are different files. Any routines that brings in a "net new" path
# to the system should convert it to a cpath.

sub assert_cpath($)
{
	my $lfn = shift;
	assert_regularpath($lfn);
	my $clfn = File::Spec->canonpath( $lfn );
	die "ASSERT CPATH FAILED: $lfn ne $clfn" if $lfn ne $clfn; 
}

# Sanity check that in places where an operation is to work
# on a regular path that it actually is one.

sub assert_regularpath($)
{
	my $path = shift;
	my $c = () = $path =~ m/\:/go;
	#print "Testing [$path] - got $c\n";
	die "ASSERT regularpath [$path] - failed -- smells like a FQLFN" if( $c == 2 );
	return 1; 
}

sub rewriteLFNPathAbsolute
{
	my $lfn = shift;
	my( $handler, $root, $path ) = parseFQLFN( $lfn );
	$path = abs_path( $path );
	return assembleLFN( $handler, $root, $path );
}

# Takes an LFN and removes the leading directory from the path component

sub rewriteLFNPathToBasename
{
	my $lfn = shift;

	my( $handler, $root, $path ) = parseFQLFN( $lfn );
	my( $fn, $dir ) = fileparse( $path );
	return assembleLFN( $handler, $root, $fn );
}

# Takes an LFN and adds a leading directory portion onto the path

sub rewriteLFNwithLeadingDirectory
{
	my $lfn = shift;
	my $leadingDir = shift;

	my( $handler, $root, $path ) = parseFQLFN( $lfn );
	$path = File::Spec->catfile( $leadingDir , $path );
	$path = main::canonize( $path );
	return assembleLFN( $handler, $root, $path);
}



# Pass it a path (not a FQLFN) and you'll get the canonical version
# which can be file compared

sub canonize($)
{
	my $lfn = shift;

	assert_regularpath( $lfn );

	my $clfn = File::Spec->canonpath( $lfn );

	# print "Canonicalize: $lfn ---> $clfn\n";	

	return $clfn;
}




# Assembles a FQLFN from its consituent parts

sub assembleLFN
{
	my ($handler, $root, $path ) = @_;

	die unless length $handler >0;
	die unless length $root >0;
	die unless defined $path;

	return join ':', $handler, $root, $path;

}


# Splits out a FQLFN into its three parts

sub parseFQLFN
{
	my $lfn = shift;

#	my @parts = split( ':', $lfn );
	my (@parts) = ( $lfn =~ m/^(\w+)\:([^:]+)\:(.*)/ );

	my ($handler, $root, $path ) = @parts;

	die "assert: parseFQLFN [$lfn] - does not have 3 parts!" unless scalar(@parts) == 3;
	# print "ParseLFN = [$lfn] -> handler:[$handler] root:[$root] lfn:[$path]\n";

	return @parts; 
}

# Does the gueswork of taking a partial user provided LFN and figuring
# out the intent and fully qualifying it

sub fullyQualifyLFN
{
	my $lfn = shift;

	my @c = split( ':', $lfn );

	my $handler;
	my $root;
	my $path;

	# first handle the case of bareword stuff like ./quxx and bar or testa/file1.txt

	if( 0 )
	{
		print "fullyQualifyLFN: Testing for element count";
		print scalar @c;
		print "\n";
	}

	if( scalar(@c) == 1 )
	{
		$handler = "fs";
		$root = "root";
		$path = $lfn;
	}
	elsif( @c < 3 )
	{
		# Yucky case - user has given us 2 things, what does he or she mean?
		# first, lets see if the first thing is one of our keywords
		# if so, we can usually assume the next part is the root

		if( $c[0] =~ /^fs|snap|remote/ )
		{
			$handler = $c[0];
			$root = $c[1];
			$path = "";

			warn "Interpolating LFN -- did you mean to leave off a path? Assuming your intent was handler:[$handler] root:[$root] path:[$path] ";
		}
		else
		{
			# In this case, best to assume that the first thing is the root
			# but what handler to use?

			$handler = "";
			$root = $c[0];
			$path = $c[1];

			die "Cannot infer compound path - [$lfn] - please specify a handler";
		}
	}
	elsif( @c > 3 )
	{
		die "Ambiguous - too many colons in this filename. (Sorry we don't like colons in filenames, at least not when provided on the command line)";
	}
	else
	{
		($handler, $root, $path ) = @c;
	}

	$path = main::canonize( $path );

	debug "FULLY QUALIFY LFN:[$lfn] -> handler:[$handler] root:[$root] path:[$path]\n";

	return assembleLFN( $handler, $root, $path );
}

package FilesystemExplorer::Snapshot;

use File::Basename;
use base qw(Class::Accessor);
FilesystemExplorer::Snapshot->mk_accessors( qw( rootGhost rootGhostStore) );

sub debug($)
{
	my $a = shift;
	main::debug( "FSE/ss: " . $a );
}



sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();

	return $self;
}

sub loadRootIfNeeded
{
	my $self = shift;

	my $rgs = $self->rootGhostStore();

	return $rgs if ref $rgs;

	$rgs = GhostStore->new();
	$rgs->slurpSnapshot( $self->rootGhost()->lfn(), "SNAPSHOT" );
	$self->rootGhostStore( $rgs );
	return $rgs;
}

sub getStatSourceVerify
{
	my $self = shift;
	my $lfn = shift;

	my $rgs = $self->loadRootIfNeeded();

	my ($size, $mtime, $mode);

	return ($size, $mtime, $mode);
}


##########
# The FSE class handles low level access and coherency for a particular
# domain of listed files. This could be a real file system or a snapshot
# or even a remote filesystem or S3 type thing.
# 
# I think this is the right definition for the class: 
#
# It provides the ability to iterate over the filesystem in an organized way.
# Everything that hits a primary resource should go here
# FSE is mainly called by the ghost API
# 
# Verbs i know it has to support
#
# - iteration
# - findDuplicates();
# - forceFullCharacterization();

package FilesystemExplorer::FS;

use Time::HiRes qw( CLOCK_REALTIME gettimeofday tv_interval);
use File::Basename;
use base qw(Class::Accessor);
FilesystemExplorer::FS->mk_accessors( qw(topLevelLFNs sizeToFNs) );

my $fseDebug = 0;

# Return new FSE
# CORE - any FSE must implement


sub debug($)
{
	my $a = shift;
	main::debug( "FSE/fs: " . $a );
}


sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();

	$self->sizeToFNs( undef );

	return $self;
}


sub getFullHashSourceVerify
{
	my $self = shift;
	my $g = shift;

	my $path = $g->getPath();

	print "*** FULLHASH: $path\n";

	# TODO: examine use of stat
	$main::run_bytes_fullread += -s $path;

	my $START_GTOD = [gettimeofday];

	my $sha = Digest::SHA->new(1);
	$sha->addfile( $path );
	my $hexdigest = $sha->hexdigest();

	$main::run_files_fullread++;

	$main::run_time_fullread += tv_interval( $START_GTOD );

	return( "SHA1/FULL/$hexdigest");
}

sub getStatSourceVerify
{
	my $self = shift;
	my $g = shift;

	my $path = $g->getPath();

	print "*** STAT: $path\n";

	$main::run_files_stat++;

	my @statfields = stat($path);

	die "Ghost [$path] failed stat - probably doesn't exist: $! ($@)" if( @statfields == 0 );
	my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size,$atime,$mtime,$ctime,$blksize,$blocks) = @statfields; 
	
	return ($size, $mtime, $mode);
}


# Return LFNs of immediate children
# CORE - any FSE must implement

sub getImmediateChildren
{
	my $self = shift;
	my $parent = shift;

	my $dir = $parent->getPath();

	print "FSE:ScanDIR into dir:[$dir]\n" if $fseDebug;

	#$dir =~ s/\/+$//;

	opendir DIR, $dir or die "cannot descend into [$dir] for getImmediateChildren: $! $@";

	$main::readdir_invokes++;

	# drop . and .., sort directory
	my @files = map { "fs:root:" . $_ }
	    map {  main::canonize( File::Spec->catfile( $dir, $_ ) ) } 
		grep { !/^\.{1,2}$/ } 
		grep { !main::isHardIgnore( $_ ) } 
		sort { $a cmp $b } 
		readdir DIR;

	$main::readdir_entries += @files;

	print( "FSE:ScanDIR Returned: [", (join '],[', @files ), "]\n" ) if $fseDebug;

	close DIR;

	return @files;
}

sub setRoots()
{
		die "TODO No longer supported here - to remove";

	my $self = shift;

	$self->topLevelLFNs( [@_] );

	foreach my $f ( @_ )
	{
		if( not -r $f )
		{		
			die "File [$f] is not a readable file or directory";
		}
	}
}

sub getIterator()
{
		die "TODO No longer supported here - to remove";

	my $self = shift;

	my $r = FilesystemIterator->new();
	$r->queue( [ @{$self->topLevelLFNs()} ] );

	return $r;
}




package FSEFactory;

# is container the right term for this?

my $fseFactoryDebug = 0;
my %fseForHandlerRoot;

sub debug($)
{
	my $a = shift;
	main::debug( "FSE-factory: " . $a );
}

sub getFSEHandlerForGhost
{
	my $class = shift;
	my $g = shift;
	my $lfn = $g->lfn();

	# print "$lfn**\n";

	my $r = undef;

	my ($handler, $root, $path ) = main::parseFQLFN($lfn);

	if( $lfn =~ /^snap/m )
	{
		my $key = $handler . ":" . $root;
		my $class = "FilesystemExplorer::Snapshot";

		## TODO - break this out into a cleaner function

		if( exists $fseForHandlerRoot{$key} )
		{
			main::debug "Found existing handler for $key @ $class"  if $fseFactoryDebug;
			$r = $fseForHandlerRoot{$key};
		}
		else
		{
			main::debug "Making new handler for $key @ $class"  if $fseFactoryDebug;
			$r = $class->new();
			$r->rootGhost($g);
		}
	}	
	else
	{
		$r = $main::localFileSystemFSE;
	}

	main::debug "FSEFactory: FSE handler for lfn:[$lfn] --> Class:[$r]" if $fseFactoryDebug;

	return $r; 
}


package TruthKeeper;

use Data::Dumper;
use File::Basename;
use base qw(Class::Accessor);

my $global_tk;

my %ghostForLFN_private;
my %ghostForAFN_private;
my %ghostStoreForDescriptorLFN;

my $tkdebug = 1;

sub debug($)
{
	my $a = shift;
	main::debug( "TK: " . $a );
}


# Takes ghosts provided by a command line and  blows out a fully qualified LFN
# and gets the ghosts returns a nice structure of data you'd need for iteration
# on the command line: [provided ARGV, fully qualified ghost name, ghost]


sub makeGhostsFromCommandLine
{
	my $self = shift;
	my @stuff = @_;

	my $gs = GhostStore->new();

	my @stash = ();

	foreach my $lfn (@stuff )
	{
		my $fqlfn = main::fullyQualifyLFN( $lfn );

		debug "Make Ghost Via CommandLine user provided lfn:[$lfn]->fqLFN:[$fqlfn] from command line to store\n";
		my $g = $self->obtainGhostForLFN($fqlfn);
		$gs->addGhost( $g );
		push @stash, [$lfn, $fqlfn, $g ];
	}

	return ($gs, \@stash);
}

sub ghostForLFN
{
	my $self = shift;
	return \%ghostForLFN_private;
}

sub ghostForAFN
{
	my $self = shift;
	return \%ghostForAFN_private;
}

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();
	# $self->ghostForLFN( +{} );
	return $self;
}

sub printInternallyTrackedLFN
{
	my $self = shift;
	my $ghostForLFN = $self->ghostForLFN();
	foreach my $g (values %$ghostForLFN )
	{
		debug ("     " 
			 . ($g->dirty() ? "YES" : "NO")
		     . "  "
		 	 . $g->lfn()
		     . "  " );

	}
	return;
}


sub printInternallyTrackedAFN
{
	my $self = shift;
	my $ghostForAFN = $self->ghostForAFN();
	foreach my $g (values %$ghostForAFN )
	{
		debug ("     " 
			 . ($g->dirty() ? "YES" : "NO")
		     . "  "
		 	 . $g->absoluteLFN()
		     . "  " );

	}
	return;
}

sub flush
{
	my $self = shift;

#	debug Dumper( $self );

	debug "TK: Beginning flush ---\n";

	debug "TK: Inventory of all internally tracked ---\n";

	$self->printInternallyTrackedLFN();

	debug "TK: Inventory of all internally tracked AFNs ---\n";

	$self->printInternallyTrackedAFN();


	debug "TK: Ghost Cache Writes ---\n";

	$self->flushGhostDescriptorCache();

	debug "TK: Verify ---\n";

	$self->verifyNoDirtyGhostsRemain();
}

sub get
{
	my $class = shift;

	return $global_tk if defined $global_tk;

	$global_tk = new TruthKeeper();

	return $global_tk;
}

sub verifyNoDirtyGhostsRemain
{
	my $self = shift;
	my $ghostForLFN = $self->ghostForLFN();

	my $error = 0;

	foreach my $g (values %$ghostForLFN )
	{
		if( 0 )
		{
			debug "   Verifying TK Ghost: ";
			debug $g->printDebug();
			debug "  ";
			debug ($g->dirty() ? "YES" : "NO");
			debug "\n";
		}	
		$error++ if $g->dirty();
	}

	die "Dirty ghosts remain unflushed!! assert" if $error > 0;
}

sub flushGhostDescriptorCache
{
	my $self = shift;

	foreach my $gslfn ( keys %ghostStoreForDescriptorLFN )
	{
		## my $gs = getGhostStoreForDescriptorFileCoveringFN( $k );

		$self->flushDescriptorToDisk( $gslfn );
	}
}

sub flushDescriptorToDisk
{
	my $self = shift;
	my $lfn = shift; # LFN of the ghoststore

	debug "TK: Flushing ghoststore [$lfn] to disk\n" if $tkdebug;

	if( not exists $ghostStoreForDescriptorLFN{$lfn} )
	{
		die "Internal assert - $lfn not found" if $tkdebug;
	}

	my $gs = $ghostStoreForDescriptorLFN{$lfn};

	$gs->purifyAllGhostsToTK();

	if( $gs->countDirty() > 0 )
	{
		$gs->writeAsDescriptor( $lfn );
	}
	else
	{
		debug "TK:   - Not needed, no dirty records\n" if $tkdebug;
	}

	map { $_->dirty(0) } $gs->getAllGhosts();

	delete $ghostStoreForDescriptorLFN{$lfn};

	return undef; 
}

sub getGhostDescriptorFileForLFN($)
{
	my $self = shift;
	my $filename = shift;

	# debug "GDF: $filename\n";

	die "Assert: $filename should be a path" if not main::assert_regularpath( $filename );

	my( $fn, $dir ) = fileparse( $filename );

 	my $dfn = File::Spec->catfile($dir, $DESCRIPTOR_FILENAME);

 	# debug "GDF [$dfn] for $filename\n";

	return $dfn;
}

sub getGhostStoreForDescriptorFileCoveringFN
{
	my $self = shift;
	my $lfn = shift;

	my $gsfn = $self->getGhostDescriptorFileForLFN( $lfn );

	if( exists $ghostStoreForDescriptorLFN{$gsfn} )
	{
		return( $ghostStoreForDescriptorLFN{$gsfn} );
	}
	else
	{

		# must revisit TODO - the point of this cache is that it shouldn't get too big
		# die "Overflow!" if ((keys %ghostStoreForDescriptorLFN) > 100);

		my $gs = GhostStore->new();

		if( -e $gsfn )
		{
			debug "Reading descriptor [$gsfn]\n" if $tkdebug;
			$gs->slurpDescriptor( $gsfn );
			debug "Incorporating stuff found in [$gsfn]\n" if $tkdebug;
			$self->incorporateGhostStore( $gs );

			# TODO
			# to properly handle identification of deleted files,
			# the ghosts should be added as children to whatever the
			# parent is
		}

		$ghostStoreForDescriptorLFN{$gsfn} = $gs;

		return $gs;
	}
}

# Takes everything we've learned from a ghost store and calls incorporate

sub incorporateGhostStore
{
	my $self = shift;
	my $gs = shift;

  # debug Dumper( $self );

	my @g = $gs->getAllGhosts();
	foreach my $g (@g)
	{
		$self->incorporateGhostData( $g );
	}

  # debug Dumper( $self );
}

# Takes everything we've learned from a ghost and incorporate it
# into our source of truth. 
# as a side effect, this may end up registering new ghosts
# as truthy.

sub incorporateGhostData
{
	my $self = shift;
	my $g = shift;

	my $icDebug = 1;

	my $lfn = $g->lfn();
	my $ghostForLFN = $self->ghostForLFN();

	debug "Incorporating ghost lfn:[$lfn] data $g (self=$self, glfn=$ghostForLFN)\n" if $icDebug;

	if( exists $ghostForLFN->{$g->lfn()} )
	{
		# merge case
		# take the best of both
		# prefer checksum from the newer one
		# use that for the date of the hash

		my $base = $ghostForLFN->{$g->lfn()};

		if( $base->lastFullHash() < $g->lastFullHash() )
		{
			$base->lastFullHash( $g->lastFullHash() );
			$base->fullHash( $g->fullHash() );
			$base->dirty(1);
			debug "  Incorporate - Merger case - existing TK ghost updated\n" if $icDebug;
		}
		else
		{
			debug "  Incorporate -  Merger case - existing TK ghost was fine\n"  if $icDebug;
		}

		$g->isTKversion(0);

		return $base; 
	}
	else
	{
		debug "  Incorporate -  Merger case - non-TK ghost we got is being declared the TK version\n" if $icDebug;

		$self->registerTruthyGhost( $g );
		#$ghostForLFN->{$g->lfn()} = $g;
		$g->isTKversion(1);
		return $g;
	}
}


sub registerTruthyGhost
{
	my $self = shift;
	my $g = shift;

	my $lfn = $g->lfn();

	debug "Register Truthy Thing: [$lfn] -> $g\n" if $tkdebug;

	my $ghostForLFN = $self->ghostForLFN();
	die "Collision [$lfn]" if exists $ghostForLFN->{$lfn};
	$ghostForLFN->{$lfn} = $g;

	my $afn = $g->absoluteLFN();
	my $ghostForAFN = $self->ghostForAFN();
	die "Collision [$afn]" if exists $ghostForAFN->{$afn};
	$ghostForAFN->{$afn} = $g;
}

# Normal logic to get a ghost -- first check if we have it already

sub obtainGhostForLFN
{
	my $self = shift;
	my $lfn = shift;

	my( $handler, $root, $path ) = main::parseFQLFN( $lfn );

	die "LFN is zero length" if ((length $lfn) < 1);
	die "LFN is not a clean string!" if ref $lfn;

	debug "TK:Obtain: obtain f:[$lfn] ($handler)($root)($path)- requested\n" if $tkdebug;

	my $ghostForLFN = $self->ghostForLFN();

	main::assert_cpath( $path );

	if( exists $ghostForLFN->{$lfn} )
	{
		debug "TK:Obtain: obtain f:[$lfn] - found in cache\n" if $tkdebug;
		return $ghostForLFN->{$lfn};		
	}

	# Next look for in global cache (if present)

	# TODO when time comes, implement global cache

	# Next look in local descriptor
	# TODO, this is sort of wrong -- the ghost store is useless for certain types of LFNS
	# really only things pretaining to file system should hit descriptor
	# refactor to move to FSE

	my $gs = $self->getGhostStoreForDescriptorFileCoveringFN($path);
	my $g = $gs->findGhostForLFN($lfn);
	debug "TK:Obtain: obtain f:[$lfn] pulled g:[$g] from ghost descriptor\n" if $tkdebug;
	
	if( defined $g )
	{
		# registration occurs by getGhostStore
		#$self->registerTruthyGhost( $g );
		return $g 
	}

	# Wow, we've totally stuck out here - make a new thing

	debug( "TK:Obtain: Making new ghost for f:[$lfn]\n")  if $tkdebug;
	$g = Ghost->make_private( $lfn );
	# registers 
	$self->incorporateGhostData( $g );
	$g->dirty(1);
	$g->isTKversion(1);
	$gs = $self->getGhostStoreForDescriptorFileCoveringFN( $path );
	$gs->addGhost( $g );
	#$self->registerTruthyGhost( $g );

	debug "TK:Obtain: Made: $g\n" if $tkdebug;

	return $g;
}





##########
#
# GhostIterator -- A helper for iterating over nested directories
# Note: Does not use File::Find! Everything is done through
# ghosts that request subdirectories so this is uber-clean. 
#
####

package GhostIterator;

use File::Basename;
use base qw(Class::Accessor);
GhostIterator->mk_accessors( qw(queue recurse parentGhoststore) );



sub debug($)
{
	my $a = shift;
	main::debug( "GI: " . $a );
}


my $GI_DEBUG = 0; 

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();
	$self->recurse(0);
	return $self;
}

# Gets the next item in the iterator
#
# Behind the scenes, will call nextRaw and handle things in the queue
# that are unexpected

sub next
{
	my $self = shift;
	my $n = $self->nextRaw();

	if( ref $n )
	{
		debug "GI: THUNK received --> $$n\n" if $GI_DEBUG;
		return $self->next();
	}

	# Check for the end-of-queue case
	if( not defined $n )
	{
		debug "GI iterator: Undef case - iterator over\n" if $GI_DEBUG;
		return undef;
	}

	# debug "Next: Got [$n]\n";

	my $tk = TruthKeeper::get();
	my $g = $tk->obtainGhostForLFN( $n );

	return $g;
}

# Internal helper function called when a directory needs to be expanded

sub scanDir
{
	my $self = shift;
	my $g = shift;
 	my $q = $self->queue();	

	# call getChildren
	# getChildren may have these buggers cached
	# caching should be weak
	# if not call up to TK and try to get from GCIP
	# if not FSM->getImmediateChildren;

	my @lfns = $g->getFSE()->getImmediateChildren( $g );

	$g->learnChildrenByLFN( time(), @lfns );

	my @children = $g->getChildren();

 	unshift @$q, \$g;  # add the thunk that will tell us the directory is over
 	unshift @$q, @lfns; # add the files themselves
}

sub nextRaw
{
	my $self = shift;

	my $q = $self->queue();
	my $c = shift @$q;

	if( not defined $c )
	{
		return undef; 
	}

	if( ref $c )
	{
		return $c; 
	}

	# Todo - clean up passing of ghosts back up to parent
	# issue here is that the parentGhostStore only has the top
	# level parents.
	# my $gs = $self->parentGhoststore();
	# my $g = $gs->findGhostForLFN( $c );

	# TODO: two obtains are called, first to check for being a directory
	# second, by next. This could be refined by making the queue
	# able to store both ghosts and LFNs.

	my $tk = TruthKeeper::get();
	my $g = $tk->obtainGhostForLFN( $c);

	debug "GI: Checking [$c]->[$g] for children\n" if $GI_DEBUG;

	# if the next thing is a directory, scan into the directory
	if( $g->canHaveChildren() )
	{
		debug "GI: Scan directory case\n" if $GI_DEBUG;
		$self->scanDir( $g );
	}

	return $c;
}






##########
#
# GhostStore - utility functions for dealing with arbitrary collections
# of ghosts
#
####

package GhostStore;

use File::Basename;
use POSIX;
use base qw(Class::Accessor);
GhostStore->mk_accessors( qw(lfnToGhost clean sizeToFNs) );


sub debug($)
{
	my $a = shift;
	main::debug( "GS: " . $a );
}


my $gsDebug = 0;

sub new
{
	my $class = shift;
	my $self = $class->SUPER::new();
	$self->lfnToGhost( +{} );
	$self->clean(1);

	return $self;
}

sub getDescendingIterator
{
	my $self = shift;

	my $r = GhostIterator->new();
	$r->queue( [ keys %{$self->lfnToGhost()} ] );
	$r->recurse(1);
	$r->parentGhoststore( $self );
	return $r;
}

sub countDirty
{
	my $self = shift;

	my $i = 0;

	map {$i++ if $_->dirty() > 0 } $self->getAllGhosts();

	return $i;
}

sub findGhostForLFN
{
	my $self= shift;
	my $lfn = shift;

	my $lfnToGhost = $self->lfnToGhost();

	if(exists $lfnToGhost->{$lfn} )
	{
		debug "   Found inside ghoststore\n" if $gsDebug;
 		return $lfnToGhost->{$lfn};
 	}

 	return undef;
}

sub purifyAllGhostsToTK
{
	my $self = shift;
	my $tk = TruthKeeper::get();
	my $lfnToGhost = $self->lfnToGhost();

	foreach my $g (values %$lfnToGhost)
	{
		if( $g->isTKversion() == 0 )
		{
			debug "GhostStore: ***** PURIFY $g->lfn()\n" if $gsDebug;
			my $n = $tk->obtainGhostForLFN( $g->lfn() );
			$lfnToGhost->{$n->lfn()} = $n;
		}
	}
}

sub getAllGhosts
{
	my $self = shift;
	my $lfnToGhost = $self->lfnToGhost();
	return values %$lfnToGhost;
}

sub addGhost($)
{
	my $self= shift;
	my $g = shift;

	my $lfn = $g->lfn();
	my $lfnToGhost = $self->lfnToGhost();

	warn "Something wrong lfn:$lfn" if $lfn eq ".";
	warn "Something wrong lfn:$lfn" if $lfn eq "..";

	debug "GhostStore: Adding ghost $g (lfn=$lfn) (lfntoghosthash=$lfnToGhost gs_self=$self) ghoststore\n" if $gsDebug;

	if( exists $lfnToGhost->{$g->lfn()} )
	{
		die "GhostStore: Boundary case - adding ghost where one already existed" if $gsDebug;
	}

	$lfnToGhost->{$lfn} = $g; 

	return;
}

# Pulls in the descriptor listed 

sub slurpDescriptor($)
{
	my $self = shift;
	my $fn = shift;

	debug "GhostStore: Slurping descriptor [$fn]\n" if $gsDebug;

	die "Assert: $fn should be a path" if not main::assert_regularpath( $fn );

	my( $parsedFn, $dir ) = fileparse( $fn );

	my $treebase = $dir; 

	$self->slurpSerializedStore( filename => $fn,
								 treeRoot => $treebase );

	# At this point, our ghosts are not linked to the TK, they are just versions of possible truth

	$main::run_descriptors_read++;
}

sub slurpSnapshot
{
	my $self = shift;
	my $fn = shift;
	my $root = shift;

	$self->slurpSerializedStore( filename => $fn,
								 snapshotRoot => $root );
}


sub slurpSerializedStore
{
	my $self = shift;
	my %opt = @_;

	my $fn = $opt{filename} or die "Filename not provided to slurp!";

	my %seen;

	open( FILE, "<$fn") or die "Cannot open $fn to slurpSerializedStore";

	while( <FILE> )
	{
		chomp;
		debug "GhostStore: Slurping: [$_]\n" if $gsDebug;

		if( /^###/ )
		{
			next;
		}

		if( /^@@@\s*(\w+)\s*\=\s*(.*)/ )
		{
			my ($name, $value) = ($1,$2);
			debug "DESCRIPTOR: $name --> $value\n" if $gsDebug;

			if( $name eq 'version' )
			{
				debug "Comparing version $SERIALIZATION_VERSION_NUMBER to [$value]\n" if $gsDebug;

				if( $SERIALIZATION_VERSION_NUMBER != ($value+0) )
				{
					die "Version mismatch in $DESCRIPTOR_FILENAME: $SERIALIZATION_VERSION_NUMBER != [$value] -- the descriptor version is wrong. Delete the old descriptors to continue.";
				}
			}

			next;
		}

		my $g = Ghost->newFromSerialized( $_, %opt );
		$g->isTKversion(0);
		$self->addGhost( $g );

		die "Ghost descriptor contains duplicates - some logic problem - see [$fn]!" if( $seen{$g->lfn()}++ > 0 );
	}

	close( FILE );
}





sub writeAsDescriptor($)
{
	my $self = shift;
	my $fn = shift;

	my $lfnToGhost = $self->lfnToGhost();

	open( FILE, ">$fn") or die "Cannot open file[$fn] to write descriptor: $!";

	my $date = strftime( "%c", localtime() );

	print FILE "### This is a checksum tracking file written by $0\n";
	print FILE "### File written on $date\n";
	print FILE "### \n";
	print FILE "### To remove this and others like it, try this command\n";
	print FILE "###    find . -name '$DESCRIPTOR_FILENAME' -print0  | xargs -0 rm -iv\n";
	print FILE "### \n";
	print FILE "@@@ version = $SERIALIZATION_VERSION_NUMBER\n";
	print FILE "### \n";

	foreach my $g ( values %$lfnToGhost )
	{
		print FILE $g->serialize( pathMode => "basename");
		print FILE "\n";

		if( $gsDebug )
		{
			my $lfn = $g->lfn();
			debug "    WAD: Write ($lfn):";
			debug $g->serialize( pathMode => "basename");
			debug "\n"
		}
	}

	close( FILE );

	debug "    WAD: Wrote descriptor -> $fn\n" if $gsDebug;

	$main::run_descriptors_write++;
}


sub writeSnapshotToDisk
{
	my $self = shift;
	my $fn = shift;

	$self->writeSerializedToDisk( $fn, pathMode => 'localized' );
}

#  TODO combine codebase with descriptors

sub writeSerializedToDisk($)
{
	my $self = shift;
	my $fn = shift;
	my %options = @_;

	my $lfnToGhost = $self->lfnToGhost();

	open( FILE, ">$fn") or die "Cannot open $fn to write snapshot or descriptor";

	my $date = strftime( "%c", localtime() );

	print FILE "### This is a snapshot, written by the tool $0\n";
	print FILE "### File written on $date\n";
	print FILE "### It is a record of all of the files stored at a point in time\n";
	print FILE "### The gfs tool can use this to reconstruct this file tree later\n";
	print FILE "### \n";
	print FILE "@@@ version = $SERIALIZATION_VERSION_NUMBER\n";
	print FILE "### \n";

	foreach my $g ( values %$lfnToGhost )
	{
		print FILE $g->serialize( %options );
		print FILE "\n";
	}

	close( FILE );

	debug "Wrote snapshots -> $fn\n";
}

sub loadSizeCache
{
	my $self = shift;

	my $h = {};
	# my $tk = TruthKeeper::get();

	my $iterator = $self->getDescendingIterator();

	debug "GS-Generating size cache\n";

	while( my $g = $iterator->next() )
	{
		next unless $g->isFile();
		my $size = $g->getSize();
		next if $size <= 0;

		if( $gsDebug )
		{
			my $lfn = $g->lfn();
			debug "GS - Size Cache lfn:[$lfn] -> $size\n" 
		}

		push @{$h->{$size}}, $g;
	}


	$self->sizeToFNs($h);

}

sub findFilesWithSize
{

	my $self = shift;
	my $s = shift;

	return undef if( $s <= 0 );

	if( not defined $self->sizeToFNs() )
	{
		$self->loadSizeCache();
	}

	my $lu = $self->sizeToFNs()->{$s};

	return +() if not defined $lu;

	return ( @{$lu} );
}

# Returns all ghosts other than the one passed that is a hash duplicate

sub findOtherDuplicates
{
	my $self = shift;
	my $g = shift;

	return grep { not $g->isSameFilename($_) } $self->findAllDuplicates($g);
}

# Returns every known ghost named in this collection that is a duplicate

sub findAllDuplicates
{
	my $self = shift;
	my $target = shift;

	my $size = $target->getSize();

	return () if $size < 1; 

	# First, check our size cache for a match
	my @otherFN = $self->findFilesWithSize( $size );

	return if @otherFN < 1;

    debug " -- Checking size duplicates size:[$size]\n" if $gsDebug;

	my @matches;

	foreach my $gc ( @otherFN )
	{
		next if $gc->isSameFilename( $target );

		if( $fseDebug )
		{
			my $cFN = $gc->lfn();
			my $tFN = $target->lfn();

			if( $gsDebug )
			{
				debug "     -- Checking size duplicates size:[$size]\n";
				debug "     ---> cfn:[$cFN]\n";
				debug "  vs ---> tfn:[$tFN]\n";
				}	
		}

		if( $target->isDuplicateOf( $gc ) )
		{
			push @matches, $gc;
		}
	}

	return @matches;

	# return @matches;
}






##########
#
# Ghost - an imprint of a file that may or may not exist at a particular place
#
# The ghost is a carrier of information about a file, and intended to be lightweight
# More than one ghost can exist for a given file, and they can be different
# to obtain an "authoritiative" ghost, the TruthKeeper is used to resolve them
# for instance a snapshot could have one version of a ghost, a descriptor a different
# and the one from the file system could yet again be different. Ghosts are intended
# to be so lightweight that they can be used as proxies for filename everywhere
# as of the "everthing-is-a-ghost" update, ghosts are used universally to handle
# files. 
#
# The ghost class does not itself hit the disk - everything is delegated to the FSE
#
# Terminology used in function names has some nuance
#
# -     size() - the internal size descriptor, never use this!!
# GET   getSize - gets an ACCEPTABLE size
# LEARN learnSize - tell me that you've definitively got a new size from disk
# MERGE mergeSize(g) - learn whatever I can from the ghost, update myself with the
# newest information 
#

package Ghost;

use File::Basename;
use base qw(Class::Accessor);

use Cwd qw(abs_path); # best way to get these



sub debug($)
{
	my $a = shift;
	main::debug( "G: " . $a );
}


# GHOST_NEW_FIELD: Place 4/4 where you add new fields to ghosts

Ghost->mk_accessors( qw(lfn lastFullHash size mode fullHash 
	dirty isTKversion lastDirScan lastStat mtime lastEnumerated firstStat fileStatus
	 children) );

my $serializeDebug = 0;
my $gChildDebug = 0;

sub newFromSerialized($)
{
	my $class = shift;
	my $str = shift;
	my %options = @_;

	my $self = Ghost->new();

	my @a = split ':', $str;

	@a = map {main::gfs_unescape($_)} @a;

	my $serialLFN = shift @a;

	if( defined $options{'treeRoot'} )
	{
		my $root = $options{'treeRoot'};

		$serialLFN = main::rewriteLFNwithLeadingDirectory( $serialLFN, $root );

	}



	# GHOST_NEW_FIELD: Place 1/4 where you add new fields to ghosts

	$self->lfn( $serialLFN );
	$self->lastFullHash( shift @a );
	$self->size( shift @a );
	$self->mode( shift @a );
	$self->fullHash( shift @a );
	$self->lastDirScan( shift @a );
	$self->lastStat( shift @a );
	$self->lastEnumerated( shift @a );
	$self->firstStat( shift @a );
	$self->fileStatus( shift @a );
	$self->mtime( shift @a );

	$self->dirty( 0 );
	$self->isTKversion( 0 );

	if( $serializeDebug )
	{
		debug "Just deserialized: ";
		debug $self->printDebug();
		debug "\n";
	}	

	return $self;

}

# getFSE - returns whatever FSE object is best for this thing

sub getFSE
{
	my $self = shift;
	my $lfn = $self->lfn();
	die unless defined $lfn;

	my $fse = FSEFactory->getFSEHandlerForGhost( $self );



	return $fse; 
}

sub getChildren()
{
	my $self = shift;

	if( not defined $self->children() )
	{
		die "Corner case - someone didn't teach me my children";
	}

	if( not ref $self->children() )
	{
		die "Corner case - someone didn't teach me my children";
	}

	# TODO - should this be weak?
	# if so, how to handle orphans?
	return @{$self->children()};
}

# Caller is giving us a complete list of our children from primary source
# Mark the deleted ones and perform other flags

sub learnChildrenByLFN()
{
	my $self = shift;
	my $time = shift;

	my @lfns = @_;

	my $tk = TruthKeeper::get();

	# Ideally, we call getChildren and do some sort of "merge"

	my @existingGhosts =  ref $self->children() ? @{$self->children()} : ();

	debug "Existing ghosts @existingGhosts\n" if $gChildDebug;

	my %seenLFN;
	my @newKids;

	foreach my $e (@existingGhosts)
	{
		 $seenLFN{ $e->lfn() } = 0;
	}

	foreach my $lfn ( @lfns )
	{
		debug "G: Learning child: lfn:[$lfn]\n" if $gChildDebug;
		if( exists $seenLFN{$lfn} )
		{
			debug "G:   Child already registered\n" if $gChildDebug;
		}

		$seenLFN{$lfn}++;

		my $g = $tk->obtainGhostForLFN( $lfn );
	
		# inform ghost that it has been seen in a directory scan
		# this also undeletes it
		$g->learnDirscan($time);
		push @newKids, $g;
	}

	foreach my $lfn ( keys %seenLFN )
	{
		if( $seenLFN{$lfn} < 1 )
		{
			debug "G:   Child has disapeared\n" if $gChildDebug;
			my $g = $self->tk()->obtainGhostForLFN( $lfn );
			$g->learnDeleted($time);
		}
	}

	$self->children( \@newKids );
}

# canHaveChildren() - True if we can descend with a call to "getChildren"

sub canHaveChildren
{
	my $self = shift;

	# debug "Fetching type\n";

	my $type = $self->getType();

	# debug "Type is: $type\n";

	# base case: no knowledge or hash

	if( $type eq 'd' )
	{
		return 1;
	}

	return 0;
}

sub printDebug
{
	my $self = shift;

	# GHOST_NEW_FIELD: Place 2/4 where you add new fields to ghosts

	my $lfn = $self->lfn();
	my $lastFullHash = $self->lastFullHash();
	my $size = $self->size();
	my $mode = $self->mode();
	my $fullHash = $self->fullHash();
	my $lastDirScan = $self->lastDirScan();
	my $lastStat = $self->lastStat();
	my $mtime = $self->mtime();
	my $lastEnumerated = $self->lastEnumerated();
	my $firstStat = $self->firstStat();
	my $fileStatus = $self->fileStatus();

	# not technically a field but we should include this
	my $type = $self->getType();

	debug "ghostDump: lfn:[$lfn] type:[$type] mode:[$mode] lFH:[$lastFullHash] full:[$fullHash] ldirscan:[$lastDirScan] lastfullstat:[$lastStat] size:[$size] mtime:[$mtime]\n";
}

sub isSameFilename
{
	my $self = shift;
	my $other = shift;

	my $fn1 = $self->lfn();
	my $fn2 = $other->lfn();

	# After some testing, it appears that abs_path (also see realpath(3)) 
	# is the very best way to test for complete filename equivilence
	# The testing read-out is below and turned off for now

	if( 0 )
	{
		debug "Checking if two files are the same filename:\n";
		debug "   me: [$fn1]\n";
		debug "   tg: [$fn2]\n";
	  
	  	my $cwd1 = abs_path( $fn1 );
	  	my $cwd2 = abs_path( $fn2 );

	 	debug "Using Cwd Abs_path:\n"; 
	  	debug "   me: [$cwd1]\n";
		debug "   tg: [$cwd2]\n";

	  	my $abs1 = File::Spec->rel2abs( $fn1 );
	  	my $abs2 = File::Spec->rel2abs( $fn2 );

	 	debug "Using rel2abs:\n"; 
	  	debug "   me: [$abs1]\n";
		debug "   tg: [$abs2]\n";
	}

	die "Incomplete info self-size" if not defined $self->lfn();
	die "Incomplete info other-size" if not defined $other->lfn();

	# TODO: revisit if perl libraries give a better way to do this

	return 1 if $self->absoluteLFN() eq $other->absoluteLFN();
	return 0;
}

# Returns a fully cleaned up absolute path name for this file
# Initial testing has shown this handles foo/../../ properly, etc
# probably requires a ton of stats in cases where there are ..
# but doesn't appear to be too onerous for usual path names

sub absoluteLFN
{
	my $self = shift;
	return main::rewriteLFNPathAbsolute($self->lfn());

}

sub isDuplicateOf
{
	my $self = shift;
	my $other = shift;

#	die "Incomplete info self-size" if not defined $self->size();
#	die "Incomplete info other-size" if not defined $other->size();

	return 0 if( $self->getSize() ne $other->getSize() );

#    die "Incomplete info self full hash" if not defined $self->fullHash();
#	die "Incomplete info other full hash " if not defined $other->fullHash();


	return 0 if( $self->getFullHash() ne $other->getFullHash() );

	return 1; 
}

sub serialize()
{
	my $self = shift;
	my %options = @_;

	my $lfn = $self->lfn();

	#debug "Serialize $self\n";

	if( exists $options{'pathMode'} and $options{'pathMode'} eq 'basename' )
	{
		$lfn = main::rewriteLFNPathToBasename( $lfn )

	}

	# GHOST_NEW_FIELD: Place 3/4 where you add new fields to ghosts

	my @s = ( $lfn, 
			  $self->lastFullHash(),
			  $self->size(),
			  $self->mode(),
			  $self->fullHash(),
			  $self->lastDirScan(),
			  $self->lastStat(),
			  $self->lastEnumerated(),
			  $self->firstStat(),
			  $self->fileStatus(),
			  $self->mtime()
			  );

	@s = map {main::gfs_escape($_)} @s;

	my $s = join ':', map { defined $_ ? $_ : '' } @s;

	return $s;
}

# as of refactor, only TK is really allowed to called this

sub getHandler
{
	my $self = shift;
	my ($handler, $root, $path ) = main::parseFQLFN( $self->lfn() );
	return $handler;
}

sub getRoot
{
	my $self = shift;
	my ($handler, $root, $path ) = main::parseFQLFN( $self->lfn() );
	return $root;
}

sub getPath
{
	my $self = shift;
	my ($handler, $root, $path ) = main::parseFQLFN( $self->lfn() );
	return $path;
}


sub make_private($)
{
	my $class = shift;
	my $lfn = shift;

	my $self = $class->new();

	# debug "Ghost: Making ghost for lfn=[$lfn]\n";

	$self->lfn( $lfn );

	return $self;
}

sub make
{
	die "Assert - old code, warning!!";

}

# Forces the key fields to be loaded if they aren't already known
# Does not recheck them against the disk unless the standard

# TODO: implement size and fasthash

sub forceCharacterization
{
	my $self = shift;

	$self->getFullHash();
	$self->getSize();
	# $self->getFastHash();	
}

sub hasAcceptableFullhash
{
	my $self = shift;

#	debug "Checking if I like my hash\n";

	return 0 if( not defined $self->fullHash() );
	
	if( defined $main::GUARD_TIME_SECONDS )
	{
		my $age = $main::SCRIPT_START - $self->lastFullHash();

		if( $age > $main::GUARD_TIME_SECONDS )
		{
			debug ( join '', "Forcing hash recalculation (", main::expressRelativeTime( $age ), ")\n");
			return 0; 
		}
	}

	return 1;
}

# returns an acceptable fullHash for the ghost
# Normally, the latest cached data is trusted, but
# this function can be set to take a out of data criteria in future TODO

sub getFullHash
{
	my $self = shift;

	if( $self->hasAcceptableFullhash() )
	{
		return $self->fullHash();
	}
	else
	{
		return $self->getFullHashSourceVerify( time() );
	}
}


sub hasAcceptableStat
{
	my $self = shift;

	return 0 if( not defined $self->size() );
	return 0 if( not defined $self->mtime() );
	return 0 if( not defined $self->mode() );

	if( defined $main::GUARD_TIME_SECONDS )
	{
		my $age = $main::SCRIPT_START - $self->lastStat();

		if( $age > $main::GUARD_TIME_SECONDS )
		{
			debug (join '', "Forcing recalculation (", main::expressRelativeTime( $age ), ")\n" );
			return 0; 
		}
	}


	return 1;
}


# TODO factor out hasAcceptable patttern into "bringStatToDateIfNeeded()"

sub getMode
{
	my $self = shift;

	if( $self->hasAcceptableStat() )
	{
		return $self->mode();
	}
	else
	{
		$self->getStatSourceVerify( time() );
		return $self->mode();
	}	
}

sub getSize
{
	my $self = shift;

	if( $self->hasAcceptableStat() )
	{
		return $self->size();
	}
	else
	{
		$self->getStatSourceVerify( time() );
		return $self->size();
	}	
}

sub getMTime
{
	my $self = shift;

	if( $self->hasAcceptableStat() )
	{
		return $self->mtime();
	}
	else
	{
		$self->getStatSourceVerify( time() );
		return $self->mtime();
	}	
}

# Dirscan means that we have seen the ghost in a directory scan
# TODO also update a "firstSeen" field.
# If deleted, this should undelete by delegating to learnPresent

sub learnDirscan
{
	my $self = shift;
	my $time = shift; 

	$self->lastDirScan( $time );

	# TODO: Do we want a dirscan to always force an update to the ghost?
	# With this next line commented out, a new directory scan will not by itself
	# force an update
	# $self->dirty(1);

	$self->learnPresent( $time );
}

# Should undelete the file

sub learnPresent
{
	my $self = shift;
	my $time = shift; 

	# TODO: implement field
}

# Deleted means that we did not see the ghost
# on a recent scan. Mark as deleted and set deleteDate.

sub learnDeleted
{
	my $self = shift;
	my $time = shift; 

	$self->lastDirScan( $time );

	# TODO: Do we want a dirscan to always force an update to the ghost?
	$self->dirty(1);
}

use Fcntl ':mode';

sub extractTypeFromMode
{
	my $self = shift;
	my $mode = shift;

	return 'f' if S_ISREG($mode);
	return 'd' if S_ISDIR($mode);
}

sub isFile
{
	my $self = shift;
	return 1 if $self->getType() eq 'f';
}

sub getType
{
	my $self = shift;
	my $mode = $self->getMode();
	return $self->extractTypeFromMode( $mode );
}

sub learnFullHash
{
	my $self = shift;
	my $time = shift;
	my $hash = shift;

	# TODO - merger and revocation case here

	$self->lastFullHash( $time );
	$self->fullHash( $hash );
	$self->dirty(1);
}

sub getFullHashSourceVerify
{
	my $self = shift;
	my $time = shift;

	die "Full hash not implemented for directories" if( $self->canHaveChildren() );

	my $fullhash = $self->getFSE()->getFullHashSourceVerify( $self );
 	$self->learnFullHash( $time, $fullhash );

	return $fullhash;
}

sub learnStat
{
	my $self = shift;
	my $time = shift;

	my $size = shift;
	my $mtime = shift;
	my $mode = shift; 

	# TODO - merger and revocation case here

	$self->size($size);
	$self->mtime($mtime);
	$self->mode($mode);

	$self->lastStat( $time );

	$self->dirty(1);
}

sub getStatSourceVerify
{
	my $self = shift;
	my $time = shift; 

	my ($size, $mtime, $mode) = $self->getFSE()->getStatSourceVerify( $self );
 
	$self->learnStat( $time, $size, $mtime, $mode );

	return undef;
}


###

main::main();
exit();



