

immutable - basically means the ghost's truth state cannot change
for instance, in the case of a snapshot

virtual - we don't know if its "real" or not. its a taint check basically

things you pass on the command line should start out virtual

things that are not virtual are 'confirmed'.

they could be deleted, present, missing, etc

but to not be virtual, someone somewhere has to either deserialize them
from the past, or find them authoritatively on disk 

that way we don't contaminate the pool of ghosts

if the program that the user is asking to run cannot track down a confirmed ghost,
they can decide what to do (it's basically a file not found.)



# How do ghost work when they cross into the world of snapshots?

hah, interesting issue: what ghosts shpuld we pull from a snapshot? its
written as a bunch of fs:root: things... so  pulling them straight out of the
file contaminates the truth store.

but really, as a snapshot, we need to load it as virtualized objects, in their
world now, they are in a different name space

raises another question: boundary case -if you snapshot a snapshot, what
should happen? - i think the right thing is to either save a snapshot with
rewritten LFNs or to change the LFNs when loading

DECISION: I think its more correct to do on writing, e.g. -> convert  to snapshot LFNs
during the write operation

this requires new FSE semantics
should we think of a snapshot operation as a push into a filesystem?

YES

make a ghost for the snapshot-to-be
mkae FSE
FSE->addObject( $g );
	clone the ghost and re-write the LFN
	make them immutable
FSE->finalize();

we probably will need similiar semantics on object stores



# Interesting hanging chad around ghosts

say you want to write a snapshot to a new place. you get a ghost for
[snap:snapshot-5419.out:] and get the FSE to write to it. You store some
objects in it, and finalize the FSE. But there is a significant gap - what is
the purpose of [snap:snapshot-5419.out:]? Does it need to be finalized?

it is technically a valid path. its a valid thing in the world. its the head
position of a snapshot. its even been read and written to a few times. the
ghost represents a real thing, and you could potentially even want to do an LS
on it later.  so who is supposed to write it to disk?



# root renames on snapshot loads

a strange corner case - you write out a snapshot, a bunch of ghosts.  what is
the proper root of the snapshot file? Its actually not clear what that should
be. for instance:

	gfs snapshot foo bar -> snapshot123.snap

	gfs ls snap:snapshot123.snap:foo snap:snapshot123.snap:bar

	cp snapshot123.snap jeremy.snap

	gfs ls snap:jeremy.snap:foo

Technically, the root here was just a transitory thing. Its basically an local
relative filename. 

Design decision: The written version will always just be "root". 

but on LOADs, we'll rewrite the LFNs/root so they make sense to the user.


# Dealing with the obnoxiousness of absolute paths and snapshots

We decided earlier that the permanent root of a snapshot is the hash of the file
that stores it. This seems to work well for git(1). But what happens with the 
framework wants an absolute LFN before its written? Current design decision is
this is not allowed.

this is a pretty wide ranging issue, turns out. Say I invoke the following

	gfs ls snap:snapshot-5803.out:quxx

technically, "snap:snapshot-5803.out:quxx" will trigger creation of a FSE 
all of these ghosts are sort of not real.

ghosts that are not real should never be attempted to convert to AFNs? is that
true? they certainly shouldn't find their way into a persistent store. if that
were true, the truthkeeper has to learns that it is actualized, and thats when
it does and AFN test.





# What is a ghost?

The basic object is a ghost. A ghost is a description of some object
discovered "for real" in the filesystem somewhere.

Things we track for ghosts:

FULLHASH - SHA of the bytestream (aka ghosthash)
FASTHAD - fast SHA of bytestream (empty if not present)
LASTMOD - last modified date from FS
DT_FULLHASH - last full verify
DT_FASTHASH - last fast verify
DT_DISC_OLD - oldest date of discovery
DT_DISC_NEW - newest date of discovery
LFN - one or more pathnames for ghosthash

my $ghost = makeOrFindGhost( LFN );

$GHOST->[FULLHASH];

writeGhostDescriptor( path, GHOST );

A .ghostdesc file is a list of the above entities of information. It is
basically serialized ghosts which have very local basenames for paths. 

The ghoststore is an abstraction around a collection of ghosts there can be
different implementations the most basic one is just a hashing container that
is as lazy as possible.


# About LFNS

LFN - local file name - whatever is colloquial to the USER to
describe something. LFNs can never presume to be universally unique between
invocations of GFS because they may be relative paths or tags/references may
change. But the user's maximal intent must be captured in the LFN.

	for instance fs:a depends on your CWD
	for a different PWD, fs:a could refer to a different file

However, there are many different handlers.

	/foo
	fs:/foo
	snap:foo.snap:file123
	remote:jgilbert@auspice.net:file123

In this case, the "LFN" is a composite of a handler, a root and a path. The
user may provide some or all of these peices on the command line. We need to
be be able  to intelligently construct the rest.

LFN's can be fullqualified, which means fully specify the missing strings and
to canonicalized the path.

To determine if two LFNs are the same inside one running instance of GFS, the
only way to do it is to canonicalize that path portion both to remove . and
../ etc. Then you need you make sure to attach the ROOT and the HANDLER.

across instances, the only way is to convert to an AFN (absolute file name)
The AFN is a unique permanent name for the location

FQAFN - fully qualified AFN: handler:root:afn
FQLFN - fully qualified LFN: handler:root:path (can be local)

snapshots will generally represent LFNs, typically from the point of view of
the PWD but their power is that they should NOT be foreced to contain AFNs -
the snapshot could be  reconstructed anywhere and we'll leave it to the user
to either feed a snapshot the AFNs or the LFNS.

in the nested case, assume the following data is stored

	snap:testdir/snapshot.gfssnap:
	snap:testdir/snapshot.gfssnap:a
	snap:testdir/snapshot.gfssnap:b

in this case, the LFN of the snapshot file itself is testdir/snapshot.gfssnap

So LFNs are designed to hold three peices of information, and together forms a
unique namespace.


# What is truth? What is the single source of truth?

Ghost is a description of the potential state of a file.

Currently, contracts look like this

- No obligation for a specific ghost to be up to date
- Only the ghosts from the TK are guarnteed to be single source of truth
- Ghosts find their FSE by looking at their handler value
- Ghosts can be in any number of ghost stores
- TruthKeeper should make all ghosts that are intended to hold present state
- The only reason TK is not used to make ghosts is in cases where you are deliverably
- TK holds all ghost pointers and knows if they are dirty or not
- Generally, the FSE doesn't hold links back to ghosts except in cases where a ghost is a root (like a snapshot)


# design ideas for object stores
object store concepts

a blob always has the hash of the file it saves - the header (everything up to the first null) can be anything


# Revocation rules and timing


we need to not be in a situation where the fullhash has changed but
the stat stays the same
scenario - two ghosts pointing to same file
ghost A has Ha and Sa (hash and stat)
ghost B has Hb and Sa

if Hb is later that Ha, we'd be confused - how could both stats be identical but the hash has changed?
contract should be
getStat
getHash
getStat

if stat is the same both times, than take the timestamp and report it for both

also implies the "learn" semantic should always be accompanied by a date
and not generated inside the routines'

(merge case)

A new stat does not mean that a hash is out of date. The stat date should be used for resolving which of two stats is most accurate. 

stat fields should be taken all or nothing. 

The only cause for revoking a hash is when the size has changed or last modification date has changed. 

The revocation should not be immediate. It can be lazy. Maybe an optional warning. But the next time anyone asks for a hash on that file, we'd be forced to get one. 

Ghosts should never revoke other ghosts. Let that semantic rest with truth keeper. TK will just ask for incorporation in direction it wants. 

If you ask for a ghost that has no authoritative record is should be marked as virtual. 

One sanity check is that the virtual ghost should not be written to disk under normal cases. 




+++++++++++


# gfs snapshot .
# generates a snapshot file

# gfs condense /etc /var snap:barf.gs
# gfs condense snap:barf.gs snap:arf.gs snap:new.gs

# will reconstruct using known afns, keeps orphans
# gfs reconstruct --test snap:barf.gs foo/
# 150 files reconstructed, 4 not located (see gfsrun.3234.orphaned.txt for details)

# make symlinks rather than copy files
# gfs reconstruct --symlink 

# uses xxx and yyy as hash sources
# gfs reconstruct --test snap:barf.gs foo/ --source=xxx --source=yyyy

# verify all descriptors in /etc
# gfs verify /etc

# creates a GFS entity that can be pushed to
# gfs gfs create /etc gfs:foo.gfs

# gfs gfs push /etc gfs:foo.gfs
# makes sure that /etc can be reconstructed by gfs:foo.gfs

# gfs gfs add gfs:goo.
# a .gfs file can contain storage and 




+++++++++++++++++


seems like the best separation of concerns is a new idea:

FSE is really about the interface to a collection of files
TruthKeeper is the module that generates ghosts
it also tracks when ghost records are stale and may need to be pushed out to new places


+++++++++++++++++




Definitions:

	Source: A place to take things from, but must remain untouched
	Auxiliary|Pillage: A place we don't give a shit about and okay to move things

+++++




Thats sort of annoying, right? 

Everything is a ghost refactor. In this design, ghosts are interachanable with filenames
and FSE is really stripped down

M: main
FSE: Filesystem manager
	getStat
	getFullHash
	listDirectory
	copy
	move

G: Ghost
	getSize()
	learnSize() - accomodate potentially new information
	learnStat
TK: Truthkeeper
GS: Ghoststore


1-How do .gcpip files get populated initially?
2-How does .gcip file change when contents is changed?
3-How does a snapshot work?

	gfs snapshot filea fileb

	main: gs = TK->makeGhostsFromCommandline( @ARGV );
			obtainGhostForLFN( shift @ARGV )
				look inside our local run cache for these ghosts first
				if not, pull in the ghoststore of the parent using existing functions
		i = gs->getDescendingIterator(); - populate this GhostIterator with a queue of the roots
		g = i->next();
			pop queue 
			if( g->hasChildren() )
				g->getChildren()
					getChildren finds out the last time dirent was populated
					    if ok, then TK->getCachedChildren( g );
					    	load the .gcip file
					    if not ok, children = FSM->getImmediateChildren( g )
					    		this function opens the directory, does a full scan,
					    		and creates a ghoststore 
					    		calls TK->makeGhostForLFN( "fs:" . thingWeFindInDir)
					    	g->learnChildrenPresent( children );
					    		setChildrenMarkPresent now scans the known children
					    		marking those that aren't found as "not present"
					    		and setting the lastDirEnt date
			onThunk
				g->finalizeChildrenPresent()
					computes the hashes of names and subhashes
					populates lastHashDate() 
					g->learnFullHash(X);
						if different, sets dirty flag
						if date different, sets it, and sets dirty flag
					g->flush();
						Tk->flush() - called on thunk only for directory case
						writes out the gcip file and cleans the dirty flag
		g->forceCharacterize();
			checks all of its fields. For those that don't seem right, 
			we call the FSM -> retrieveFullHashHard
							-> retrieveStatHard




	gfs lsdup dirA dirB
	$sourceGS = TK->makeFromCommand( @argv sources)
	$targetGS = TK->makeFromCommand( @argv dest)

	$targetGS->getDescendingIterator();
	foreach( my $g = getNext() )
		$sourceGS->findAllDuplicates( $g );
			my @sizeMatches = $gs->findFilesWithSize( $size );
				@matches->isDuplicateOf( $g )



###


++++

RSYNC implementation ideas

gs = ghoststore of source
for each file in ghoststore
	get a full snapshot of the remote directory + its pillage/spare places + aux places
	get a full snapshot of the source directory
	identify corresponding path in target to match rsync exactly
		A. There is a file fT already sitting at TARGET at this filename
			A1. The hash of fT is correct - its what we want
				-- Mark TARGET fT as claimed, no action needed, go to next file
			A2. The hash is not correct
				-- Mark as orphaned, select new orphaning location - during clearance MOVE phase (will be moved out first)
				-- Flow down to Case B
		B. There is no file at the remote location in TARGET tree at that filename, or the file in TARGET is marked orphaned
			A1. There is no hash ANYWHERE at TARGET, PILLAGE, AUX, COPY or ORPHAN
				-- Queue for remote copy, function done
			A2. There is a hash available in PILLAGE that is not claimed
				-- Queue move PILLAGE -> fT, claim it
			A2. There is a hash availble in ORPHAN that is not claimed
				-- Queue clearance move ORPHAN -> fT (assign new location) - DONE  (What about case of a swap..?)
			A3. There is a hash available in TARGET that is claimed
				-- Queue local copy, done
			A4. There is a hash available in AUX
				-- Queue local copy, done
			A5. There is a hash available in PILLAGE that is claimed
				-- Queue local copy, done
			A6. There is a hash available in COPYLIST
				-- Queue local copy, done

First do all clearance moves
Then do all remote copies
Then do all local copies

Internal commands we need:

action_clearanceMove( $s, $d )
	mark $s as empty, $s->deleted()
	mark $d with new ghost by cloning and assigning new LFN

action_remoteCopy( $s, $d )
	mark $d 

action_localCopy


FileOpPlan
	knows how to record activities
	knows how to check for conflicts
	knows how to start work and verify its proceeding as planned
	fires actual actions over to the FSE in sequence
	copy
	move
	copyIntoObjectFormat
	
We need to insist on a contract that STATs are repeated during full hash
this is going to be done anyway by the OS
also a guard if the file changes and the original stat and hash fall out of sync





virtual ghosts
==============

gfs ls a b c 

will try to obtain equivilent of the following

gfs ls fs:a fs:b fs:c

but a b and c may not exist!

until a successful stat, they should be marked as a status = v
virtual should not get stored anywhere

whereas if you do a gfs ls . in a directory that has a b and c

in this case, a b c come from a scan, which by definition is not virtual
see?




so we create some virtual ghosts along the way
every time the operation is done, we should commit them (take off their virtual flag?)

maybe we just have a notion of copies or moves, and later we decide if they are local or remote?

need to check $g->isPathUnder($y);

next steps could occur in parallel
	begin copying over files we think are net new in reverse mtime order
	begin verification download (basically, get a snapshot of the remote FS)


PUSH looks different.. Push just says that we're going to move over things we think weren't there
into a "pushed-content" subdirectory
we could get things wrong but better for an offline situation

gsf accept pushed-content-1234 is used to rearrange the tree

maybe we have concept of a library
technically snapshots, orphans, pushes, etc could all be objects

GFS-library/objects
GFS-library/primay
GFS-library/orphans
GFS-library/pushes
GFS-library/snapshots
GFS-library/snapshots/Latest->xxx

need a flag on a blob if is is a moved file, or just some junk that GFS maintained
otherwise, cleanup on aisle three situation is shitty

maybe object syntax is as simple as foo/bar/this@234abc32a993, 
this syntax always means a file with this hash under that tree

how do we create definitive names for things and spread them around?
seems like git just stores things in namespace/xxx format

refs/tags/xyz


GFS objects


# design decision - where should domains be stored? How do they nest?

fs:/a -> /a

do we store fs:/a in the lfn?
or do we split into a separate field like domain?
my temptation is to split them

that decision would result in these definitions:




# so what should be cached?

technically the B file's only LFN inside the invocation is: snap:testdir/snapshot.gfssnap/b
what is the AFN?
I suppose it must be 
/home/jgilbert/testdir/snapshot.gfssnap/b

but what if snapshot.gifssnap moves?

The funny thing in the case of a snapshot is that snapshot.gfssnap is 
probably not going to change

so you'd be good actually saying the AFN is: snap:423fe15a4757767bb4d2a04702f8572d3421179d/a/b

If the snapshot changes, you'd automatically get "revocation" of those AFNs

What about the remote case?

normally i'd talk about files somewhere else like this:

	jgilbert@auspice.net:backups/file-a

	(which is really:)

	jgilbert@auspice.net:/home/jgilbert/backups/file-a

	or

	jgilbert@auspice.net:/tmp/file-b

from the perspective of the local cache on the sending side, the AFN is what?

Ideally, you'd want to know 

	jgilbert@auspice.net:. 

		is the same as 

	jgilbert@auspice.net:/home/jgilbert

but how would i learn anything about that? feels like there is no clean way,
and the system can deal with discrepencies even if it doesn't know this
information. would be nice if there was a way to tell GFS that in the future

ideally when i have a volume tagging process i can say

	gfs volume.add.remote @GRYPHON jgilbert@auspice.net:myvolume

	gfs init GRYPHON

	gfs rsync my-photos/test @GRYPHON

So if we use the GIT strategy of tagging, there is some symbolic link between GRYPHON 
and a data structure with the connection information

@GRYPHON becomes its own virtual path. Assuming that there are no overlaps
@with other paths, or other volumes, the FQAFN would be remote:GRYPHON/my-
@photos/test

technically, the "remote" in this case is superflous because it can be
instantly known that this is a remote path by decoding @GRYPHON. Also we'd
want a way in the future to relocate @GRYPHON to a local path.

so these alias constructs know
	The handler (local, remote, volume, snapshot, etc)
	The remote location if there is one

technically, that means that every alias is a pointer to some object sitting in
an object store (Either one that is "real and dedicate", or one that is "found" )

this implies i can do the following

	gfs alias snap:foo.snap @FOO

	# creates a link saying that FOO -> 423fe15a4757767bb4d2a04702f8572d3421179d
	# and also remembers that 423fe15...21179d is a snapshot

	gfs ls @FOO/bar

	# which as long as I can find 423fe15...21179d, i'll just reach into that snapshot

But my stored FQAFNs.... Should they be:

	snap:423fe15...21179d/a/b/c

Or should they be

	alias:@FOO/bar ?

What if FOO changes in the future? The data that is closest to the "truth" is
the first one. That is also the information that is most reusable. But the second
strategy is probably better because @FOO presumably means something to the user
and the user has some intent to refer to @FOO/bar in the future

this raises another question even more fundamental. what if I do this?

	gfs alias /home/jgilbert/backups @LOCAL_BAKS

and say the content is like this

	/home/jgilbert/backups/file1
	/home/jgilbert/backups/file2
	/home/jgilbert/backups/file3

now I do a scan

	gfs snapshot @LOCAL_BAKS

Technically, I now have three universal names for these three files

	fs:/home/jgilbert/backups/file1 -> checksum 123
	snap:423fe15...21179d/file1     -> checksum 123
	@LOCAL_BAKS/file1               -> checksum 123

I think for the moment, all of these things are OK

A snapshot basically acts like a local alias. and the snapshot is the most permanent thing

if i were to list who has checksum 123, 

I'd want to see 

	snap:423fe15...21179d/file1
	@LOCAL_BAKS/file1

The first one I'd rather NOT see because it's expansion will have an identical expansion

How does this work with objects? Lets assume that when an blob is stored, its checksum is identical to a file that was also stored with that hash.

Implications

	gfs checksum file1
	-> 623fe15...24479d
	# now we know this hash

Next I can copy by hash

	gfs copy blob:423fe15...21179d foo.txt

I go through and find obj: anywhere I can, and copy it as a blob. 

Another form of this:

	gfs copy blob:423fe15...21179d foo/

	# copies into foo/423fe15...21179d.blob

But what is this idea of an object store? The object store theoretically has a name
and a location on disk. And the contract is that anytime you copy a file there, its name is lost and it gets absorbed.

	gfs copy foo.txt objstore:path/to/store
	# takes foo.txt and places it in objstore:path/to/store/obj/42/423fe15...21179d

	# the AFNs involved
	# objstore:/home/jgilbert/path/to/store/obj/42/423fe15...21179d --> 423fe15...21179d

Wait, so what is the point of storing objstore as the "domain" here? what
information does it add to the system?

Interesting pattern - in which cases does the AFN actually "need" a domain?

	Doesn't matter for aliases, regular files (fs:)
	but it does matter for remote
	and it matters for snapshots (i think)
	and its confusing for object stores

for instance, what is the difference between 

	objstore:/home/jgilbert/path/to/store/obj/42/423fe15...21179d
		  fs:/home/jgilbert/path/to/store/obj/42/423fe15...21179d

What data is gained by calling something an objectstore in the AFN?

two obvservations now that i've written this out:

1) AFNs really have only three core types:

	fs paths: /home/jgilbert/la-la-la
	containers: tarballs, snapshots, things that contain files and have an addressing scheme
	aliases: which can theoretically cover the earlier two cases

2) The meta-data requirements are different

	fs paths: don't need to know anything
	containers: need to know what expansion formula to use
	aliases: may need to point to either fs, or containers, or remote things

An alias is basically a container. But i need a level of indirection. The data in an alias
could change (hostname updates, path updates), and the namespace has to be valid.

so maybe the best term for a domain is a namespace

a. one name space is limited by files on your computer - world of absolute pathnames
b. another name space is basically ghosts that live under a single file-like-thing
	theoretically that single file like thing could have different "views"
c. another name space is aliases, which are ghosts that are referenced through a LUT

the prefixes used on the command line could be better thought of as access strategies?

consider a case of (b.) above.

AFN: snap:423fe15...21179d/file1 

but i might also have derrivative things

AFN: gunzip:423fe15...21179d     -> whatever the hash is of the thing unziped
AFN: gzip:423fe15...21179d    -> has of the thing zipped

what if the gzip algorithim changes?

well, each row is a ghost. so technically, each ghost has a lastFullHash date, 
and if that gets too old, you'd have to repeat the operation.

An alias can be said to always start with an AT

@FOO/bar

so lets consider a simple case of LS

	gfs ls @FOO/bar

	first, we make @FOO/bar a ghost G1
	then user calls G1->getHash();
	G1 is going to say, "wait, don't ask me, dereference me first!"
	so G2 = G1->dereference();
	two cases now
		case 1: fs alias
			G2 is going to be /home/foo/bar
			so i give the information about G2 and ascribe it to G1
		case 2: snapshot alias
			G2 is going to be snap:423fe15...21179d/file1
	Either way, G2 is something that i can ask a meaningful question about
	there is actually a question if G1 should even get "stored" anywhere

	in the case that i have no idea what snap:423fe15...21179d/file1 resolves as a hash

	when i call obtain "snap:423fe15...21179d/file1"

	the TK handler makes a virtual ghost with that name
	G2->getHash()

	will get passed to the "snap" FSE 

	SNAP FSE says fine, get me an object named 423fe15...21179d
	presumably this thing appears
	and i slurp it in, and then i'll have my LFN cache, and i look up file1

great lets take another case

	gfs ls snap:foo.snap/file1
	I obtain a ghost G1 for "snap:foo.snap/file1".
	G1->getHash();
		this will be a cache miss (obviously!)
		needs to be some logic to deference rather than giving up early
		so next I call G1->getFSE()
		and the FSE call will make me a new explorer connected to foo.snap
		if one doesn't exist already
		this implies some sort of FSE cache or factory
		Now I call FSE->getFullHash()
			well, if i have an AFN cache, a forced conversion to AFN will give me an
				opportunity to remember this answer since it AFN is snap:2343...43432/file1
			but if not..
			this routine will force enumeration of foo.snap, populating a LFN cache
			all of the ghosts will be stored in the FSE maybe for use later
			these ghosts should be marked as "immutable" somehow
				i'll pull out the ghost, and extract the hash from it, and return to caller

great, lets take another case

	gfs checksum tar:foo.tar/file1

	I obtain a ghost for G1 for "tar:foo.tar/file1"
	I ask, is tar:foo.tar/file1 a directory?
	the ghost code won't know yet,
	so it will ask for a stat on tar:foo.tar/file1
	get me a FSE for tar:foo.tar/file1
	this will navigate to a cahce for tar:foo.tar FSE controller
		i'll now generate an AFN and check it
		but assuming that fails
		I untar the file somewhere
		i'll be generating LFNs that look like this
			tar:foo.tar/a 
			tar:foo.tar/file1
		and i'll get the checksum of that file
			i'll make ghosts for the things i find there 
				and the call to checksum it will pass through to that ghost
					ghost will call me asking for the checksu
					i'll construct a new path with the temporary directory
						and hash that file
		if anyone asks for the AFN
		ghost will call the FSE to get the AFN

THis implies that canonocalization and rel2abs, cwd stuff all should live with the 
FSE, not the ghost code!!!

Lets revisit the alais case in more detail

	gfs checksum @mainbackup/neepfile.txt

	I obtain a ghost for "@mainbackup/neepfile.txt"
	initially marked as virtual, b/c i don't know what it is.
	first, i ask "are you an alias"?
		ghost getFSE returns the alias handling FSE
			fse->getFileType("@mainbackup/neepfile.txt")
				FSE will say yes, you are an alias
					not clear if FSE is a singleton thingy or one per alias
					might be cleaner if each alias consiered to be its own FSE
	now i say, G2 = G1->dereference();
		ghost will call getFSE->dereference("@mainbackup/neepfile.txt")
			FSE will go to its reference database
				learn that "mainbackup" points to object 423fe15...21179d
					so now I pull this object from store
							TK->getGhostForHash( )
						the object is going to say mainbackup = /Volumes/blah/bu
						now FSE calls TK->obtainGhostFor "/Volumes/blah/bu/neepfile.txt"
						return
	great, now I have G2 = "/Volumes/blah/bu/neepfile.txt"
	That clearly is just a regular FS path
	so handled the usual way, (Generate pcip files, etc.)
	not clear how the G2 information gets "absorbed into G1" and committed to disk

another way to think about this is that maybe there is no explicit "dereference"
instead, a ghost that knows it is an alias just passes all questions about itself
to the other thing?
but that would require a ton of proliferated code

maybe the TK just gets aliases and dereferences them after the fact to keep things clean

or there is a function on a ghost called g->absorbAttributesFromReferenceGhost()
and this moves over the hash, size, stat and other information

big question - is the file type of an alias always an alias?
like a symlink?
where you don't know if the symlink is a directory or a file?
maybe its best if we do that
unix seems to cope with that type of situation just fine


we need to figure out semantics for the reference database
we need to store two things permanently:

obj and ref

just like git

we can do this in our working directory
but it would be nice if this was all managed

this also should be some sort of FSE

objectstore

and there is a $coreOBS that is my working directory of shit
and i have an FSE complaint thing that manages it

so if I construct a hash like blob:423fe15,
G1 = tk->getGhostWithHash( "423fe15" )
	this routine is going to get you the most local version it can
	this may involve scanning various object stores it knows about
		its going to eventually end up saying
			$coreOBS->getGhostWithHash( "423fe15")
			the core OBS is special
			when you ask a object store FSE for a hashed thing
			it doesn't have to scan its known ghosts
			instead, it can actually just pick up the file
			it turns that into a ghost
			and someone should call "isAcceptaleCopy" to do a guard test on it

if i construct an lfn like blob:423fe15
G1  = TK->obtainGhostFromLFN( "blob:423fe15" );
	I'll get the ghost right away (its virtual)
	but the second anyone asks me to do something with it,
	i'll get delegated to to a blob FSE
	and the blob FSE knows to go back to truthkeeper
	maybe blobs are ocnsidered aliases (e.g. caller must dereference them)

thats sort of a nice way to handle it

in fact, yes, lets do it that way

maybe truthkeeper has a way when asked to do a getGhistWithHash
of passing that work down to FSEs?

there is also a ghostFromLFN strategy to think about
TK first checks its cache
if it can't find it there, it asks the relevant FSM
which implies that a global function to find FSM for LFN
this lives at the factory level




































