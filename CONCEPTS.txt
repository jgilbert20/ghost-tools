















The basic object is a ghost. A ghost is a description of some object discovered "for real" in the filesystem somewhere. 

Things we track for ghosts:

FULLHASH - SHA of the bytestream (aka ghosthash)
FASTHAD - fast SHA of bytestream (empty if not present)
LASTMOD - last modified date from FS
DT_FULLHASH - last full verify
DT_FASTHASH - last fast verify
DT_DISC_OLD - oldest date of discovery
DT_DISC_NEW - newest date of discovery
LFN - one or more pathnames for ghosthash


my $ghost = makeOrFindGhost( LFN );

$GHOST->[FULLHASH];

writeGhostDescriptor( path, GHOST );

A .ghostdesc file is a list of the above entities of information.

The ghosttree is an abstraction around a collection of ghosts
there can be different implementations
the most basic one is just a hashing container that is as lazy as possible

$GhostTree = getAllGhostsUnderPath();

my @ghosts = GhostTree->ghostsForHash();


+++++++++++


# gfs snapshot .
# generates a snapshot file

# gfs condense /etc /var snap:barf.gs
# gfs condense snap:barf.gs snap:arf.gs snap:new.gs

# will reconstruct using known afns, keeps orphans
# gfs reconstruct --test snap:barf.gs foo/
# 150 files reconstructed, 4 not located (see gfsrun.3234.orphaned.txt for details)

# make symlinks rather than copy files
# gfs reconstruct --symlink 

# uses xxx and yyy as hash sources
# gfs reconstruct --test snap:barf.gs foo/ --source=xxx --source=yyyy

# verify all descriptors in /etc
# gfs verify /etc

# creates a GFS entity that can be pushed to
# gfs gfs create /etc gfs:foo.gfs

# gfs gfs push /etc gfs:foo.gfs
# makes sure that /etc can be reconstructed by gfs:foo.gfs

# gfs gfs add gfs:goo.
# a .gfs file can contain storage and 



++++++++++++++





now we have a bit of an issue
the FSE implementation is pretty tied to the descriptor logic
also, ghosts can be part of many different ghost stores
and there is no clean way for updated truth to be spontaneosly discovered and written back out to 
those files

maybe ghoststore is really just a good convienence method for a collection of ghosts
don't think of it as a first class object

maybe the FSE is really the management concept around a filesystem and its state
its handles the details of its "backing store".
we don't worry about Ghosts being in more than one GS, because FSE is really controlling the end-to-end behavior

fse->writeSnapshot()

$gs2 = fse->gs()->merge( fse2->gs() );

the GS of an FSE is only for files in its tree (although maybe we don't have to take this
as a super strict rule?)

i = fse->findAllDuplicates(); # starts stat scan, returns first match;
i->next();

fse->removeFile( $i );
fse->copyFile( $i , $destFSE, $xfn )

i = fse->findOverlap( fse2 ) -- returns a hit for everything in FSE that is matched in fse2
f = i->getNext

fse2->findDuplicateOfGhost( f );

the FSE syntax shpuld be implmeneted for real filesystes, remote filesystems and snapshots


+++++++++++++++++


seems like the best separation of concerns is a new idea:

FSE is really about the interface to a collection of files
TruthKeeper is the module that generates ghosts
it also tracks when ghost records are stale and may need to be pushed out to new places


+++++++++++++++++




Definitions:

	Source: A place to take things from, but must remain untouched
	Auxiliary|Pillage: A place we don't give a shit about and okay to move things

+++++




Thats sort of annoying, right? 

Everything is a ghost refactor

M: main
FSE: Filesystem manager
G: Ghost
	getSize()
	learnSize() - accomodate potentially new information
	learnStat
TK: Truthkeeper
GS: Ghoststore


1-How do .gcpip files get populated initially?
2-How does .gcip file change when contents is changed?
3-How does a snapshot work?

	gfs snapshot filea fileb

	main: gs = TK->makeGhostsFromCommandline( @ARGV );
			obtainGhostForLFN( shift @ARGV )
				look inside our local run cache for these ghosts first
				if not, pull in the ghoststore of the parent using existing functions
		i = gs->getDescendingIterator(); - populate this GhostIterator with a queue of the roots
		g = i->next();
			pop queue 
			if( g->hasChildren() )
				g->getChildren()
					getChildren finds out the last time dirent was populated
					    if ok, then TK->getCachedChildren( g );
					    	load the .gcip file
					    if not ok, children = FSM->getImmediateChildren( g )
					    		this function opens the directory, does a full scan,
					    		and creates a ghoststore 
					    		calls TK->makeGhostForLFN( "fs:" . thingWeFindInDir)
					    	g->learnChildrenPresent( children );
					    		setChildrenMarkPresent now scans the known children
					    		marking those that aren't found as "not present"
					    		and setting the lastDirEnt date
			onThunk
				g->finalizeChildrenPresent()
					computes the hashes of names and subhashes
					populates lastHashDate() 
					g->learnFullHash(X);
						if different, sets dirty flag
						if date different, sets it, and sets dirty flag
					g->flush();
						Tk->flush() - called on thunk only for directory case
						writes out the gcip file and cleans the dirty flag
		g->forceCharacterize();
			checks all of its fields. For those that don't seem right, 
			we call the FSM -> retrieveFullHashHard
							-> retrieveStatHard




	gfs lsdup dirA dirB
	$sourceGS = TK->makeFromCommand( @argv sources)
	$targetGS = TK->makeFromCommand( @argv dest)

	$targetGS->getDescendingIterator();
	foreach( my $g = getNext() )
		$sourceGS->findAllDuplicates( $g );
			my @sizeMatches = $gs->findFilesWithSize( $size );
				@matches->isDuplicateOf( $g )


++++

Everything-is-a-ghost refactor complete
things still not really handled

1) lsdup should work with snapshots
2) findChildren should start with the files found in the descriptor, saving directory hashing
3) we aren't handling the thunks, therefore directories aren't geting hashes
4) support for identification of deleted files
5) support for filesystems that may or may not be online - e.g. volumes that mount or unmount

fields to add to ghosts lastEnumerated, firstStat, isDeleted, 


isHardIgnore needs to have . and .. added (they are creeping in)
