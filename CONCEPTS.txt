
The basic object is a ghost. A ghost is a description of some object discovered "for real" in the filesystem somewhere. 

Things we track for ghosts:

FULLHASH - SHA of the bytestream (aka ghosthash)
FASTHAD - fast SHA of bytestream (empty if not present)
LASTMOD - last modified date from FS
DT_FULLHASH - last full verify
DT_FASTHASH - last fast verify
DT_DISC_OLD - oldest date of discovery
DT_DISC_NEW - newest date of discovery
LFN - one or more pathnames for ghosthash


my $ghost = makeOrFindGhost( LFN );

$GHOST->[FULLHASH];

writeGhostDescriptor( path, GHOST );

A .ghostdesc file is a list of the above entities of information.

The ghosttree is an abstraction around a collection of ghosts
there can be different implementations
the most basic one is just a hashing container that is as lazy as possible

$GhostTree = getAllGhostsUnderPath();

my @ghosts = GhostTree->ghostsForHash();


+++++++++++


# gfs snapshot .
# generates a snapshot file

# gfs condense /etc /var snap:barf.gs
# gfs condense snap:barf.gs snap:arf.gs snap:new.gs

# will reconstruct using known afns, keeps orphans
# gfs reconstruct --test snap:barf.gs foo/
# 150 files reconstructed, 4 not located (see gfsrun.3234.orphaned.txt for details)

# make symlinks rather than copy files
# gfs reconstruct --symlink 

# uses xxx and yyy as hash sources
# gfs reconstruct --test snap:barf.gs foo/ --source=xxx --source=yyyy

# verify all descriptors in /etc
# gfs verify /etc

# creates a GFS entity that can be pushed to
# gfs gfs create /etc gfs:foo.gfs

# gfs gfs push /etc gfs:foo.gfs
# makes sure that /etc can be reconstructed by gfs:foo.gfs

# gfs gfs add gfs:goo.
# a .gfs file can contain storage and 



++++++++++++++





now we have a bit of an issue
the FSE implementation is pretty tied to the descriptor logic
also, ghosts can be part of many different ghost stores
and there is no clean way for updated truth to be spontaneosly discovered and written back out to 
those files

maybe ghoststore is really just a good convienence method for a collection of ghosts
don't think of it as a first class object

maybe the FSE is really the management concept around a filesystem and its state
its handles the details of its "backing store".
we don't worry about Ghosts being in more than one GS, because FSE is really controlling the end-to-end behavior

fse->writeSnapshot()

$gs2 = fse->gs()->merge( fse2->gs() );

the GS of an FSE is only for files in its tree (although maybe we don't have to take this
as a super strict rule?)

i = fse->findAllDuplicates(); # starts stat scan, returns first match;
i->next();

fse->removeFile( $i );
fse->copyFile( $i , $destFSE, $xfn )

i = fse->findOverlap( fse2 ) -- returns a hit for everything in FSE that is matched in fse2
f = i->getNext

fse2->findDuplicateOfGhost( f );

the FSE syntax shpuld be implmeneted for real filesystes, remote filesystems and snapshots


+++++++++++++++++


seems like the best separation of concerns is a new idea:

FSE is really about the interface to a collection of files
TruthKeeper is the module that generates ghosts
it also tracks when ghost records are stale and may need to be pushed out to new places


+++++++++++++++++

TODO: -G|guard - if a basic something hasn't been checked in this many days, check it again
should get a warning if not specified and old data is being relied on


gfs verify A B C

    can A and B reconstruct everything in directory C?

gfs snapshot C snap:foo

	Add everything in C to the snapshot called foo. Checksums are forced if not present
	but they are not recalcualted unnecessarily

gfs verify C snap:foo

	Verify if C contains everything in snapshot foo (is C in conformance to foo?)
	If C has extra things, that is OK. The thing we are testing is snap:foo

gfs verify snap:foo A

	Verify that snapshot foo has everything now in A.. That is, is there anything
	in volume A we cannot find in snap:foo?

gfs rsync|copy|cp A B

	Acts like we are copying A to B. We will feel free to move anything
	around in B to make it look like A. 

gfs rsync|copy|cp A B --pillage=C

	In cases where it makes sense to fill in B by pillaging from C, go ahead and do that

gfs rsync|copy|cp A B --delete

	Same as earlier, but things in B that aren't supposed to be there will be moved to a
	"deleted-xxxxxx" subdirectory kept at the top level of B

gfs rsync|copy|cp A B --delete=C

	Same as earlier, but things in B that aren't supposed to be there will be moved to a
	"deleted-xxxxxx" subdirectory kept at the top level of C

gfs deduplicate A B C 

	Go through C, and anything that is duplicated in A, B or C is moved out

gfs deduplicate A B C --lighten|thunk

	Go through C -- things that are no longer needed are converted to thunks




gfs lighten A B C

    anuthing in C that can be reconstructed with A and B will be converted into a
    lightweight thunk file

gfs thicken A B C

	Convert all thunks in C by copying files from A and B

gfs bless /path/to/C volume1

	now any AFN under /path/to/c will be volumized

gfs verify vol:volume1 snap:foo 

	equivilent to gfs verify /path/to/C snap:foo

gfs scan .
	
	Updates all of our descriptors and also updates volume mappings
	Brings our localdatabase up to date
	basically the same operation as a snapshot but doesn't write a file





Definitions:

	Source: A place to take things from, but must remain untouched
	Auxiliary|Pillage: A place we don't give a shit about and okay to move things

+++++

If you're anything like me, you've got files scattered in an annoying number of different places

- My main laptop (800GB)
- My main desktop (3TB) plus a RAID-8TB and a DroboPro-16Tb)
- An old Drobo that sometimes I connect to keep spare copies of things
- A few old hard drives on my desk with video render files I probably can delete
- An archive of my files before 2012 at my parent's house
- An archive of some more recent things
- A dropbox folder
- A google drive folder
- An old laptop that I may or may not have fully moved out from 2013
- A gaming machine that may or may not have other files

How do you manage all of this stuff? How do you figure out what is a copy, what is a backup, and what is a primay storage for something? If you were smart, maybe you could be super organized. But there is another way. The power of technology. 





Thats sort of annoying, right? 

Everything is a ghost refactor

M: main
FSE: Filesystem manager
G: Ghost
	getSize()
	learnSize() - accomodate potentially new information
	learnStat
TK: Truthkeeper
GS: Ghoststore


1-How do .gcpip files get populated initially?
2-How does .gcip file change when contents is changed?
3-How does a snapshot work?

	gfs snapshot filea fileb

	main: @ghosts = TK->makeGhostFromCommandline( @ARGV );
		GS->addGhosts( @ghosts );
		i = gs->getDescendingIterator(); - populate this GhostIterator with a queue of the roots
		g = i->next();
			pop queue 
			if( g->hasChildren() )
				g->getChildren()
					getChildren finds out the last time dirent was populated
					    if ok, then TK->getCachedChildren( g );
					    	load the .gcip file
					    if not ok, children = FSM->getImmediateChildren( g )
					    	g->learnChildrenPresent( children );
					    		setChildrenMarkPresent now scans the known children
					    		marking those that aren't found as "not present"
					    		and setting the lastDirEnt date
			onThunk
				g->finalizeChildrenPresent()
					computes the hashes of names and subhashes
					populates lastHashDate() 
					g->learnFullHash(X);
						if different, sets dirty flag
						if date different, sets it, and sets dirty flag
					g->flush();
						Tk->flush() - called on thunk only for directory case
						writes out the gcip file and cleans the dirty flag




