# What is this document

It is a collection of retired ideas.. anything that is current has been moved to the full concept file. 




# Cool tools to check

https://github.com/bup/bup

http://superuser.com/questions/730592/compressing-many-similar-big-files/730598
https://git-annex.branchable.com/future_proofing/
http://ck.kolivas.org/apps/lrzip/README
https://raw.githubusercontent.com/bup/bup/master/DESIGN


git annex is cool! i want it to do what i want! but it doesn.t its stuck doign
everything like a big git repository that knows how to shuffle files around.
you have to manually add things into the annex and commit them. My style is
more to just put files around in any place I want them and then worry about
redudancy later. Annex is nice though becuase it seems to provide closure
around a set of "managed" files so there is no confusion as to what your
archive looks like no matter where the peices are scattered.

and bup is way cool too, but also seemingly tied to being a backup tool. But
its got way awesome large file saving and incremental backup support.

in my ideal tool, i'd do the following

	gfs init-volume /              laptop-root
	gfs init-volume /Volumes/usb   usb1-spare

	mkdir ~/working-stuff
	add lots of things under here

Now, to "run" a backup...

	gfs push . 

	# Looks for things in laptop-root its never seen before, and then fishes around
	#for a place to stash them. 

	./working-stuff/a,b,c -> usb1-spare/backup-today-20160601

And i can check on replication status whenever I want...

	gfs check .

	15 files have stashed copies on usb1-spare (trusted, but currently offline)
	4 files are novel and unreplicated anywhere else

The key thing is that GFS stays flexible where and how these other things are
saved and stored. And it doesn't create symlinks or other messy things like
that.

GFS also tries to stay flexibile about how blobs are backed up. The lowest
common denominator of a backed up file is just a user-level copy of the file.



# 




# One to Many references

there is probably also a type of thing called an opener.. 

expand:foo/bar.gz:bar

The AFN for an opener is the hash of the object being openeed

expand:234fc234ffeeaab3234b:













So really base case, lets implement 

- singleton object
gfs init 
  - makes all of the directories and stuff
gfs store filex
  - exercises the storeGhost API (which can be hackist, no GST required.)
gfs obj-setname foo bar
  - exercises pointer logic
  



Side note: We need a way of defining a ghoststore that is "backed" by a file such that slurping is completely lazy and uses some sort of native indexing tool. Hate the idea that a million rows of a ghoststore might have to be read just to get some random value. 







# great idea here: (copypaste from BUP technical notes)


bup makes accommodations for the expected "worst-case" filesystem timestamp resolution -- currently one second; examples include VFAT, ext2, ext3, small ext4, etc. Since bup cannot know the filesystem timestamp resolution, and could be traversing multiple filesystems during any given run, it always assumes that the resolution may be no better than one second.

As a practical matter, this means that index updates are a bit imprecise, and so bup save may occasionally record filesystem changes that you didn't expect. That's because, during an index update, if bup encounters a path whose actual timestamps are more recent than one second before the update started, bup will set the index timestamps for that path (mtime and ctime) to exactly one second before the run, -- effectively capping those values.





# Compare mode

a new sematic i didn't realize
its not reconstruct
its stronger
it asks "is everything here exactly as it was in the snapshot?"


# Singleton nature

Its canonical that the LFN of a ghost once created must never change.

if you need to reference a new thing, make a new ghost


# determinis and order

ghost iterators now sort their contents why? well, turns out there is some
non-deterministic behavior going on depending on how the values get scrabled
into the cache and i need consistency. ideally though, we need a way of
iterating through the ghost store in an order similiar to the one the user
intendend.

# too much caching

there is a good reason to really restat the entire destination directory
before developing a workplan otherwise operations will start to go wrong when
things aren't where expected. I think its fair to not rely on caching 
when you are actually about to write new stuff.. 

do this at the start, don't wait for some forced cache



now another thing has occured to me -what do we do about FSE proliferation?

technically, more than one FSE can be operative on a local file system at a time.

does it matter who or what finalizes these things?

we need to recheck the LSDUP semantics and make sure getFSE() isn't going to get 
completely confused. my guess is that because the ::FS is so thin, it probably doesn't 
matter.  it stores very little state relateive to the ::Snapshiot

but this is an issue when it comes to moving the ghost descriptor code. 

i think we need to make sure that all fs:root ghosts always get the global FS when they ask questions about themselves. And I think this is what the code does now.


# thoughts on the absolute ghost cache (AGC)

## Problem 1

THe absolute cache is an interesting beast and has some peculuarities I need
to work through. First of all, how should it interact with .gfs_ip files? Say
I look for an ghost record and hit the AGC. There is no opportunity for state
to flow up from the .gfs_ip cache into the AGC. And if there is a dirty
record, we'll have to spontaneously make sure that the gfs_ip is loaded, which
itself may disrupt known state..

## Problem 2

When serializing to the AGC, we will write the filenames by asking the ghost
to represent them in an absolute way. There are at least two transformations
we can expect:

	1- The filenames will go to absolute
	2- snapshot roots will get converted to ^234abcdfef things

Now when those AGCs are retrieved, at what point do we "convert" them into
their local versions? Do we ever need to do this?

Lets say we leave them as absolutes. This will mean that anyone who calls
lfn() will see something they may not recognize. But the behavior of the
software may be correct anyway -- its not going to be fed "wrong" information,
just getting data in an unexpected form.

Maybe a better way to think about the AGC is that it is an overarching store
used to populate certain peices of information. If I want a ghost of ./a/test-
file1, I make it and it says local all of its life. But as a pre-loading step,
to "get me started", one source of truth about it is to copy data over from
the AGC. But we can do that with a bunch of "learn" optimizations. I can
g->learnFromOtherGhost(), and when I do that, I just check the AFNs are the
same. If they are, the data is safe to transfer over. The learning algorithim
will be smart to either keep or discard things.

My preference is to deal with .gfs_ip files at termination of the program, so 
lets let the dirty handler take that. 

SO we need really good learn semantics. Maybe we should write those down.

In the case of snapshot, I start with snap:foo:filea. Lets say I want to
operate on that file to do an LS. I'll make a ghost representing
snap:foo:filea. The AFN convert will see it as a ^234db pointer (forcing a
checksum of the file along the way, which is an separate thing), and therefore
we'll potentially hit the global cache, not even reading the file directly.

So decision stands: the AFNs will never directly enter the pool.






## Entries vs. ghosts

An entry is a thing that exists somewhere for the name. A ghost is a view
about state of an entry. There can be many conceptual ghosts pointing at the
same entry. When I call the truthkeeper, my request is to get the most recent
(or best) ghost for that entry. 











things that are not virtual are 'confirmed'.

they could be deleted, present, missing, etc

but to not be virtual, someone somewhere has to either deserialize them
from the past, or find them authoritatively on disk 

that way we don't contaminate the pool of ghosts

if the program that the user is asking to run cannot track down a confirmed ghost,
they can decide what to do (it's basically a file not found.)



# How do ghost work when they cross into the world of snapshots?

hah, interesting issue: what ghosts shpuld we pull from a snapshot? its
written as a bunch of fs:root: things... so  pulling them straight out of the
file contaminates the truth store.

but really, as a snapshot, we need to load it as virtualized objects, in their
world now, they are in a different name space

raises another question: boundary case -if you snapshot a snapshot, what
should happen? - i think the right thing is to either save a snapshot with
rewritten LFNs or to change the LFNs when loading

DECISION: I think its more correct to do on writing, e.g. -> convert  to snapshot LFNs
during the write operation

this requires new FSE semantics
should we think of a snapshot operation as a push into a filesystem?

YES

make a ghost for the snapshot-to-be
mkae FSE
FSE->addObject( $g );
	clone the ghost and re-write the LFN
	make them immutable
FSE->finalize();

we probably will need similiar semantics on object stores








# What is a ghost?

The basic object is a ghost. A ghost is a description of some object
discovered "for real" in the filesystem somewhere.

Things we track for ghosts:

FULLHASH - SHA of the bytestream (aka ghosthash)
FASTHAD - fast SHA of bytestream (empty if not present)
LASTMOD - last modified date from FS
DT_FULLHASH - last full verify
DT_FASTHASH - last fast verify
DT_DISC_OLD - oldest date of discovery
DT_DISC_NEW - newest date of discovery
LFN - one or more pathnames for ghosthash

my $ghost = makeOrFindGhost( LFN );

$GHOST->[FULLHASH];

writeGhostDescriptor( path, GHOST );

A .ghostdesc file is a list of the above entities of information. It is
basically serialized ghosts which have very local basenames for paths. 

The ghoststore is an abstraction around a collection of ghosts there can be
different implementations the most basic one is just a hashing container that
is as lazy as possible.


# About LFNS

LFN - local file name - whatever is colloquial to the USER to
describe something. LFNs can never presume to be universally unique between
invocations of GFS because they may be relative paths or tags/references may
change. But the user's maximal intent must be captured in the LFN.

	for instance fs:a depends on your CWD
	for a different PWD, fs:a could refer to a different file

However, there are many different handlers.

	/foo
	fs:/foo
	snap:foo.snap:file123
	remote:jgilbert@auspice.net:file123

In this case, the "LFN" is a composite of a handler, a root and a path. The
user may provide some or all of these peices on the command line. We need to
be be able  to intelligently construct the rest.

LFN's can be fullqualified, which means fully specify the missing strings and
to canonicalized the path.

To determine if two LFNs are the same inside one running instance of GFS, the
only way to do it is to canonicalize that path portion both to remove . and
../ etc. Then you need you make sure to attach the ROOT and the HANDLER.

across instances, the only way is to convert to an AFN (absolute file name)
The AFN is a unique permanent name for the location

FQAFN - fully qualified AFN: handler:root:afn
FQLFN - fully qualified LFN: handler:root:path (can be local)

snapshots will generally represent LFNs, typically from the point of view of
the PWD but their power is that they should NOT be foreced to contain AFNs -
the snapshot could be  reconstructed anywhere and we'll leave it to the user
to either feed a snapshot the AFNs or the LFNS.

in the nested case, assume the following data is stored

	snap:testdir/snapshot.gfssnap:
	snap:testdir/snapshot.gfssnap:a
	snap:testdir/snapshot.gfssnap:b

in this case, the LFN of the snapshot file itself is testdir/snapshot.gfssnap

So LFNs are designed to hold three peices of information, and together forms a
unique namespace.


# What is truth? What is the single source of truth?

Ghost is a description of the potential state of a file.

Currently, contracts look like this

- No obligation for a specific ghost to be up to date
- Only the ghosts from the TK are guarnteed to be single source of truth
- Ghosts find their FSE by looking at their handler value
- Ghosts can be in any number of ghost stores
- TruthKeeper should make all ghosts that are intended to hold present state
- The only reason TK is not used to make ghosts is in cases where you are deliverably
- TK holds all ghost pointers and knows if they are dirty or not
- Generally, the FSE doesn't hold links back to ghosts except in cases where a ghost is a root (like a snapshot)


# design ideas for object stores
object store concepts

a blob always has the hash of the file it saves - the header (everything up to the first null) can be anything


# Revocation rules and timing


we need to not be in a situation where the fullhash has changed but
the stat stays the same
scenario - two ghosts pointing to same file
ghost A has Ha and Sa (hash and stat)
ghost B has Hb and Sa

if Hb is later that Ha, we'd be confused - how could both stats be identical but the hash has changed?
contract should be
getStat
getHash
getStat

if stat is the same both times, than take the timestamp and report it for both

also implies the "learn" semantic should always be accompanied by a date
and not generated inside the routines'

(merge case)

A new stat does not mean that a hash is out of date. The stat date should be used for resolving which of two stats is most accurate. 

stat fields should be taken all or nothing. 

The only cause for revoking a hash is when the size has changed or last modification date has changed. 

The revocation should not be immediate. It can be lazy. Maybe an optional warning. But the next time anyone asks for a hash on that file, we'd be forced to get one. 

Ghosts should never revoke other ghosts. Let that semantic rest with truth keeper. TK will just ask for incorporation in direction it wants. 

If you ask for a ghost that has no authoritative record is should be marked as virtual. 

One sanity check is that the virtual ghost should not be written to disk under normal cases. 




+++++++++++





+++++++++++++++++


seems like the best separation of concerns is a new idea:

FSE is really about the interface to a collection of files
TruthKeeper is the module that generates ghosts
it also tracks when ghost records are stale and may need to be pushed out to new places


+++++++++++++++++




Definitions:

	Source: A place to take things from, but must remain untouched
	Auxiliary|Pillage: A place we don't give a shit about and okay to move things

+++++




Thats sort of annoying, right? 

Everything is a ghost refactor. In this design, ghosts are interachanable with filenames
and FSE is really stripped down

M: main
FSE: Filesystem manager
	getStat
	getFullHash
	listDirectory
	copy
	move

G: Ghost
	getSize()
	learnSize() - accomodate potentially new information
	learnStat
TK: Truthkeeper
GS: Ghoststore


1-How do .gcpip files get populated initially?
2-How does .gcip file change when contents is changed?
3-How does a snapshot work?

	gfs snapshot filea fileb

	main: gs = TK->makeGhostsFromCommandline( @ARGV );
			obtainGhostForLFN( shift @ARGV )
				look inside our local run cache for these ghosts first
				if not, pull in the ghoststore of the parent using existing functions
		i = gs->getDescendingIterator(); - populate this GhostIterator with a queue of the roots
		g = i->next();
			pop queue 
			if( g->hasChildren() )
				g->getChildren()
					getChildren finds out the last time dirent was populated
					    if ok, then TK->getCachedChildren( g );
					    	load the .gcip file
					    if not ok, children = FSM->getImmediateChildren( g )
					    		this function opens the directory, does a full scan,
					    		and creates a ghoststore 
					    		calls TK->makeGhostForLFN( "fs:" . thingWeFindInDir)
					    	g->learnChildrenPresent( children );
					    		setChildrenMarkPresent now scans the known children
					    		marking those that aren't found as "not present"
					    		and setting the lastDirEnt date
			onThunk
				g->finalizeChildrenPresent()
					computes the hashes of names and subhashes
					populates lastHashDate() 
					g->learnFullHash(X);
						if different, sets dirty flag
						if date different, sets it, and sets dirty flag
					g->flush();
						Tk->flush() - called on thunk only for directory case
						writes out the gcip file and cleans the dirty flag
		g->forceCharacterize();
			checks all of its fields. For those that don't seem right, 
			we call the FSM -> retrieveFullHashHard
							-> retrieveStatHard




	gfs lsdup dirA dirB
	$sourceGS = TK->makeFromCommand( @argv sources)
	$targetGS = TK->makeFromCommand( @argv dest)

	$targetGS->getDescendingIterator();
	foreach( my $g = getNext() )
		$sourceGS->findAllDuplicates( $g );
			my @sizeMatches = $gs->findFilesWithSize( $size );
				@matches->isDuplicateOf( $g )



###


++++

RSYNC implementation ideas

gs = ghoststore of source
for each file in ghoststore
	get a full snapshot of the remote directory + its pillage/spare places + aux places
	get a full snapshot of the source directory
	identify corresponding path in target to match rsync exactly
		A. There is a file fT already sitting at TARGET at this filename
			A1. The hash of fT is correct - its what we want
				-- Mark TARGET fT as claimed, no action needed, go to next file
			A2. The hash is not correct
				-- Mark as orphaned, select new orphaning location - during clearance MOVE phase (will be moved out first)
				-- Flow down to Case B
		B. There is no file at the remote location in TARGET tree at that filename, or the file in TARGET is marked orphaned
			A1. There is no hash ANYWHERE at TARGET, PILLAGE, AUX, COPY or ORPHAN
				-- Queue for remote copy, function done
			A2. There is a hash available in PILLAGE that is not claimed
				-- Queue move PILLAGE -> fT, claim it
			A2. There is a hash availble in ORPHAN that is not claimed
				-- Queue clearance move ORPHAN -> fT (assign new location) - DONE  (What about case of a swap..?)
			A3. There is a hash available in TARGET that is claimed
				-- Queue local copy, done
			A4. There is a hash available in AUX
				-- Queue local copy, done
			A5. There is a hash available in PILLAGE that is claimed
				-- Queue local copy, done
			A6. There is a hash available in COPYLIST
				-- Queue local copy, done

First do all clearance moves
Then do all remote copies
Then do all local copies

Internal commands we need:

action_clearanceMove( $s, $d )
	mark $s as empty, $s->deleted()
	mark $d with new ghost by cloning and assigning new LFN

action_remoteCopy( $s, $d )
	mark $d 

action_localCopy


FileOpPlan
	knows how to record activities
	knows how to check for conflicts
	knows how to start work and verify its proceeding as planned
	fires actual actions over to the FSE in sequence
	copy
	move
	copyIntoObjectFormat
	
We need to insist on a contract that STATs are repeated during full hash
this is going to be done anyway by the OS
also a guard if the file changes and the original stat and hash fall out of sync





virtual ghosts
==============

gfs ls a b c 

will try to obtain equivilent of the following

gfs ls fs:a fs:b fs:c

but a b and c may not exist!

until a successful stat, they should be marked as a status = v
virtual should not get stored anywhere

whereas if you do a gfs ls . in a directory that has a b and c

in this case, a b c come from a scan, which by definition is not virtual
see?




so we create some virtual ghosts along the way
every time the operation is done, we should commit them (take off their virtual flag?)

maybe we just have a notion of copies or moves, and later we decide if they are local or remote?

need to check $g->isPathUnder($y);

next steps could occur in parallel
	begin copying over files we think are net new in reverse mtime order
	begin verification download (basically, get a snapshot of the remote FS)


PUSH looks different.. Push just says that we're going to move over things we think weren't there
into a "pushed-content" subdirectory
we could get things wrong but better for an offline situation

gsf accept pushed-content-1234 is used to rearrange the tree

maybe we have concept of a library
technically snapshots, orphans, pushes, etc could all be objects

GFS-library/objects
GFS-library/primay
GFS-library/orphans
GFS-library/pushes
GFS-library/snapshots
GFS-library/snapshots/Latest->xxx

need a flag on a blob if is is a moved file, or just some junk that GFS maintained
otherwise, cleanup on aisle three situation is shitty

maybe object syntax is as simple as foo/bar/this@234abc32a993, 
this syntax always means a file with this hash under that tree

how do we create definitive names for things and spread them around?
seems like git just stores things in namespace/xxx format

refs/tags/xyz


GFS objects

What about the remote case?

normally i'd talk about files somewhere else like this:

	jgilbert@auspice.net:backups/file-a

	(which is really:)

	jgilbert@auspice.net:/home/jgilbert/backups/file-a

	or

	jgilbert@auspice.net:/tmp/file-b

from the perspective of the local cache on the sending side, the AFN is what?

Ideally, you'd want to know 

	jgilbert@auspice.net:. 

		is the same as 

	jgilbert@auspice.net:/home/jgilbert

but how would i learn anything about that? feels like there is no clean way,
and the system can deal with discrepencies even if it doesn't know this
information. would be nice if there was a way to tell GFS that in the future

ideally when i have a volume tagging process i can say

	gfs volume.add.remote @GRYPHON jgilbert@auspice.net:myvolume

	gfs init GRYPHON

	gfs rsync my-photos/test @GRYPHON

So if we use the GIT strategy of tagging, there is some symbolic link between GRYPHON 
and a data structure with the connection information

@GRYPHON becomes its own virtual path. Assuming that there are no overlaps
@with other paths, or other volumes, the FQAFN would be remote:GRYPHON/my-
@photos/test

technically, the "remote" in this case is superflous because it can be
instantly known that this is a remote path by decoding @GRYPHON. Also we'd
want a way in the future to relocate @GRYPHON to a local path.

so these alias constructs know
	The handler (local, remote, volume, snapshot, etc)
	The remote location if there is one

technically, that means that every alias is a pointer to some object sitting in
an object store (Either one that is "real and dedicate", or one that is "found" )

this implies i can do the following

	gfs alias snap:foo.snap @FOO

	# creates a link saying that FOO -> 423fe15a4757767bb4d2a04702f8572d3421179d
	# and also remembers that 423fe15...21179d is a snapshot

	gfs ls @FOO/bar

	# which as long as I can find 423fe15...21179d, i'll just reach into that snapshot

But my stored FQAFNs.... Should they be:

	snap:423fe15...21179d/a/b/c

Or should they be

	alias:@FOO/bar ?

What if FOO changes in the future? The data that is closest to the "truth" is
the first one. That is also the information that is most reusable. But the second
strategy is probably better because @FOO presumably means something to the user
and the user has some intent to refer to @FOO/bar in the future

this raises another question even more fundamental. what if I do this?

	gfs alias /home/jgilbert/backups @LOCAL_BAKS

and say the content is like this

	/home/jgilbert/backups/file1
	/home/jgilbert/backups/file2
	/home/jgilbert/backups/file3

now I do a scan

	gfs snapshot @LOCAL_BAKS

Technically, I now have three universal names for these three files

	fs:/home/jgilbert/backups/file1 -> checksum 123
	snap:423fe15...21179d/file1     -> checksum 123
	@LOCAL_BAKS/file1               -> checksum 123

I think for the moment, all of these things are OK

A snapshot basically acts like a local alias. and the snapshot is the most permanent thing

if i were to list who has checksum 123, 

I'd want to see 

	snap:423fe15...21179d/file1
	@LOCAL_BAKS/file1

The first one I'd rather NOT see because it's expansion will have an identical expansion

How does this work with objects? Lets assume that when an blob is stored, its checksum is identical to a file that was also stored with that hash.

Implications

	gfs checksum file1
	-> 623fe15...24479d
	# now we know this hash

Next I can copy by hash

	gfs copy blob:423fe15...21179d foo.txt

I go through and find obj: anywhere I can, and copy it as a blob. 

Another form of this:

	gfs copy blob:423fe15...21179d foo/

	# copies into foo/423fe15...21179d.blob

But what is this idea of an object store? The object store theoretically has a name
and a location on disk. And the contract is that anytime you copy a file there, its name is lost and it gets absorbed.

	gfs copy foo.txt objstore:path/to/store
	# takes foo.txt and places it in objstore:path/to/store/obj/42/423fe15...21179d

	# the AFNs involved
	# objstore:/home/jgilbert/path/to/store/obj/42/423fe15...21179d --> 423fe15...21179d

Wait, so what is the point of storing objstore as the "domain" here? what
information does it add to the system?

Interesting pattern - in which cases does the AFN actually "need" a domain?

	Doesn't matter for aliases, regular files (fs:)
	but it does matter for remote
	and it matters for snapshots (i think)
	and its confusing for object stores

for instance, what is the difference between 

	objstore:/home/jgilbert/path/to/store/obj/42/423fe15...21179d
		  fs:/home/jgilbert/path/to/store/obj/42/423fe15...21179d

What data is gained by calling something an objectstore in the AFN?

two obvservations now that i've written this out:

1) AFNs really have only three core types:

	fs paths: /home/jgilbert/la-la-la
	containers: tarballs, snapshots, things that contain files and have an addressing scheme
	aliases: which can theoretically cover the earlier two cases

2) The meta-data requirements are different

	fs paths: don't need to know anything
	containers: need to know what expansion formula to use
	aliases: may need to point to either fs, or containers, or remote things

An alias is basically a container. But i need a level of indirection. The data in an alias
could change (hostname updates, path updates), and the namespace has to be valid.

so maybe the best term for a domain is a namespace

a. one name space is limited by files on your computer - world of absolute pathnames
b. another name space is basically ghosts that live under a single file-like-thing
	theoretically that single file like thing could have different "views"
c. another name space is aliases, which are ghosts that are referenced through a LUT

the prefixes used on the command line could be better thought of as access strategies?

consider a case of (b.) above.

AFN: snap:423fe15...21179d/file1 

but i might also have derrivative things

AFN: gunzip:423fe15...21179d     -> whatever the hash is of the thing unziped
AFN: gzip:423fe15...21179d    -> has of the thing zipped

what if the gzip algorithim changes?

well, each row is a ghost. so technically, each ghost has a lastFullHash date, 
and if that gets too old, you'd have to repeat the operation.

An alias can be said to always start with an AT

@FOO/bar

so lets consider a simple case of LS

	gfs ls @FOO/bar

	first, we make @FOO/bar a ghost G1
	then user calls G1->getHash();
	G1 is going to say, "wait, don't ask me, dereference me first!"
	so G2 = G1->dereference();
	two cases now
		case 1: fs alias
			G2 is going to be /home/foo/bar
			so i give the information about G2 and ascribe it to G1
		case 2: snapshot alias
			G2 is going to be snap:423fe15...21179d/file1
	Either way, G2 is something that i can ask a meaningful question about
	there is actually a question if G1 should even get "stored" anywhere

	in the case that i have no idea what snap:423fe15...21179d/file1 resolves as a hash

	when i call obtain "snap:423fe15...21179d/file1"

	the TK handler makes a virtual ghost with that name
	G2->getHash()

	will get passed to the "snap" FSE 

	SNAP FSE says fine, get me an object named 423fe15...21179d
	presumably this thing appears
	and i slurp it in, and then i'll have my LFN cache, and i look up file1

great lets take another case

	gfs ls snap:foo.snap/file1
	I obtain a ghost G1 for "snap:foo.snap/file1".
	G1->getHash();
		this will be a cache miss (obviously!)
		needs to be some logic to deference rather than giving up early
		so next I call G1->getFSE()
		and the FSE call will make me a new explorer connected to foo.snap
		if one doesn't exist already
		this implies some sort of FSE cache or factory
		Now I call FSE->getFullHash()
			well, if i have an AFN cache, a forced conversion to AFN will give me an
				opportunity to remember this answer since it AFN is snap:2343...43432/file1
			but if not..
			this routine will force enumeration of foo.snap, populating a LFN cache
			all of the ghosts will be stored in the FSE maybe for use later
			these ghosts should be marked as "immutable" somehow
				i'll pull out the ghost, and extract the hash from it, and return to caller

great, lets take another case

	gfs checksum tar:foo.tar/file1

	I obtain a ghost for G1 for "tar:foo.tar/file1"
	I ask, is tar:foo.tar/file1 a directory?
	the ghost code won't know yet,
	so it will ask for a stat on tar:foo.tar/file1
	get me a FSE for tar:foo.tar/file1
	this will navigate to a cahce for tar:foo.tar FSE controller
		i'll now generate an AFN and check it
		but assuming that fails
		I untar the file somewhere
		i'll be generating LFNs that look like this
			tar:foo.tar/a 
			tar:foo.tar/file1
		and i'll get the checksum of that file
			i'll make ghosts for the things i find there 
				and the call to checksum it will pass through to that ghost
					ghost will call me asking for the checksu
					i'll construct a new path with the temporary directory
						and hash that file
		if anyone asks for the AFN
		ghost will call the FSE to get the AFN

THis implies that canonocalization and rel2abs, cwd stuff all should live with the 
FSE, not the ghost code!!!

Lets revisit the alais case in more detail

	gfs checksum @mainbackup/neepfile.txt

	I obtain a ghost for "@mainbackup/neepfile.txt"
	initially marked as virtual, b/c i don't know what it is.
	first, i ask "are you an alias"?
		ghost getFSE returns the alias handling FSE
			fse->getFileType("@mainbackup/neepfile.txt")
				FSE will say yes, you are an alias
					not clear if FSE is a singleton thingy or one per alias
					might be cleaner if each alias consiered to be its own FSE
	now i say, G2 = G1->dereference();
		ghost will call getFSE->dereference("@mainbackup/neepfile.txt")
			FSE will go to its reference database
				learn that "mainbackup" points to object 423fe15...21179d
					so now I pull this object from store
							TK->getGhostForHash( )
						the object is going to say mainbackup = /Volumes/blah/bu
						now FSE calls TK->obtainGhostFor "/Volumes/blah/bu/neepfile.txt"
						return
	great, now I have G2 = "/Volumes/blah/bu/neepfile.txt"
	That clearly is just a regular FS path
	so handled the usual way, (Generate pcip files, etc.)
	not clear how the G2 information gets "absorbed into G1" and committed to disk

another way to think about this is that maybe there is no explicit "dereference"
instead, a ghost that knows it is an alias just passes all questions about itself
to the other thing?
but that would require a ton of proliferated code

maybe the TK just gets aliases and dereferences them after the fact to keep things clean

or there is a function on a ghost called g->absorbAttributesFromReferenceGhost()
and this moves over the hash, size, stat and other information

big question - is the file type of an alias always an alias?
like a symlink?
where you don't know if the symlink is a directory or a file?
maybe its best if we do that
unix seems to cope with that type of situation just fine


we need to figure out semantics for the reference database
we need to store two things permanently:

obj and ref

just like git

we can do this in our working directory
but it would be nice if this was all managed

this also should be some sort of FSE

objectstore

and there is a $coreOBS that is my working directory of shit
and i have an FSE complaint thing that manages it

so if I construct a hash like blob:423fe15,
G1 = tk->getGhostWithHash( "423fe15" )
	this routine is going to get you the most local version it can
	this may involve scanning various object stores it knows about
		its going to eventually end up saying
			$coreOBS->getGhostWithHash( "423fe15")
			the core OBS is special
			when you ask a object store FSE for a hashed thing
			it doesn't have to scan its known ghosts
			instead, it can actually just pick up the file
			it turns that into a ghost
			and someone should call "isAcceptaleCopy" to do a guard test on it

if i construct an lfn like blob:423fe15
G1  = TK->obtainGhostFromLFN( "blob:423fe15" );
	I'll get the ghost right away (its virtual)
	but the second anyone asks me to do something with it,
	i'll get delegated to to a blob FSE
	and the blob FSE knows to go back to truthkeeper
	maybe blobs are ocnsidered aliases (e.g. caller must dereference them)

thats sort of a nice way to handle it

in fact, yes, lets do it that way

maybe truthkeeper has a way when asked to do a getGhistWithHash
of passing that work down to FSEs?

there is also a ghostFromLFN strategy to think about
TK first checks its cache
if it can't find it there, it asks the relevant FSM
which implies that a global function to find FSM for LFN
this lives at the factory level



+++++

# what is the means by whcih deleted files are recongized?
# in cases of a full scan, someone has to be smart enough
# to know we are doing a scan that is "full" enough to count,
# and to mark ghosts for deletion

# right now, there is no stat verification when writing a snapshot
# snapshot -verify-stat (can find it, size and lastmod match) --verify-
# hash and when those things are in place, anthing that hasn't been
# checked in the last 24 hours are rejected, unless you say --hit-disk
# which means basically ignore all of the  tools and recheck everything


























